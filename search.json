[{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/AGENTS.html","id":"project-structure--module-organization","dir":"","previous_headings":"","what":"Project Structure & Module Organization","title":"Repository Guidelines","text":"R/ holds exported R wrappers, S3 methods, roxygen docs; mirror existing files like ops.R adding API surface. src/ contains Rcpp glue MLX (mlx_bindings.cpp, mlx_ops.cpp); keep headers sync RcppExports.R. tests/testthat/ groups unit specs domain (test-math.R, test-matmul.R); add new files test-feature.R. vignettes/getting-started.Rmd introduces workflows; update adding user-facing features. configure, DESCRIPTION, NAMESPACE manage build-time detection package metadata; configure step runs automatically install.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/AGENTS.html","id":"build-test-and-development-commands","dir":"","previous_headings":"","what":"Build, Test, and Development Commands","title":"Repository Guidelines","text":"R -q -e 'Rcpp::compileAttributes()' regenerates RcppExports touching headers .cpp. R -q -e 'devtools::document()' rebuilds NAMESPACE Rd files roxygen comments. R -q -e 'devtools::build()' creates source tarball; R -q -e 'devtools::check()' runs formal package checks. R -q -e 'devtools::test()' runs testthat suite; use R -q -e 'devtools::load_all()' rapid iteration.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/AGENTS.html","id":"coding-style--naming-conventions","dir":"","previous_headings":"","what":"Coding Style & Naming Conventions","title":"Repository Guidelines","text":"Use two-space indents R C++; keep lines 100 characters match current style. Prefer snake_case R helpers (as_mlx), S3 methods Generic.class (Math.mlx). C++ helpers follow descriptive snake_case RAII patterns; include <mlx/mlx.h> via mlx_bindings.hpp. Document R functions roxygen #' blocks; let @export drive NAMESPACE entries.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/AGENTS.html","id":"testing-guidelines","dir":"","previous_headings":"","what":"Testing Guidelines","title":"Repository Guidelines","text":"Write tests testthat tests/testthat; mirror existing structure keep scenario-focused blocks within test_that. Use CPU-friendly fixtures (small matrices) GPU CPU paths run quickly. Run R -q -e 'devtools::test()' locally; conditional skips—tests allowed fail MLX absent.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/AGENTS.html","id":"commit--pull-request-guidelines","dir":"","previous_headings":"","what":"Commit & Pull Request Guidelines","title":"Repository Guidelines","text":"Follow repository’s imperative, capitalized commit style (e.g., Add rowSums helper); keep subject lines near 70 characters. PR link issues relevant, summarize API changes, note Metal/CPU devices covered. opening PR, run R -q -e 'devtools::document()', R -q -e 'devtools::test()', R -q -e 'devtools::check()'; include notable outputs screenshots performance-sensitive work.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/AGENTS.html","id":"current-agent-notes-2025-10-22","dir":"","previous_headings":"","what":"Current Agent Notes (2025-10-22)","title":"Repository Guidelines","text":"MLX tensor creation Metal-backed work (e.g., as_mlx(), GPU tests) succeed session runs danger-full-access; restricted sandboxes block Metal device initialisation processx/callr’s kqueue() calls. restricted modes can still build via R CMD build/INSTALL roxygen2::roxygenise(load_code = roxygen2::load_source), expect MLX runtime calls bail c++ exception (unknown reason). danger-full-access, full devtools workflow (document(), test(), check()) works end--end. devtools::check() currently reports single NOTE bashism configure line 33; everything else clean. Keep workspace tidy checks: remove Rmlx_0.0.0.9000.tar.gz, temporary Rmlx.Rcheck/, local library/ installs create . Tests now pass, rely MLX availability. Avoid adding conditional skips—failures acceptable MLX absent.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/AGENTS.html","id":"mlx-integration-reminders","dir":"","previous_headings":"Additional Guidance","what":"MLX Integration Reminders","title":"Repository Guidelines","text":"MLX may rename C API entry points; confirm function names <mlx/c/mlx.h> wiring Rcpp wrappers. Update src/mlx_bindings.cpp src/mlx_ops.cpp whenever upstream changes occur. R arrays column-major MLX tensors row-major. reduction tests misbehave, double-check axis ordering (swapping axis 0/1 often fixes ).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/AGENTS.html","id":"testing-notes","dir":"","previous_headings":"Additional Guidance","what":"Testing Notes","title":"Repository Guidelines","text":"testthat specs live tests/testthat/; skip MLX fails load. Prefer tolerance = 1e-6 asserting floating point equality. Use base R results oracle comparisons. Run single file via R -q -e 'devtools::test_file(\"tests/testthat/test-ops.R\")' iterating.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/AGENTS.html","id":"documentation-workflow","dir":"","previous_headings":"Additional Guidance","what":"Documentation Workflow","title":"Repository Guidelines","text":"Roxygen comments power man/ docs; vignette vignettes/getting-started.Rmd. doc edits, regenerate R -q -e 'devtools::document()'. Favor markdown lists/tables roxygen \\item. Add @seealso links relevant MLX online docs new exports. adding features, update pkgdown reference index.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/AGENTS.html","id":"handy-tips","dir":"","previous_headings":"Additional Guidance","what":"Handy Tips","title":"Repository Guidelines","text":"usethis:: helpers provide canonical workflows package chores—prefer possible. MLX array types lack default constructor; always supply shape/dtype explicitly C++. Discover exports via library(help = \"Rmlx\"); inspect functions ls(envir = asNamespace(\"Rmlx\"), .names = TRUE). Search upstream docs https://ml-explore.github.io/mlx/build/html/search.html?q=<term>. Never edit NAMESPACE R/RcppExports.R hand—regenerate devtools::document() / Rcpp::compileAttributes() updating roxygen C++ signatures. user-facing APIs docs, prefer term array tensor match R conventions. Add concise internal documentation (comments helper docstrings) non-obvious internal helpers; keep codebase self-explanatory.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":null,"dir":"","previous_headings":"","what":"CLAUDE.md","title":"CLAUDE.md","text":"file provides guidance Claude Code (claude.ai/code) working code repository.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"package-overview","dir":"","previous_headings":"","what":"Package Overview","title":"CLAUDE.md","text":"Rmlx R interface Apple’s MLX (Machine Learning eXchange) library GPU-accelerated array operations Apple Silicon. package provides lazy evaluation, S3 operator overloading, familiar R syntax GPU computing. Requirements: - macOS Apple Silicon (M1/M2/M3+) - MLX C/C++ library installed - Rcpp R/C++ integration","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"building-and-testing","dir":"","previous_headings":"Development Commands","what":"Building and Testing","title":"CLAUDE.md","text":"R -q -e 'Rcpp::compileAttributes()' - Generate Rcpp exports modifying C++ code (ALWAYS run first) R -q -e 'devtools::document()' - Generate documentation roxygen comments R -q -e 'devtools::load_all()' - Load package interactive development R -q -e 'devtools::build()' - Build package R -q -e 'devtools::check()' - Run R CMD check R -q -e 'devtools::test()' - Run tests","code":""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"installing","dir":"","previous_headings":"Development Commands","what":"Installing","title":"CLAUDE.md","text":"R -q -e 'devtools::install()' - Install package locally (requires MLX)","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"mlx-installation","dir":"","previous_headings":"System Requirements","what":"MLX Installation","title":"CLAUDE.md","text":"package requires MLX headers library. Configure script searches: - /opt/homebrew/include/mlx/c/mlx.h (headers) - /opt/homebrew/lib/libmlx.dylib (library) - /usr/local/include, /usr/local/lib (alternatives) Override environment variables:","code":"export MLX_INCLUDE=/path/to/mlx/include export MLX_LIB_DIR=/path/to/mlx/lib export MLX_LIBS=\"-lmlx\""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"build-process","dir":"","previous_headings":"System Requirements","what":"Build Process","title":"CLAUDE.md","text":"configure script detects MLX writes src/Makevars cleanup script removes generated src/Makevars Build fails gracefully helpful error MLX found","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"c-core-src","dir":"","previous_headings":"Architecture","what":"C++ Core (src/)","title":"CLAUDE.md","text":"mlx_bindings.hpp/cpp - RAII wrapper, array creation, conversion, evaluation mlx_ops.cpp - Unary ops, binary ops, reductions, matrix ops, slicing init.cpp - R package registration RcppExports.cpp - Auto-generated Rcpp::compileAttributes() Key design: - MlxArray class wraps mlx_array* RAII semantics - External pointers R finalizers memory management - C++ functions exported via [[Rcpp::export]]","code":""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"r-code-r","dir":"","previous_headings":"Architecture","what":"R Code (R/)","title":"CLAUDE.md","text":"class.R - S3 class, constructors, converters (as_mlx, .matrix.mlx, mlx_eval) ops.R - Operator overloading (Ops.mlx, %*%.mlx) stats.R - Reductions matrix helpers (sum, mean, colMeans, t, crossprod) utils.R - Print, indexing [.mlx, accessors (dim, length) device.R - Device management (mlx_default_device, mlx_synchronize) Rmlx-package.R - Package documentation RcppExports.R - Auto-generated Rcpp::compileAttributes()","code":""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"key-features","dir":"","previous_headings":"Architecture","what":"Key Features","title":"CLAUDE.md","text":"Lazy evaluation - Operations build computation graph; evaluate mlx_eval() .matrix() S3 dispatch - Standard R syntax: +, -, *, /, ^, %*%, t(), etc. Broadcasting - NumPy-style broadcasting binary ops GPU/CPU - Default GPU; switch mlx_default_device()","code":""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"mlx-c-api-assumptions","dir":"","previous_headings":"Architecture","what":"MLX C API Assumptions","title":"CLAUDE.md","text":"C++ code assumes MLX C API functions like: - mlx_array_from_data(), mlx_array_free(), mlx_array_eval() - mlx_array_add(), mlx_array_matmul(), mlx_array_transpose() - mlx_array_sum(), mlx_array_mean(), etc. IMPORTANT: actual MLX C API function names may differ. compilation errors occur, check MLX documentation update function names src/mlx_bindings.cpp src/mlx_ops.cpp.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"mlx-headers-not-found","dir":"","previous_headings":"Common Issues","what":"MLX headers not found","title":"CLAUDE.md","text":"Install MLX: brew install mlx (available) build source Set MLX_INCLUDE environment variable Check header path /path//include/mlx/c/mlx.h","code":""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"wrong-mlx-function-names","dir":"","previous_headings":"Common Issues","what":"Wrong MLX function names","title":"CLAUDE.md","text":"MLX C API may different naming conventions Check #include <mlx/c/mlx.h> equivalent header Update function calls src/mlx_bindings.cpp src/mlx_ops.cpp","code":""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"axis-confusion-row-major-vs-column-major","dir":"","previous_headings":"Common Issues","what":"Axis confusion (row-major vs column-major)","title":"CLAUDE.md","text":"R uses column-major order MLX uses row-major order Tests verify colMeans/rowMeans map correct axes tests fail, swap axis=0 axis=1 reductions","code":""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"testing","dir":"","previous_headings":"","what":"Testing","title":"CLAUDE.md","text":"Tests tests/testthat/: - tests skip package can’t load (MLX available) - Use tolerance = 1e-6 floating-point comparisons - Compare base R results correctness Run specific test file:","code":"R -q -e 'devtools::test_file(\"tests/testthat/test-ops.R\")'"},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"CLAUDE.md","text":"Roxygen2 comments R files Vignette vignettes/getting-started.Rmd Examples use \\dontrun{} since MLX required editing docs: possible, use usethis:: package commands things canonical way. array type doesn’t default constructor! add function, update pkgdown reference index. add new function, include @seealso link online mlx documentation, appropriate. can use library(help = “Rmlx”) find exported R functions package, descriptions . can use ls(envir = asNamespace(“Rmlx”), .names = TRUE) find functions including unexported ones. url https://ml-explore.github.io/mlx/build/html/search.html?q=foobar search documentation foobar Always use markdown roxygen possible (e.g. markdown lists rather ).","code":"R -q -e 'devtools::document()'"},{"path":"https://hughjonesd.github.io/Rmlx/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 Rmlx authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/articles/getting-started.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Getting Started with Rmlx","text":"Apple MLX (Machine Learning eXchange) Apple’s high-performance array machine-learning framework Apple Silicon, built top Metal GPU execution optimized CPU kernels. offers lazy evaluation, vectorized math, automatic differentiation, neural network building blocks (see official MLX documentation full details). Rmlx thin R layer MLX lets : Create MLX tensors R data (as_mlx()). Run GPU-accelerated math, linear algebra, FFTs, reductions familiar R syntax. Use automatic differentiation (mlx_grad(), mlx_value_grad()) optimization. Build simple models MLX modules update using SGD helpers. heavy computation stays MLX land; copy back base R call functions like .matrix().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/articles/getting-started.html","id":"system-requirements","dir":"Articles","previous_headings":"","what":"System Requirements","title":"Getting Started with Rmlx","text":"using Rmlx, ensure MLX installed:","code":"# Using Homebrew (if available) brew install mlx  # Or build from source git clone https://github.com/ml-explore/mlx.git cd mlx && mkdir build && cd build cmake .. && make && sudo make install"},{"path":"https://hughjonesd.github.io/Rmlx/articles/getting-started.html","id":"creating-mlx-arrays","dir":"Articles","previous_headings":"","what":"Creating MLX Arrays","title":"Getting Started with Rmlx","text":"Convert R objects MLX arrays using as_mlx(): Precision note: Numeric inputs stored single precision (float32). Requesting dtype = \"float64\" downcast input warning. Logical inputs stored MLX bool tensors (logical NA values supported). Complex inputs stored complex64 (single-precision real imaginary parts). Use base R arrays need double precision arithmetic.","code":"library(Rmlx) #>  #> Attaching package: 'Rmlx' #> The following object is masked from 'package:stats': #>  #>     fft #> The following objects are masked from 'package:base': #>  #>     chol2inv, colMeans, colSums, diag, outer, rowMeans, rowSums, svd  # From a vector v <- as_mlx(1:10) print(v) #> mlx array [10] #>   dtype: float32 #>   device: gpu #>   values: #>  [1]  1  2  3  4  5  6  7  8  9 10  # From a matrix m <- matrix(1:12, nrow = 3, ncol = 4) x <- as_mlx(m) print(x) #> mlx array [3 x 4] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] [,4] #> [1,]    1    4    7   10 #> [2,]    2    5    8   11 #> [3,]    3    6    9   12  # Move the array to the GPU x_gpu <- as_mlx(m, device = \"gpu\")"},{"path":"https://hughjonesd.github.io/Rmlx/articles/getting-started.html","id":"lazy-evaluation","dir":"Articles","previous_headings":"","what":"Lazy Evaluation","title":"Getting Started with Rmlx","text":"MLX arrays use lazy evaluation - operations recorded computed needed:","code":"# These operations are not computed immediately x <- as_mlx(matrix(1:100, 10, 10)) y <- as_mlx(matrix(101:200, 10, 10)) z <- x + y * 2  # Force evaluation of a specific array mlx_eval(z)  # Or convert to R (automatically evaluates) as.matrix(z) #>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] #>  [1,]  203  233  263  293  323  353  383  413  443   473 #>  [2,]  206  236  266  296  326  356  386  416  446   476 #>  [3,]  209  239  269  299  329  359  389  419  449   479 #>  [4,]  212  242  272  302  332  362  392  422  452   482 #>  [5,]  215  245  275  305  335  365  395  425  455   485 #>  [6,]  218  248  278  308  338  368  398  428  458   488 #>  [7,]  221  251  281  311  341  371  401  431  461   491 #>  [8,]  224  254  284  314  344  374  404  434  464   494 #>  [9,]  227  257  287  317  347  377  407  437  467   497 #> [10,]  230  260  290  320  350  380  410  440  470   500  # Wait for all queued work on the GPU if needed mlx_synchronize(\"gpu\")"},{"path":"https://hughjonesd.github.io/Rmlx/articles/getting-started.html","id":"arithmetic-operations","dir":"Articles","previous_headings":"","what":"Arithmetic Operations","title":"Getting Started with Rmlx","text":"Rmlx supports standard arithmetic operators:","code":"x <- as_mlx(matrix(1:12, 3, 4)) y <- as_mlx(matrix(13:24, 3, 4))  # Element-wise operations sum_xy <- x + y diff_xy <- x - y prod_xy <- x * y quot_xy <- x / y pow_xy <- x ^ 2  # Convert back to R to see results as.matrix(sum_xy) #>      [,1] [,2] [,3] [,4] #> [1,]   14   20   26   32 #> [2,]   16   22   28   34 #> [3,]   18   24   30   36"},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/articles/getting-started.html","id":"matrix-multiplication","dir":"Articles","previous_headings":"Matrix Operations","what":"Matrix Multiplication","title":"Getting Started with Rmlx","text":"","code":"a <- as_mlx(matrix(1:6, 2, 3)) b <- as_mlx(matrix(1:6, 3, 2))  # Matrix multiplication c <- a %*% b as.matrix(c) #>      [,1] [,2] #> [1,]   22   49 #> [2,]   28   64"},{"path":"https://hughjonesd.github.io/Rmlx/articles/getting-started.html","id":"transpose","dir":"Articles","previous_headings":"Matrix Operations","what":"Transpose","title":"Getting Started with Rmlx","text":"","code":"x <- as_mlx(matrix(1:12, 3, 4)) x_t <- t(x) print(x_t) #> mlx array [4 x 3] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] #> [1,]    1    2    3 #> [2,]    4    5    6 #> [3,]    7    8    9 #> [4,]   10   11   12"},{"path":"https://hughjonesd.github.io/Rmlx/articles/getting-started.html","id":"cross-products","dir":"Articles","previous_headings":"Matrix Operations","what":"Cross Products","title":"Getting Started with Rmlx","text":"","code":"x <- as_mlx(matrix(rnorm(20), 5, 4)) true_w <- as_mlx(matrix(c(2, -1, 0.5, 0.25), 4, 1)) y <- x %*% true_w w <- as_mlx(matrix(0, 4, 1))  # Loss must stay entirely in MLX-land: no conversions back to base R loss <- function(theta, data_x, data_y) {   preds <- data_x %*% theta   resids <- preds - data_y   sum(resids * resids) / length(data_y) }  grads <- mlx_grad(loss, w, x, y)  # Wrong: converting to base R breaks the gradient bad_loss <- function(theta, data_x, data_y) {   preds <- as.matrix(data_x %*% theta)  # leaves MLX   resids <- preds - as.matrix(data_y)   sum(resids * resids) / nrow(resids) } try(mlx_grad(bad_loss, w, x, y)) #> Error in eval(expr, envir) :  #>   MLX autograd failed to differentiate the function: Gradient function must return an `mlx` object. Ensure your closure keeps computations in MLX or wraps the result with as_mlx(). #> Ensure all differentiable computations use MLX operations.  # A small SGD loop using the module/optimizer helpers model <- mlx_linear(4, 1, bias = FALSE)  # learns a single weight vector parameters <- mlx_parameters(model) opt <- mlx_optimizer_sgd(parameters, lr = 0.1) loss_fn <- function(mod, data_x, data_y) {   theta <- mlx_param_values(parameters)[[1]]   loss(theta, data_x, data_y) }  loss_history <- numeric(50) for (step in seq_along(loss_history)) {   step_res <- mlx_train_step(model, loss_fn, opt, x, y)   loss_history[step] <- as.vector(step_res$loss) }  # Check final loss and inspect learned parameters final_loss <- mlx_forward(model, x) residual_mse <- as.vector(mean((final_loss - y) * (final_loss - y))) residual_mse #> [1] 5.658819e-05 loss_history #>  [1] 8.308889e+00 4.272983e+00 2.288200e+00 1.283615e+00 7.582743e-01 #>  [6] 4.726674e-01 3.102017e-01 2.130744e-01 1.520021e-01 1.117421e-01 #> [11] 8.408680e-02 6.443550e-02 5.009037e-02 3.939489e-02 3.128565e-02 #> [16] 2.505323e-02 2.020860e-02 1.640565e-02 1.339452e-02 1.099170e-02 #> [21] 9.060724e-03 7.498934e-03 6.228307e-03 5.189063e-03 4.335000e-03 #> [26] 3.630075e-03 3.046037e-03 2.560509e-03 2.155664e-03 1.817213e-03 #> [31] 1.533631e-03 1.295554e-03 1.095328e-03 9.267041e-04 7.845016e-04 #> [36] 6.644622e-04 5.630297e-04 4.772589e-04 4.046760e-04 3.432218e-04 #> [41] 2.911653e-04 2.470508e-04 2.096552e-04 1.779418e-04 1.510463e-04 #> [46] 1.282235e-04 1.088608e-04 9.242821e-05 7.848036e-05 6.664058e-05  learned_w <- mlx_param_values(parameters)[[1]] as.matrix(learned_w) #>            [,1] #> [1,]  1.9941052 #> [2,] -1.0081218 #> [3,]  0.4934084 #> [4,]  0.2496413 as.matrix(true_w) #>       [,1] #> [1,]  2.00 #> [2,] -1.00 #> [3,]  0.50 #> [4,]  0.25"},{"path":"https://hughjonesd.github.io/Rmlx/articles/getting-started.html","id":"reductions","dir":"Articles","previous_headings":"","what":"Reductions","title":"Getting Started with Rmlx","text":"Compute summaries across arrays:","code":"x <- as_mlx(matrix(1:100, 10, 10))  # Overall reductions sum(x) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 5050 mean(x) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 50.5  # Column and row means colMeans(x) #> mlx array [10] #>   dtype: float32 #>   device: gpu #>   values: #>  [1]  5.5 15.5 25.5 35.5 45.5 55.5 65.5 75.5 85.5 95.5 rowMeans(x) #> mlx array [10] #>   dtype: float32 #>   device: gpu #>   values: #>  [1] 46 47 48 49 50 51 52 53 54 55  # Convert to R to see values as.matrix(colMeans(x)) #>  [1]  5.5 15.5 25.5 35.5 45.5 55.5 65.5 75.5 85.5 95.5  # Cumulative operations flatten the array in column-major order as.vector(cumsum(x)) #>   [1]    1    3    6   10   15   21   28   36   45   55   66   78   91  105  120 #>  [16]  136  153  171  190  210  231  253  276  300  325  351  378  406  435  465 #>  [31]  496  528  561  595  630  666  703  741  780  820  861  903  946  990 1035 #>  [46] 1081 1128 1176 1225 1275 1326 1378 1431 1485 1540 1596 1653 1711 1770 1830 #>  [61] 1891 1953 2016 2080 2145 2211 2278 2346 2415 2485 2556 2628 2701 2775 2850 #>  [76] 2926 3003 3081 3160 3240 3321 3403 3486 3570 3655 3741 3828 3916 4005 4095 #>  [91] 4186 4278 4371 4465 4560 4656 4753 4851 4950 5050"},{"path":"https://hughjonesd.github.io/Rmlx/articles/getting-started.html","id":"indexing","dir":"Articles","previous_headings":"","what":"Indexing","title":"Getting Started with Rmlx","text":"Subset MLX arrays similar R:","code":"x <- as_mlx(matrix(1:100, 10, 10))  # Select rows and columns x_sub <- x[1:5, 1:5]  # Select specific row row_1 <- x[1, ]  # Select specific column col_1 <- x[, 1]"},{"path":"https://hughjonesd.github.io/Rmlx/articles/getting-started.html","id":"device-management","dir":"Articles","previous_headings":"","what":"Device Management","title":"Getting Started with Rmlx","text":"Control whether computations run GPU CPU: Remember numeric computations always performed float32; CPU mode useful need compare base R debug without GPU.","code":"# Check default device mlx_default_device() #> [1] \"gpu\"  # Set to CPU for debugging mlx_default_device(\"cpu\") #> [1] \"cpu\"  # Create array on CPU x_cpu <- as_mlx(matrix(1:12, 3, 4), device = \"cpu\")  # Set back to GPU mlx_default_device(\"gpu\") #> [1] \"gpu\""},{"path":"https://hughjonesd.github.io/Rmlx/articles/getting-started.html","id":"performance-comparison","dir":"Articles","previous_headings":"","what":"Performance Comparison","title":"Getting Started with Rmlx","text":"’s simple timing comparison large matrix multiplication: Note: informal comparison, rigorous benchmark. Performance gains depend array size, operation type, hardware.","code":"n <- 1000  # R base m1 <- matrix(rnorm(n * n), n, n) m2 <- matrix(rnorm(n * n), n, n) t1 <- system.time(r_result <- m1 %*% m2)  # MLX x1 <- as_mlx(m1) x2 <- as_mlx(m2) mlx_eval(x1) mlx_eval(x2) t2 <- system.time({   mlx_result <- x1 %*% x2   mlx_eval(mlx_result)   final <- as.matrix(mlx_result) })  cat(\"Base R:\", t1[\"elapsed\"], \"seconds\\n\") #> Base R: 0.429 seconds cat(\"MLX:\", t2[\"elapsed\"], \"seconds\\n\") #> MLX: 0.018 seconds"},{"path":"https://hughjonesd.github.io/Rmlx/articles/getting-started.html","id":"best-practices","dir":"Articles","previous_headings":"","what":"Best Practices","title":"Getting Started with Rmlx","text":"Keep data GPU: Minimize transfers R MLX Use lazy evaluation: Build computation graphs evaluating Batch operations: Combine operations forcing evaluation Monitor memory: GPU memory limited; free unused arrays Start CPU: Use CPU device debugging, switch GPU","code":""},{"path":"https://hughjonesd.github.io/Rmlx/articles/getting-started.html","id":"limitations","dir":"Articles","previous_headings":"","what":"Limitations","title":"Getting Started with Rmlx","text":"Current limitations initial version: Apple Silicon (Intel Mac platforms) 2D arrays (matrices) primary focus Limited indexing operations autodiff gradient computation (planned future release)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/articles/linear-regression.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Linear Regression with MLX","text":"vignette demonstrates linear regression using Rmlx, based MLX linear regression example. ’ll train linear model using automatic differentiation stochastic gradient descent (SGD) GPU-accelerated arrays.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/articles/linear-regression.html","id":"problem-setup","dir":"Articles","previous_headings":"","what":"Problem Setup","title":"Linear Regression with MLX","text":"’ll create synthetic data linear regression high dimensionality: - random “true” weight vector w_star dimension 100 - random design matrix X 10,000 cases × 100 features - Noisy labels y = X @ w_star + small_noise","code":"library(Rmlx) #>  #> Attaching package: 'Rmlx' #> The following object is masked from 'package:stats': #>  #>     fft #> The following objects are masked from 'package:base': #>  #>     chol2inv, colMeans, colSums, diag, outer, rowMeans, rowSums, svd  # Problem metadata num_features <- 100 num_cases <- 10000 num_iters <- 1200          # iterations of SGD learning_rate <- 0.01      # learning rate for SGD  # Set seed for reproducibility set.seed(42)  # True parameters (what we're trying to learn) w_star <- mlx_rand_normal(c(num_features, 1))  # Input examples (design matrix) X <- mlx_rand_normal(c(num_cases, num_features))  # Noisy labels eps <- 1e-2 * mlx_rand_normal(c(num_cases, 1)) y <- X %*% w_star + eps"},{"path":"https://hughjonesd.github.io/Rmlx/articles/linear-regression.html","id":"define-the-loss-function","dir":"Articles","previous_headings":"","what":"Define the Loss Function","title":"Linear Regression with MLX","text":"mean squared error loss standard choice regression: loss measures well parameters w predict labels. Lower loss means better predictions.","code":"# Define loss function loss_fn <- function(w) {   preds <- X %*% w   residuals <- preds - y   0.5 * mean(residuals * residuals) }"},{"path":"https://hughjonesd.github.io/Rmlx/articles/linear-regression.html","id":"automatic-differentiation","dir":"Articles","previous_headings":"","what":"Automatic Differentiation","title":"Linear Regression with MLX","text":"Rmlx provides mlx_grad() compute gradients via automatic differentiation. computes gradient loss respect parameters:","code":"# Get the gradient function grad_fn <- function(w) {   mlx_grad(loss_fn, w)[[1]] }  train_sgd <- function(steps = num_iters, step_size = learning_rate, verbose = TRUE) {   w <- 1e-2 * mlx_rand_normal(c(num_features, 1))   for (i in seq_len(steps)) {     grad <- grad_fn(w)     w <- w - step_size * grad     mlx_eval(w)     if (verbose && i %% 1000 == 0) {       cat(\"Iteration\", i, \"- Loss:\", as.vector(loss_fn(w)), \"\\n\")     }   }   w }"},{"path":"https://hughjonesd.github.io/Rmlx/articles/linear-regression.html","id":"training-loop-with-sgd","dir":"Articles","previous_headings":"","what":"Training Loop with SGD","title":"Linear Regression with MLX","text":"train repeatedly computing gradients updating parameters. iteration, : Compute gradient loss respect w Update parameters using gradient step Force evaluation prevent computation graph growing unbounded Monitor progress printing loss every 1000 iterations","code":"w_sgd <- train_sgd() #> Iteration 1000 - Loss: 5.007338e-05"},{"path":"https://hughjonesd.github.io/Rmlx/articles/linear-regression.html","id":"method-2-closed-form-regression-via-matrix-algebra","dir":"Articles","previous_headings":"","what":"Method 2: Closed-form Regression via Matrix Algebra","title":"Linear Regression with MLX","text":"Gradient descent flexible, linear regression also closed-form solution can obtained via QR decomposition. Rather forming X⊤XX^\\top X explicitly, factor X=QRX = QR Q⊤Q=IQ^\\top Q = solve triangular system Rw=Q⊤yRw = Q^\\top y:","code":"mlx_normal_eq <- function(X, y) {   qr_res <- qr(X)   q <- qr_res$Q   r <- qr_res$R   q_ty <- crossprod(q, y)   mlx_solve_triangular(r, q_ty, upper = TRUE) }  w_closed <- mlx_normal_eq(X, y) mlx_eval(w_closed)  closed_error <- w_closed - w_star closed_error_norm <- sqrt(sum(closed_error * closed_error)) cat(\"Closed-form ||w - w*|| =\", as.vector(closed_error_norm), \"\\n\") #> Closed-form ||w - w*|| = 0.0009292653"},{"path":"https://hughjonesd.github.io/Rmlx/articles/linear-regression.html","id":"accelerating-the-closed-form-solution-with-mlx_compile","dir":"Articles","previous_headings":"","what":"Accelerating the Closed-form Solution with mlx_compile()","title":"Linear Regression with MLX","text":"closed-form function mixes several MLX primitives. can trace fuse operations mlx_compile(). first call incurs tracing cost; subsequent calls reuse compiled graph.","code":"compiled_normal_eq <- mlx_compile(mlx_normal_eq)  # Warm-up call performs tracing and compilation mlx_eval(compiled_normal_eq(X, y))  # Re-use the compiled function w_compiled <- compiled_normal_eq(X, y) mlx_eval(w_compiled)  compiled_error <- w_compiled - w_star compiled_error_norm <- sqrt(sum(compiled_error * compiled_error)) cat(\"Compiled closed-form ||w - w*|| =\", as.vector(compiled_error_norm), \"\\n\") #> Compiled closed-form ||w - w*|| = 0.0009292653"},{"path":"https://hughjonesd.github.io/Rmlx/articles/linear-regression.html","id":"accuracy-and-performance-comparison","dir":"Articles","previous_headings":"","what":"Accuracy and Performance Comparison","title":"Linear Regression with MLX","text":"compare approaches measure elapsed time several repetitions resulting distance estimate true coefficients. also add base R’s normal-equation implementation reference.","code":"library(bench)  # Fit models once for accuracy measurements w_sgd <- train_sgd(verbose = FALSE) w_closed <- mlx_normal_eq(X, y) compiled_normal_eq <- mlx_compile(mlx_normal_eq) mlx_eval(compiled_normal_eq(X, y)) w_compiled <- compiled_normal_eq(X, y) X_r <- as.matrix(X) y_r <- as.matrix(y) w_base <- matrix(lm.fit(X_r, y_r[, 1])$coefficients, ncol = 1)  # Accuracy comparisons to_norm <- function(w_hat) {   diff <- w_hat - as.matrix(w_star)   sqrt(sum(diff * diff)) }  # Benchmark timings (compiled solution already warm) timings <- bench::mark(   sgd = {     res <- train_sgd(verbose = FALSE)     mlx_eval(res)   },   mlx_closed = {     res <- mlx_normal_eq(X, y)     mlx_eval(res)   },   mlx_closed_compiled = {     res <- compiled_normal_eq(X, y)     mlx_eval(res)   },   base_R = {     lm.fit(X_r, y_r[, 1])$coefficients   },   iterations = 3,   check = FALSE ) |>   as.data.frame() #> Warning: Some expressions had a GC in every iteration; so filtering is #> disabled.  results <- data.frame(   method = c(\"SGD\", \"MLX closed form\", \"MLX closed form (compiled)\", \"Base R\"),   median_time = timings$median,   parameter_error = c(     to_norm(as.matrix(w_sgd)),     to_norm(as.matrix(w_closed)),     to_norm(as.matrix(w_compiled)),     to_norm(w_base)   ) ) knitr::kable(results, digits = 4)"},{"path":"https://hughjonesd.github.io/Rmlx/articles/linear-regression.html","id":"device-selection","dir":"Articles","previous_headings":"","what":"Device Selection","title":"Linear Regression with MLX","text":"default, computations run GPU speed. Switch CPU needed:","code":"# Use CPU (useful for debugging) mlx_default_device(\"cpu\") #> [1] \"cpu\"  # Or back to GPU mlx_default_device(\"gpu\") #> [1] \"gpu\""},{"path":"https://hughjonesd.github.io/Rmlx/articles/neural-networks.html","id":"building-a-neural-network","dir":"Articles","previous_headings":"","what":"Building a Neural Network","title":"Neural Networks with Rmlx","text":"Rmlx provides modular neural network components can combined using mlx_sequential(). ’s simple multi-layer perceptron (MLP) binary classification:","code":"library(Rmlx) #>  #> Attaching package: 'Rmlx' #> The following object is masked from 'package:stats': #>  #>     fft #> The following objects are masked from 'package:base': #>  #>     chol2inv, colMeans, colSums, diag, outer, rowMeans, rowSums, svd  # Create a 3-layer MLP mlp <- mlx_sequential(   mlx_linear(2, 32),    # Input: 2 features   mlx_relu(),   mlx_dropout(p = 0.2),   mlx_linear(32, 16),   mlx_relu(),   mlx_linear(16, 1),    # Output: 1 logit   mlx_sigmoid()         # Probability output )"},{"path":"https://hughjonesd.github.io/Rmlx/articles/neural-networks.html","id":"generating-training-data","dir":"Articles","previous_headings":"","what":"Generating Training Data","title":"Neural Networks with Rmlx","text":"Let’s create simple binary classification dataset:","code":"set.seed(42)  # Generate spiral dataset n_samples <- 200 noise <- 0.2  # Class 0: outer spiral theta0 <- runif(n_samples/2, 0, 4*pi) r0 <- theta0 / (4*pi) + rnorm(n_samples/2, 0, noise) x0 <- cbind(r0 * cos(theta0), r0 * sin(theta0)) y0 <- rep(0, n_samples/2)  # Class 1: inner spiral theta1 <- runif(n_samples/2, 0, 4*pi) r1 <- theta1 / (4*pi) + rnorm(n_samples/2, 0, noise) + 0.5 x1 <- cbind(r1 * cos(theta1), r1 * sin(theta1)) y1 <- rep(1, n_samples/2)  # Combine x_train <- rbind(x0, x1) y_train <- c(y0, y1)  # Convert to MLX tensors x_mlx <- as_mlx(x_train) y_mlx <- as_mlx(matrix(y_train, ncol = 1))"},{"path":"https://hughjonesd.github.io/Rmlx/articles/neural-networks.html","id":"training-loop","dir":"Articles","previous_headings":"","what":"Training Loop","title":"Neural Networks with Rmlx","text":"Define loss function train using gradient descent:","code":"# Loss function operating on the module loss_fn <- function(module, x, y) {   preds <- mlx_forward(module, x)   mlx_binary_cross_entropy(preds, y) }  # Training parameters learning_rate <- 0.05 n_epochs <- 60  # Optimizer and training mode optimizer <- mlx_optimizer_sgd(mlx_parameters(mlp), lr = learning_rate) mlx_set_training(mlp, TRUE)  for (epoch in seq_len(n_epochs)) {   step <- mlx_train_step(mlp, loss_fn, optimizer, x_mlx, y_mlx)    if (epoch %% 10 == 0) {     loss_value <- as.numeric(as.matrix(step$loss))     cat(sprintf(\"Epoch %d, Loss: %.4f\\n\", epoch, loss_value))   } } #> Epoch 10, Loss: 0.6927 #> Epoch 20, Loss: 0.6846 #> Epoch 30, Loss: 0.6549 #> Epoch 40, Loss: 0.6498 #> Epoch 50, Loss: 0.6425 #> Epoch 60, Loss: 0.6264  mlx_set_training(mlp, FALSE)"},{"path":"https://hughjonesd.github.io/Rmlx/articles/neural-networks.html","id":"making-predictions","dir":"Articles","previous_headings":"","what":"Making Predictions","title":"Neural Networks with Rmlx","text":"training, use model predictions:","code":"# Generate test points x_test <- as_mlx(matrix(c(0.5, 0.5, -0.5, -0.5), 2, 2))  # Forward pass mlx_set_training(mlp, FALSE)  # Ensure evaluation mode (disables dropout) predictions <- mlx_forward(mlp, x_test)  # Convert to probabilities probs <- as.matrix(predictions) classes <- ifelse(probs > 0.5, 1, 0) print(classes) #>      [,1] #> [1,]    1 #> [2,]    1"},{"path":"https://hughjonesd.github.io/Rmlx/articles/neural-networks.html","id":"using-different-architectures","dir":"Articles","previous_headings":"","what":"Using Different Architectures","title":"Neural Networks with Rmlx","text":"Rmlx provides various layer types different architectures:","code":""},{"path":"https://hughjonesd.github.io/Rmlx/articles/neural-networks.html","id":"convolutional-features","dir":"Articles","previous_headings":"Using Different Architectures","what":"Convolutional Features","title":"Neural Networks with Rmlx","text":"full convolution layers require C++ implementation, can combine linear layers reshape operations:","code":"# Classifier with normalization classifier <- mlx_sequential(   mlx_linear(10, 64),   mlx_layer_norm(64),   mlx_relu(),   mlx_dropout(p = 0.5),   mlx_linear(64, 32),   mlx_batch_norm(32),   mlx_relu(),   mlx_linear(32, 3),   mlx_softmax_layer()  # Multi-class output )"},{"path":"https://hughjonesd.github.io/Rmlx/articles/neural-networks.html","id":"embeddings-for-categorical-data","dir":"Articles","previous_headings":"Using Different Architectures","what":"Embeddings for Categorical Data","title":"Neural Networks with Rmlx","text":"Use mlx_embedding() categorical inputs:","code":"# Text/token embeddings vocab_size <- 10000 embed_dim <- 128  embedding_net <- mlx_sequential(   mlx_embedding(vocab_size, embed_dim),   mlx_linear(embed_dim, 64),   mlx_relu(),   mlx_linear(64, 1) )  # Input: token indices (0-indexed) tokens <- as_mlx(c(42, 17, 99)) output <- mlx_forward(embedding_net, tokens)"},{"path":"https://hughjonesd.github.io/Rmlx/articles/neural-networks.html","id":"available-loss-functions","dir":"Articles","previous_headings":"","what":"Available Loss Functions","title":"Neural Networks with Rmlx","text":"Rmlx implements common loss functions: mlx_mse_loss(): Mean squared error (regression) mlx_l1_loss(): Mean absolute error (robust regression) mlx_binary_cross_entropy(): Binary classification mlx_cross_entropy(): Multi-class classification supports reduction = \"mean\", \"sum\", \"none\".","code":""},{"path":"https://hughjonesd.github.io/Rmlx/articles/neural-networks.html","id":"available-activation-functions","dir":"Articles","previous_headings":"","what":"Available Activation Functions","title":"Neural Networks with Rmlx","text":"mlx_relu(): Rectified Linear Unit mlx_gelu(): Gaussian Error Linear Unit mlx_sigmoid(): Logistic sigmoid mlx_tanh(): Hyperbolic tangent mlx_silu(): Sigmoid Linear Unit (Swish) mlx_leaky_relu(): Leaky ReLU configurable slope mlx_softmax_layer(): Softmax normalization","code":""},{"path":"https://hughjonesd.github.io/Rmlx/articles/neural-networks.html","id":"regularization-and-normalization","dir":"Articles","previous_headings":"","what":"Regularization and Normalization","title":"Neural Networks with Rmlx","text":"mlx_dropout(): Dropout regularization mlx_layer_norm(): Layer normalization mlx_batch_norm(): Batch normalization Remember set training mode appropriately:","code":"model <- mlx_sequential(   mlx_linear(2, 4),   mlx_dropout(0.5) )  # Training mlx_set_training(model, TRUE)  # Evaluation mlx_set_training(model, FALSE)"},{"path":"https://hughjonesd.github.io/Rmlx/articles/neural-networks.html","id":"best-practices","dir":"Articles","previous_headings":"","what":"Best Practices","title":"Neural Networks with Rmlx","text":"Always evaluate: Call mlx_eval() parameter updates trigger computation Training mode: Set models training mode training, evaluation mode inference Gradient computation: Use argnums mlx_grad() specify arguments differentiate Device management: Ensure tensors device (GPU/CPU)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/articles/neural-networks.html","id":"further-reading","dir":"Articles","previous_headings":"","what":"Further Reading","title":"Neural Networks with Rmlx","text":"See vignette(\"linear-regression\") simpler optimization example Check ?mlx_grad automatic differentiation details Refer MLX Python documentation advanced patterns","code":""},{"path":"https://hughjonesd.github.io/Rmlx/articles/performance.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Performance Benchmarks","text":"vignette compares runtime core operations base R Rmlx.","code":"library(Rmlx) #>  #> Attaching package: 'Rmlx' #> The following object is masked from 'package:stats': #>  #>     fft #> The following objects are masked from 'package:base': #>  #>     chol2inv, colMeans, colSums, diag, outer, rowMeans, rowSums, svd library(bench) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2)"},{"path":"https://hughjonesd.github.io/Rmlx/articles/performance.html","id":"matrix-addition","dir":"Articles","previous_headings":"","what":"Matrix addition","title":"Performance Benchmarks","text":"","code":"mat_sizes <- c(256, 512, 1024) add_results <- bind_rows(lapply(mat_sizes, function(n) {   A_r <- matrix(runif(n * n), n, n)   B_r <- matrix(runif(n * n), n, n)   A_mlx <- as_mlx(A_r)   B_mlx <- as_mlx(B_r)    mb <- bench::mark(     base = { A_r + B_r },     rmlx = { as.matrix(A_mlx + B_mlx) },     iterations = 5,     check = \\(x, y) all.equal(x, y, tolerance = 1e-6)   )   mb$size <- n   mb }))  ggplot(add_results, aes(x = factor(size), y = as.numeric(median),                          fill = as.character(expression))) +   geom_col(position = \"dodge\") +   labs(     title = \"Matrix addition timing (median)\",     x = \"Matrix dimension\",     y = \"Median time\",     fill = \"Implementation\"   )"},{"path":"https://hughjonesd.github.io/Rmlx/articles/performance.html","id":"matrix-multiplication","dir":"Articles","previous_headings":"","what":"Matrix multiplication","title":"Performance Benchmarks","text":"","code":"matmul_results <- bind_rows(lapply(mat_sizes, function(n) {   A_r <- matrix(runif(n * n), n, n)   B_r <- matrix(runif(n * n), n, n)   A_mlx <- as_mlx(A_r)   B_mlx <- as_mlx(B_r)    mb <- bench::mark(     base = { A_r %*% B_r },     rmlx = { as.matrix(A_mlx %*% B_mlx) },     iterations = 3,     check = \\(x, y) all.equal(x, y, tolerance = 1e-6)   )   mb$size <- n   mb }))  ggplot(matmul_results, aes(x = factor(size), y = as.numeric(median),                          fill = as.character(expression))) +   geom_col(position = \"dodge\") +   labs(     title = \"Matrix multiplication timing (median)\",     x = \"Matrix dimension\",     y = \"Median time\",     fill = \"Implementation\"   )"},{"path":"https://hughjonesd.github.io/Rmlx/articles/performance.html","id":"linear-system-solves","dir":"Articles","previous_headings":"","what":"Linear system solves","title":"Performance Benchmarks","text":"","code":"solve_results <- bind_rows(lapply(mat_sizes, function(n) {   A_r <- matrix(rnorm(n * n), n, n)   A_r <- crossprod(A_r) + diag(n) * 1e-3   b_r <- matrix(rnorm(n), n, 1)   A_mlx <- as_mlx(A_r)   b_mlx <- as_mlx(b_r)    base_sol <- solve(A_r, b_r)   mlx_sol <- as.matrix(solve(A_mlx, b_mlx))   stopifnot(     max(abs(A_r %*% base_sol - b_r)) < 1e-8,     max(abs(A_r %*% mlx_sol - b_r)) < 5e-1   )    mb <- bench::mark(     base = { solve(A_r, b_r) },     rmlx = { as.matrix(solve(A_mlx, b_mlx)) },     iterations = 3,     check = FALSE   )   mb$size <- n   mb }))  ggplot(solve_results, aes(x = factor(size), y = as.numeric(median),                          fill = as.character(expression))) +   geom_col(position = \"dodge\") +   labs(     title = \"Linear solve timing (median)\",     x = \"Matrix dimension\",     y = \"Median time\",     fill = \"Implementation\"   )"},{"path":"https://hughjonesd.github.io/Rmlx/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"David Hugh-Jones. Author, maintainer.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Hugh-Jones D (2025). Rmlx: R Interface Apple's MLX library GPU-accelerated arrays. R package version 0.1.0.9000, https://hughjonesd.github.io/Rmlx/.","code":"@Manual{,   title = {Rmlx: R Interface to Apple's MLX library for GPU-accelerated arrays},   author = {David Hugh-Jones},   year = {2025},   note = {R package version 0.1.0.9000},   url = {https://hughjonesd.github.io/Rmlx/}, }"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"rmlx","dir":"","previous_headings":"","what":"R Interface to Apple's MLX library for GPU-accelerated arrays","title":"R Interface to Apple's MLX library for GPU-accelerated arrays","text":"R interface Apple’s MLX (Machine Learning eXchange) library.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"R Interface to Apple's MLX library for GPU-accelerated arrays","text":"Rmlx provides R interface Apple’s MLX framework, enabling high-performance GPU computing Apple Silicon. package vibe-coded Claude/OpenAI Codex week. Use risk! Much C++ API implemented, python-features large neural network layers.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"motivation","dir":"","previous_headings":"","what":"Motivation","title":"R Interface to Apple's MLX library for GPU-accelerated arrays","text":"Modern Macs GPU, great performing matrix operations. Statistics uses lot matrix operations. now, way R Mac use GPU. Rmlx changes .","code":""},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"requirements","dir":"","previous_headings":"","what":"Requirements","title":"R Interface to Apple's MLX library for GPU-accelerated arrays","text":"macOS Apple Silicon Linux CUDA MacOS/Linux CPU-build","code":""},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"R Interface to Apple's MLX library for GPU-accelerated arrays","text":"brew install mlx Linux equivalent. just install package normal: Alternatively, can build mlx source.","code":"# install.packages(\"remotes\") remotes::install(\"hughjonesd/Rmlx\")"},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"fast-gpu-operations","dir":"","previous_headings":"Features","what":"Fast GPU Operations","title":"R Interface to Apple's MLX library for GPU-accelerated arrays","text":"","code":"library(Rmlx) #>  #> Attaching package: 'Rmlx' #> The following object is masked from 'package:stats': #>  #>     fft #> The following objects are masked from 'package:base': #>  #>     chol2inv, colMeans, colSums, diag, outer, rowMeans, rowSums, svd  A <- matrix(rnorm(1e6), 1e3, 1e3) system.time(solve(A)) #>    user  system elapsed  #>   0.395   0.002   0.399 system.time(solve(as_mlx(A))) #>    user  system elapsed  #>   0.048   0.055   0.104"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"lazy-evaluation","dir":"","previous_headings":"Features","what":"Lazy Evaluation","title":"R Interface to Apple's MLX library for GPU-accelerated arrays","text":"Operations recorded executed explicitly evaluated:","code":"x <- as_mlx(matrix(1:25, 5, 5)) y <- as_mlx(matrix(101:125, 5, 5))  # Lazy - not computed yet z <- x + y * 2  # Force evaluation mlx_eval(z)  # Or convert to R (automatically evaluates) as.matrix(z) #>      [,1] [,2] [,3] [,4] [,5] #> [1,]  203  218  233  248  263 #> [2,]  206  221  236  251  266 #> [3,]  209  224  239  254  269 #> [4,]  212  227  242  257  272 #> [5,]  215  230  245  260  275"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"device-management","dir":"","previous_headings":"Features","what":"Device Management","title":"R Interface to Apple's MLX library for GPU-accelerated arrays","text":"M series chips shared memory CPU GPU, switching devices costless.","code":"# Check/set default device dev <- mlx_default_device()            mlx_default_device(\"cpu\")    # Switch to CPU mlx_default_device(dev)      # Back to GPU  # Create on specific device x_gpu <- as_mlx(matrix(1:12, 3, 4), device = \"gpu\") x_cpu <- as_mlx(matrix(1:12, 3, 4), device = \"cpu\")"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"subsetting","dir":"","previous_headings":"Features","what":"Subsetting","title":"R Interface to Apple's MLX library for GPU-accelerated arrays","text":"Subsetting works like base R:","code":"x <- as_mlx(matrix(1:9, 3, 3)) x[1:2, 1:2] #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]    1    4 #> [2,]    2    5  # drop = FALSE by default x[1, ] #> mlx array [1 x 3] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] #> [1,]    1    4    7  logical_mask <- c(TRUE, FALSE, TRUE) x[logical_mask, ] #> mlx array [2 x 3] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] #> [1,]    1    4    7 #> [2,]    3    6    9  # subset assignment  x[, 2] <- c(0, 0, 0) x #> mlx array [3 x 3] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] #> [1,]    1    0    7 #> [2,]    2    0    8 #> [3,]    3    0    9"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"arithmetic","dir":"","previous_headings":"Features","what":"Arithmetic","title":"R Interface to Apple's MLX library for GPU-accelerated arrays","text":"","code":"x <- as_mlx(matrix(1:12, 3, 4)) y <- as_mlx(matrix(13:24, 3, 4))  # Element-wise operations sum_xy <- x + y diff_xy <- x - y prod_xy <- x * y quot_xy <- x / y pow_xy <- x ^ 2  # Comparisons lt <- x < y eq <- x == y  # Bring results back to R as.matrix(sum_xy) #>      [,1] [,2] [,3] [,4] #> [1,]   14   20   26   32 #> [2,]   16   22   28   34 #> [3,]   18   24   30   36 as.matrix(lt) #>      [,1] [,2] [,3] [,4] #> [1,] TRUE TRUE TRUE TRUE #> [2,] TRUE TRUE TRUE TRUE #> [3,] TRUE TRUE TRUE TRUE"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"matrix-operations","dir":"","previous_headings":"Features","what":"Matrix Operations","title":"R Interface to Apple's MLX library for GPU-accelerated arrays","text":"Many base R matrix functions mlx-specific methods:","code":"a <- as_mlx(matrix(1:6, 2, 3)) b <- as_mlx(matrix(1:6, 3, 2))  # rbind, cbind, transpose rbind(a, t(b)) #> mlx array [4 x 3] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] #> [1,]    1    3    5 #> [2,]    2    4    6 #> [3,]    1    2    3 #> [4,]    4    5    6 cbind(a, t(b)) #> mlx array [2 x 6] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] [,4] [,5] [,6] #> [1,]    1    3    5    1    2    3 #> [2,]    2    4    6    4    5    6  # Matrix multiplication a %*% b #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]   22   49 #> [2,]   28   64  # Reductions sum(a) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 21 mean(a) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 3.5 colMeans(a) #> mlx array [3] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 1.5 3.5 5.5 rowMeans(a) #> mlx array [2] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 3 4  # Cumulative operations flatten column-major as.vector(cumsum(a)) #> [1]  1  3  6 10 15 21  qr_res <- qr(a) svd_res <- svd(a) chol_res <- chol(as_mlx(crossprod(matrix(1:6, 3, 2)))) fft_res <- fft(a)  qr_res$Q #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>            [,1]       [,2] #> [1,] -0.4472135 -0.8944272 #> [2,] -0.8944272  0.4472136 svd_res$d #> mlx array [2] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 9.5255194 0.5143015 chol_res #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>          [,1]     [,2] #> [1,] 3.741657 8.552360 #> [2,] 0.000000 1.963962"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"random-sampling","dir":"","previous_headings":"Features","what":"Random Sampling","title":"R Interface to Apple's MLX library for GPU-accelerated arrays","text":"","code":"mlx_rand_uniform(c(3, 3), min = -1, max = 1) #> mlx array [3 x 3] #>   dtype: float32 #>   device: gpu #>   values: #>             [,1]       [,2]       [,3] #> [1,] -0.88357937 -0.3713405 -0.0342840 #> [2,]  0.09261358 -0.2968941 -0.4256831 #> [3,]  0.72074342  0.5229734 -0.1605381"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"data-transformations","dir":"","previous_headings":"Features","what":"Data Transformations","title":"R Interface to Apple's MLX library for GPU-accelerated arrays","text":"","code":"scores <- as_mlx(c(0.1, 0.7, 0.4, 0.9)) mlx_sort(scores) #> mlx array [4] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 0.1 0.4 0.7 0.9 mlx_topk(scores, 2) #> mlx array [2] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 0.7 0.9 mlx_argmax(scores) #> mlx array [] #>   dtype: int64 #>   device: gpu #>   values: #> [1] 4"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"matrix-operations-1","dir":"","previous_headings":"Features","what":"Matrix Operations","title":"R Interface to Apple's MLX library for GPU-accelerated arrays","text":"","code":"A <- as_mlx(matrix(1:4, 2, 2)) B <- as_mlx(matrix(c(1, 0, -1, 0), 2, 2)) A %*% B #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]    1   -1 #> [2,]    2   -2 solve(A, B) #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]   -2    2 #> [2,]    1   -1 crossprod(A, B) #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]    1   -1 #> [2,]    3   -3"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"automatic-differentiation","dir":"","previous_headings":"Features","what":"Automatic Differentiation","title":"R Interface to Apple's MLX library for GPU-accelerated arrays","text":"","code":"loss <- function(w, x, y) {   preds <- x %*% w   resids <- preds - y   sum(resids * resids) / length(y) }  x <- as_mlx(matrix(rnorm(20), 5, 4)) y <- as_mlx(matrix(rnorm(5), 5, 1)) w <- as_mlx(matrix(0, 4, 1))  grads <- mlx_grad(loss, w, x, y)  # Inspect gradient as.matrix(grads[[1]]) #>             [,1] #> [1,] -0.77310860 #> [2,]  0.14119890 #> [3,] -0.12343385 #> [4,]  0.05721617  # Simple SGD loop model <- mlx_linear(4, 1, bias = FALSE) opt <- mlx_optimizer_sgd(mlx_parameters(model), lr = 0.1) loss_fn <- function(mod, data_x, data_y) {   preds <- mlx_forward(mod, data_x)   resids <- preds - data_y   sum(resids * resids) / length(data_y) } for (step in 1:50) {   mlx_train_step(model, loss_fn, opt, x, y) }  # Check final loss final_loss <- mlx_forward(model, x) mean((final_loss - y) * (final_loss - y)) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 0.06682333"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"data-types","dir":"","previous_headings":"","what":"Data Types","title":"R Interface to Apple's MLX library for GPU-accelerated arrays","text":"Supported data types: float32 numeric data (default) bool logical data Integer types int8, int16, int32, int64, uint8, uint16, uint32, uint64. complex64","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"high-level-scope-for-the-agent","dir":"","previous_headings":"","what":"High-level scope (for the agent)","title":"Project: Rmlx","text":"Language: R (+ C++ via Rcpp). OS: macOS Apple Silicon (Metal backend). Cross-platform explicitly scope now. Dependency: Apple MLX C/C++ library (present system). ’ll vendor MLX; ’ll detect link . Core object: S3 class mlx wrapping external pointer MLX array. Semantics: lazy default. .matrix.mlx() (conversions) force evaluation; otherwise, users call mlx_eval(x). Operator overloading: arithmetic, matrix algebra, comparisons; plus targeted stats helpers (colMeans.mlx, rowMeans.mlx, crossprod.mlx, tcrossprod.mlx, t.mlx, sum.mlx, mean.mlx). Phase 1: low-level arrays + ops, evaluation, conversions, basic reductions, tests, doc. (Autodiff/optimizers reserved later phase, implemented now.)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"milestones","dir":"","previous_headings":"","what":"Milestones","title":"Project: Rmlx","text":"Scaffold & toolchain C++ core: array handle, create/convert/eval Binary ops & reductions Matrix algebra & helpers R S3 class + operator overloading Indexing, printing, diagnostics Device/stream management Docs, examples, tests Build, local check, packaging milestone lists atomic tasks.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"milestone-1--scaffold--toolchain","dir":"","previous_headings":"","what":"Milestone 1 — Scaffold & toolchain","title":"Project: Rmlx","text":"T1. Create package skeleton Create standard R package layout: Acceptance: R CMD build produces tarball; R CMD check runs (expect skips missing MLX T3/T4 add detection). T2. DESCRIPTION Minimal fields: Package: Rmlx Type: Package Title: R Interface Apple's MLX Arrays (GPU-Accelerated Apple Silicon) Version: 0.0.0.9000 Authors@R: person(\"First\",\"Last\", role=c(\"aut\",\"cre\"), email=\"@example.com\") Description: S3 class 'mlx' backed Apple MLX arrays lazy GPU ops via Rcpp. License: MIT + file LICENSE Encoding: UTF-8 Depends: R (>= 4.1.0) Imports: Rcpp (>= 1.0.10) LinkingTo: Rcpp Suggests: testthat (>= 3.0.0), knitr, rmarkdown Config/testthat/edition: 3 SystemRequirements: MLX (Apple Machine Learning eXchange) C/C++ headers library; macOS Apple Silicon Acceptance: R CMD check reads DESCRIPTION cleanly. T3. NAMESPACE Start : ’ll also register %*% mlx via setMethod pattern R (see T17). T4. Build-time MLX detection (configure) Implement POSIX shell configure : Looks MLX headers & libs (probe typical locations: /opt/homebrew/include, /opt/homebrew/lib, /usr/local/include, /usr/local/lib, xcrun -sdk macosx --show-sdk-path). Allows env overrides: MLX_INCLUDE, MLX_LIB_DIR, MLX_LIBS (e.g., -lmlx -lc++) Writes src/Makevars PKG_CPPFLAGS including -... PKG_LIBS including -L... -lmlx. Add helpful error found: write small header check fail message telling user install MLX (Homebrew tap Apple docs). Acceptance: R CMD INSTALL . fails gracefully MLX missing; succeeds include+lib provided. Gotcha: keep Makevars minimal platform-guarded; hardcode Intel paths.","code":"Rmlx/   R/   src/   inst/   man/   tests/testthat/   vignettes/   DESCRIPTION   NAMESPACE   .Rbuildignore   .gitignore   configure     # POSIX shell   cleanup       # optional useDynLib(Rmlx, .registration = TRUE) importFrom(Rcpp, sourceCpp) S3method(print, mlx) S3method(as.matrix, mlx) S3method(colMeans, mlx) S3method(rowMeans, mlx) S3method(t, mlx) S3method(sum, mlx) S3method(mean, mlx) S3method(crossprod, mlx) S3method(tcrossprod, mlx) S3method(Ops, mlx) S3method(MatMult, mlx)       # custom for %*% (see T17)"},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"milestone-2--c-core-array-handle-createconverteval","dir":"","previous_headings":"","what":"Milestone 2 — C++ core: array handle, create/convert/eval","title":"Project: Rmlx","text":"T5. Define C++ wrapper class & finalizer File: src/mlx_bindings.cpp, plus header src/mlx_bindings.hpp. Create thin RAII wrapper around MLX array handle (consult MLX C API names; assume types like mlx_array*): Expose external pointer R finalizer deletes MlxArray. Acceptance: Creating garbage-collecting mlx object leak (use valgrind locally possible). T6. Create MLX array R data Rcpp-exposed functions (C++): SEXP cpp_mlx_from_numeric(SEXP x, SEXP dim, SEXP dtype, SEXP device); Inputs: x NumericVector (contiguous), dim IntegerVector, dtype string (“float32”/“float64”), device string (“gpu”/“cpu”). Create MLX array given shape copy host data. SEXP cpp_mlx_empty(SEXP dim, SEXP dtype, SEXP device); Acceptance: as_mlx(matrix(...)) returns mlx matching shape dtype. T7. Copy MLX array back R Function: SEXP cpp_mlx_to_numeric(SEXP x); Ensure evaluation first (see T8). copy NumericVector (column-major like R). Acceptance: .matrix.mlx(x) yields identical values input roundtrip. T8. Evaluation Implement: void cpp_mlx_eval(SEXP x); (force compute & sync). Design: store “needs_eval” flag inside wrapper, rely MLX’s state; call MLX eval array current graph root. R side: mlx_eval(x) calls cpp_mlx_eval. .matrix.mlx() must call mlx_eval() copying. Acceptance: Composed lazy ops compute evaluated converted.","code":"struct MlxArray {   mlx_array* ptr;   MlxArray();                       // null   explicit MlxArray(mlx_array* p);  // takes ownership   ~MlxArray();                      // calls mlx_array_free(ptr)   MlxArray(const MlxArray&) = delete;   MlxArray& operator=(const MlxArray&) = delete;   MlxArray(MlxArray&&) noexcept;   MlxArray& operator=(MlxArray&&) noexcept; };"},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"milestone-3--binary-ops--reductions","dir":"","previous_headings":"","what":"Milestone 3 — Binary ops & reductions","title":"Project: Rmlx","text":"T9. Elementwise unary ops C++ functions: neg, abs, sqrt, exp, log, sin, cos, etc. Signature pattern: SEXP cpp_mlx_unary(SEXP x, std::string op); // op ∈ {\"neg\",\"exp\",\"log\",...} Implementation maps MLX C API unary ops; output matches input dtype unless op requires float. T10. Elementwise binary ops Support: + - * / ^ comparisons < <= > >= == !=. Signature: SEXP cpp_mlx_binary(SEXP x, SEXP y, std::string op); Broadcasting rules: Follow MLX’s broadcasting (like NumPy). Validate shapes; throw R error incompatible shapes. scalar RHS/LHS, allow numeric logical scalars (wrap 0-d/1-d MLX arrays handle scalar op MLX supports). T11. Reductions Support: sum, mean (overall along axes), min, max. Signatures: SEXP cpp_mlx_reduce(SEXP x, std::string op); // full reduction -> scalar mlx SEXP cpp_mlx_reduce_axis(SEXP x, std::string op, int axis, bool keepdims); R wrappers provide sum.mlx, mean.mlx, helper colMeans.mlx / rowMeans.mlx built axis reductions. Acceptance: Numerically matches R within tolerance random small arrays.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"milestone-4--matrix-algebra--helpers","dir":"","previous_headings":"","what":"Milestone 4 — Matrix algebra & helpers","title":"Project: Rmlx","text":"T12. Transpose, reshape SEXP cpp_mlx_transpose(SEXP x); SEXP cpp_mlx_reshape(SEXP x, SEXP new_dim); T13. Matrix multiply SEXP cpp_mlx_matmul(SEXP , SEXP b); Accept shapes: (m×k) %*% (k×n) → (m×n); vectors meaningful (k)×(k) → scalar. Use MLX matmul op; ensure float32/float64 supported. T14. Crossprod & tcrossprod Implement top matmul + transpose, exploit MLX fused ops available later. R wrappers: crossprod.mlx(x, y = NULL) → t(x) %*% (y %||% x) tcrossprod.mlx(x, y = NULL) → x %*% t(y %||% x) T15. t.mlx, colMeans.mlx, rowMeans.mlx t.mlx → transpose colMeans.mlx → mean(x, axis=0) assuming R column-major (verify axis mapping; likely axis=0 == rows; explicit test). rowMeans.mlx → mean(x, axis=1) (ditto). Document axis semantics clearly.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"milestone-5--r-s3-class--operator-overloading","dir":"","previous_headings":"","what":"Milestone 5 — R S3 class + operator overloading","title":"Project: Rmlx","text":"T16. Class constructors & converters (R) File: R/class.R new_mlx <- function(ptr, dim, dtype, device) { structure(list(ptr=ptr, dim=dim, dtype=dtype, device=device), class=\"mlx\") } as_mlx <- function(x, dtype=c(\"float32\",\"float64\"), device=c(\"gpu\",\"cpu\")) Coerce matrix/array/numeric MLX via cpp_mlx_from_numeric. .matrix.mlx <- function(x, ...) { mlx_eval(x); cpp_mlx_to_numeric(x$ptr) |> structure(dim=x$dim) } mlx_eval <- function(x) { cpp_mlx_eval(x$ptr); invisible(x) } .mlx <- function(x) inherits(x, \"mlx\") T17. Operator overloading File: R/ops.R Define S3 method Ops.mlx dispatch elementwise + comparisons. Helper R wrappers call C++: .mlx_unary <- function(x, op) new_mlx(cpp_mlx_unary(x$ptr, op), x$dim, x$dtype, x$device) .mlx_binary <- function(x, y, op) new_mlx(cpp_mlx_binary(x$ptr, y$ptr, op), broadcast_dim(x,y), promote_dtype(x,y), common_device(x,y)) Matrix multiply %*% base R %*% primitive; define S3 generic shim: Register .onLoad: T18. Stats helpers File: R/stats.R sum.mlx, mean.mlx → reductions (full). colMeans.mlx, rowMeans.mlx → axis reductions + drop=TRUE return 1D mlx (dim length 1 removed) keepdims + reshape. t.mlx → transpose wrapper. crossprod.mlx, tcrossprod.mlx. T19. Class utilities File: R/utils.R print.mlx → show shape, dtype, device, lazy/evaluated flag; show small preview (e.g., 6×6) evaluating small slice (optionally evaluate fully size small). str.mlx → concise structure. Acceptance: Arithmetic, comparisons, %*%, col/row means reductions work mlx/regular R objects, producing mlx user calls .matrix() mlx_eval().","code":"Ops.mlx <- function(e1, e2 = NULL) {   op <- .Generic   if (is.null(e2)) {     # unary ops: \"+\" (no-op), \"-\" (neg)     if (op == \"+\") return(e1)     if (op == \"-\") return(.mlx_unary(e1, \"neg\"))     stop(sprintf(\"Unary op '%s' not supported for mlx\", op))   }   # Coerce scalars/matrix to mlx   if (!is.mlx(e1)) e1 <- as_mlx(e1)   if (!is.mlx(e2)) e2 <- as_mlx(e2)   if (op %in% c(\"+\",\"-\",\"*\",\"/\",\"^\")) return(.mlx_binary(e1, e2, op))   if (op %in% c(\"==\",\"!=\",\"<\",\"<=\",\">\",\">=\")) return(.mlx_binary(e1, e2, op))   stop(sprintf(\"Op '%s' not supported for mlx\", op)) } `%*%.mlx` <- function(x, y) {   if (!is.mlx(x)) x <- as_mlx(x)   if (!is.mlx(y)) y <- as_mlx(y)   new_mlx(cpp_mlx_matmul(x$ptr, y$ptr), c(x$dim[1L], y$dim[length(y$dim)]), promote_dtype(x,y), common_device(x,y)) } .onLoad <- function(...) {   # Ensure our method is visible for dispatch   # (S3 method for primitive is recognized if named `%*%.mlx`) }"},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"milestone-6--indexing-printing-diagnostics","dir":"","previous_headings":"","what":"Milestone 6 — Indexing, printing, diagnostics","title":"Project: Rmlx","text":"T20. Indexing [ ] R method: C++: SEXP cpp_mlx_slice(SEXP x, SEXP i_, SEXP j_); Support integer/real/logical vectors; negative indices throw (translate). Use MLX slicing ops (start/stop/step per axis). Acceptance: x[ ,1], x[1:5, 3:7], logical masks rows/cols (optional v1) behave; returns mlx. T21. Shape/dtype accessors R: mlx_dim <- function(x) x$dim mlx_dtype <- function(x) x$dtype dim.mlx <- function(x) x$dim (S3) length.mlx <- function(x) prod(x$dim) T22. Error messages Ensure C++ functions translate exceptions R errors actionable messages: incompatible shapes, dtype mismatch, found MLX op, etc.","code":"`[.mlx` <- function(x, i, j, ..., drop = TRUE) {   # Convert missing to full spans, build slices, call C++ slice   new_mlx(cpp_mlx_slice(x$ptr, normalize_index(i), normalize_index(j)), new_dim, x$dtype, x$device) }"},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"milestone-7--devicestream-management","dir":"","previous_headings":"","what":"Milestone 7 — Device/stream management","title":"Project: Rmlx","text":"T23. Default device R: mlx_default_device <- local({ dev <- \"gpu\"; function(value) { (!missing(value)) dev <<- match.arg(value, c(\"gpu\",\"cpu\")); dev }}) Used as_mlx() constructors device specified. C++: Keep references MLX CPU/GPU streams (e.g., MLX_GPU_STREAM, MLX_CPU_STREAM identifiers). Make small helper select stream per call. Acceptance: Users can switch default CPU debugging; ops route accordingly. T24. Synchronization R: mlx_synchronize(device=c(\"gpu\",\"cpu\")) → C++ call stream/device synchronize (MLX exposes ). Acceptance: outstanding work remains synchronize.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"milestone-8--docs-examples-tests","dir":"","previous_headings":"","what":"Milestone 8 — Docs, examples, tests","title":"Project: Rmlx","text":"T25. Roxygen2 docs Add #' docs user-facing functions: as_mlx, .matrix.mlx, mlx_eval, ops overview, %*%, colMeans.mlx, rowMeans.mlx, etc. ?mlx overview man page: explain laziness, evaluation points, device selection, unified memory concept. T26. Vignette vignettes/getting-started.Rmd Walkthrough: creating mlx arrays, arithmetic, %*%, reductions, colMeans, evaluation/convert, simple timing demo vs base R large matmul (note: formal benchmark). State Apple-requirement. T27. Tests (testthat) Skip tests MLX unavailable device GPU: Tests: Roundtrip as_mlx → .matrix equality. Elementwise ops vs base R (small sizes). %*% correctness vs base R. colMeans/rowMeans/sum/mean equality vs base R. Broadcasting cases. Indexing behavior. Tolerances: use expect_equal(..., tolerance = 1e-6).","code":"skip_if_not(mlx_available())"},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"milestone-9--build-local-check-packaging","dir":"","previous_headings":"","what":"Milestone 9 — Build, local check, packaging","title":"Project: Rmlx","text":"T28. Local build Commands: R CMD build . R CMD INSTALL Rmlx_0.0.0.9000.tar.gz R CMD check Rmlx_0.0.0.9000.tar.gz ---cran Accept: ERRORs; NOTE/WARN SystemRequirements acceptable. T29. Minimal examples Add examples function docs run fast touch small arrays avoid GPU timeouts.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"file-by-file-stubs-for-the-agent","dir":"","previous_headings":"","what":"File-by-file stubs (for the agent)","title":"Project: Rmlx","text":"R/class.R R/ops.R (skeleton shown earlier) R/stats.R src/Makevars (generated configure) src/registration.cpp src/mlx_bindings.cpp (sketch)","code":"#' Create MLX array from R object #' @export as_mlx <- function(x, dtype = c(\"float32\",\"float64\"), device = mlx_default_device()) {   dtype <- match.arg(dtype)   if (is.mlx(x)) return(x)   if (is.vector(x)) dim <- length(x) else dim <- dim(x)   stopifnot(!is.null(dim))   ptr <- cpp_mlx_from_numeric(as.numeric(x), as.integer(dim), dtype, device)   structure(list(ptr = ptr, dim = as.integer(dim), dtype = dtype, device = device), class = \"mlx\") }  #' Force evaluation #' @export mlx_eval <- function(x) { stopifnot(is.mlx(x)); cpp_mlx_eval(x$ptr); invisible(x) }  #' Convert MLX array to base matrix/array #' @export as.matrix.mlx <- function(x, ...) {   mlx_eval(x)   out <- cpp_mlx_to_numeric(x$ptr)   dim(out) <- x$dim   out }  is.mlx <- function(x) inherits(x, \"mlx\") #' @export sum.mlx  <- function(x, ...) .mlx_reduce(x, \"sum\") #' @export mean.mlx <- function(x, ...) .mlx_reduce(x, \"mean\")  #' @export colMeans.mlx <- function(x, na.rm = FALSE, dims = 1, ...) .mlx_reduce_axis(x, \"mean\", axis = 0L, keepdims = FALSE) #' @export rowMeans.mlx <- function(x, na.rm = FALSE, dims = 1, ...) .mlx_reduce_axis(x, \"mean\", axis = 1L, keepdims = FALSE)  #' @export t.mlx <- function(x) new_mlx(cpp_mlx_transpose(x$ptr), rev(x$dim), x$dtype, x$device)  #' @export crossprod.mlx <- function(x, y = NULL) { if (is.null(y)) y <- x; t(x) %*% y } #' @export tcrossprod.mlx <- function(x, y = NULL) { if (is.null(y)) y <- x; x %*% t(y) } PKG_CPPFLAGS = -I$(MLX_INCLUDE) PKG_LIBS     = -L$(MLX_LIB_DIR) -lmlx #include <Rcpp.h> using namespace Rcpp; // forward-declare C++ functions to register with R // RCPP_MODULE / R_registerRoutines as needed  extern \"C\" {   void R_init_Rmlx(DllInfo *dll) {     R_registerRoutines(dll, NULL, NULL, NULL, NULL);     R_useDynamicSymbols(dll, TRUE);   } } #include <Rcpp.h> #include \"mlx_bindings.hpp\" #include <mlx/c_api.h>  // adjust include path per installed MLX  using namespace Rcpp;  // Helpers to unwrap/wrap external pointers, set dims/dtype/device (store those in R side)  SEXP cpp_mlx_from_numeric(SEXP x_, SEXP dim_, SEXP dtype_, SEXP device_) {   NumericVector x(x_);   IntegerVector dim(dim_);   std::string dtype = as<std::string>(dtype_);   std::string device = as<std::string>(device_);    // create MLX array with given shape and dtype on device   // copy x.data() into MLX array   // return XPtr<MlxArray>(new MlxArray(ptr), true) }  SEXP cpp_mlx_to_numeric(SEXP xp_) {   // ensure evaluated   // copy MLX array data to NumericVector }  void cpp_mlx_eval(SEXP xp_) {   // call MLX eval on underlying array/graph }  // unary, binary, reduce, reduce_axis, transpose, reshape, matmul, slice..."},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"acceptance-checklist-phase-1-complete","dir":"","previous_headings":"","what":"Acceptance checklist (Phase 1 complete)","title":"Project: Rmlx","text":"Build succeeds Apple Silicon MLX installed. as_mlx(), .matrix.mlx() roundtrip correct. + - * / ^, comparisons, %*% produce correct results vs base R (small sizes). sum.mlx, mean.mlx, colMeans.mlx, rowMeans.mlx, t.mlx, crossprod.mlx, tcrossprod.mlx correct. Lazy default; .matrix.mlx() forces evaluation; mlx_eval() works. Indexing [] supports common cases. Helpful errors MLX found install, shape/dtype mismatches runtime. Vignette explains usage caveats.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"risks--notes-for-the-agent","dir":"","previous_headings":"","what":"Risks & notes for the agent","title":"Project: Rmlx","text":"MLX headers & symbols: Ensure correct include (e.g., #include <mlx/c_api.h>) link flags; actual header path & lib name may vary; keep configure flexible env overrides. Dtype: R double default; ’ll allow float32 float64. Decide default (float32 faster GPU; match R expectations, maybe default float64; document choice). Axis conventions: Confirm MLX axis numbering vs R’s column-major expectations; lock tests colMeans/rowMeans. Broadcasting: Implement consistent rules; add tests scalar + array, vector + matrix. Evaluation semantics: MLX needs explicit graph roots streams eval, store whatever handle required array (per-session singleton), make cpp_mlx_eval robust. Thread safety: Rcpp calls execute R main thread; ensure MLX usage safe context. Indexing: Logical indexing may deferred; start integer ranges : slices.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"phase-2-later-not-in-scope-for-this-handoff","dir":"","previous_headings":"","what":"Phase 2 (later, not in scope for this handoff)","title":"Project: Rmlx","text":"Autodiff: wrap MLX grad transforms; expose mlx_grad(fn, params) R closures provide graph-based differentiation APIs. Optimizers: SGD/Adam mlx parameters. linalg: solve, chol, svd, eigen (depending MLX support). Datasets/dataloaders, random seeding, fused kernels, compilation.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Math.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Math operations for MLX arrays — Math.mlx","title":"Math operations for MLX arrays — Math.mlx","text":"Math operations MLX arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Math.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Math operations for MLX arrays — Math.mlx","text":"","code":"# S3 method for class 'mlx' Math(x, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/Math.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Math operations for MLX arrays — Math.mlx","text":"x mlx array. ... Additional arguments (ignored)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Math.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Math operations for MLX arrays — Math.mlx","text":"mlx object result","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/Math.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Math operations for MLX arrays — Math.mlx","text":"","code":"x <- as_mlx(matrix(c(-1, 0, 1), 3, 1)) sin(x) #> mlx array [3 x 1] #>   dtype: float32 #>   device: gpu #>   values: #>           [,1] #> [1,] -0.841471 #> [2,]  0.000000 #> [3,]  0.841471 round(x + 0.4) #> mlx array [3 x 1] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] #> [1,]   -1 #> [2,]    0 #> [3,]    1"},{"path":"https://hughjonesd.github.io/Rmlx/reference/Ops.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Arithmetic and comparison operators for MLX arrays — Ops.mlx","title":"Arithmetic and comparison operators for MLX arrays — Ops.mlx","text":"Arithmetic comparison operators MLX arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Ops.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Arithmetic and comparison operators for MLX arrays — Ops.mlx","text":"","code":"# S3 method for class 'mlx' Ops(e1, e2 = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/Ops.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Arithmetic and comparison operators for MLX arrays — Ops.mlx","text":"e1 First operand (mlx numeric) e2 Second operand (mlx numeric)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Ops.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Arithmetic and comparison operators for MLX arrays — Ops.mlx","text":"mlx object","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/Ops.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Arithmetic and comparison operators for MLX arrays — Ops.mlx","text":"","code":"if (FALSE) { # \\dontrun{ x <- as_mlx(matrix(1:4, 2, 2)) y <- as_mlx(matrix(5:8, 2, 2)) x + y x < y } # }"},{"path":"https://hughjonesd.github.io/Rmlx/reference/Rmlx-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Rmlx: R Interface to Apple's MLX Arrays — Rmlx-package","title":"Rmlx: R Interface to Apple's MLX Arrays — Rmlx-package","text":"package provides R interface Apple's MLX (Machine Learning eXchange) library GPU-accelerated array operations Apple Silicon.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Rmlx-package.html","id":"key-features","dir":"Reference","previous_headings":"","what":"Key Features","title":"Rmlx: R Interface to Apple's MLX Arrays — Rmlx-package","text":"Lazy evaluation: Operations computed explicitly evaluated GPU acceleration: Leverage Metal Apple Silicon Familiar syntax: S3 methods standard R operations Unified memory: Efficient data sharing CPU GPU","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Rmlx-package.html","id":"main-functions","dir":"Reference","previous_headings":"","what":"Main Functions","title":"Rmlx: R Interface to Apple's MLX Arrays — Rmlx-package","text":"as_mlx(): Convert R objects MLX arrays .matrix.mlx(): Convert MLX arrays back R mlx_eval(): Force evaluation lazy operations Arithmetic: +, -, *, /, ^ Matrix ops: %*%, t, crossprod, tcrossprod Reductions: sum, mean, colMeans, rowMeans","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Rmlx-package.html","id":"lazy-evaluation","dir":"Reference","previous_headings":"","what":"Lazy Evaluation","title":"Rmlx: R Interface to Apple's MLX Arrays — Rmlx-package","text":"MLX arrays use lazy evaluation default. Operations recorded executed : call mlx_eval(x) convert R .matrix(x) result needed another computation","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Rmlx-package.html","id":"device-management","dir":"Reference","previous_headings":"","what":"Device Management","title":"Rmlx: R Interface to Apple's MLX Arrays — Rmlx-package","text":"Use mlx_default_device() control whether arrays created GPU (default) CPU. mlx arrays stored float32 regardless device. Use base R arrays require float64 math.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Rmlx-package.html","id":"known-limitations","dir":"Reference","previous_headings":"","what":"Known Limitations","title":"Rmlx: R Interface to Apple's MLX Arrays — Rmlx-package","text":"Rmlx yet wrap every MLX primitive. Major gaps include: Scatter-style updates (e.g. scatter_add, take_along_axis) Bitwise integer kernels (bitwise //XOR, shifts) Advanced autograd transforms (jvp, vjp, vmap, custom VJPs) N-dimensional FFT helpers (fftn, rfftn, inverse variants) Distributed collectives (NCCL/MPI backends) See dev/mlx_coverage.txt living checklist MLX surface area.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/Rmlx-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Rmlx: R Interface to Apple's MLX Arrays — Rmlx-package","text":"Maintainer: David Hugh-Jones david@hughjones.com","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/abind.html","id":null,"dir":"Reference","previous_headings":"","what":"Bind mlx arrays along an axis — abind","title":"Bind mlx arrays along an axis — abind","text":"Bind mlx arrays along axis","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/abind.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bind mlx arrays along an axis — abind","text":"","code":"abind(..., along = 1L)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/abind.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bind mlx arrays along an axis — abind","text":"... One mlx arrays (single list arrays) combine. along Positive integer giving existing axis (1-indexed) along bind inputs.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/abind.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bind mlx arrays along an axis — abind","text":"mlx array formed concatenating inputs along along.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/abind.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bind mlx arrays along an axis — abind","text":"MLX-backed alternative abind::abind(). inputs must share shape non-bound axes. along axis must already exist; create new axis use mlx_stack().","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/abind.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bind mlx arrays along an axis — abind","text":"","code":"x <- as_mlx(array(1:12, c(2, 3, 2))) y <- as_mlx(array(13:24, c(2, 3, 2))) z <- abind(x, y, along = 3) dim(z) #> [1] 2 3 4"},{"path":"https://hughjonesd.github.io/Rmlx/reference/all.equal.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Test if two MLX arrays are (nearly) equal — all.equal.mlx","title":"Test if two MLX arrays are (nearly) equal — all.equal.mlx","text":"S3 method .equal following R semantics. Returns TRUE arrays close, character vector describing differences .","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/all.equal.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test if two MLX arrays are (nearly) equal — all.equal.mlx","text":"","code":"# S3 method for class 'mlx' all.equal(target, current, tolerance = sqrt(.Machine$double.eps), ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/all.equal.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test if two MLX arrays are (nearly) equal — all.equal.mlx","text":"target, current MLX arrays compare tolerance Numeric tolerance comparison (default: sqrt(.Machine$double.eps)) ... Additional arguments (currently ignored)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/all.equal.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test if two MLX arrays are (nearly) equal — all.equal.mlx","text":"Either TRUE character vector describing differences","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/all.equal.mlx.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Test if two MLX arrays are (nearly) equal — all.equal.mlx","text":"method follows R's .equal() semantics: Returns TRUE arrays close within tolerance Returns character vector describing differences otherwise Checks dimensions/shapes comparing values tolerance converted MLX's rtol atol parameters: rtol = tolerance atol = tolerance","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/all.equal.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test if two MLX arrays are (nearly) equal — all.equal.mlx","text":"","code":"a <- as_mlx(c(1.0, 2.0, 3.0)) b <- as_mlx(c(1.0 + 1e-6, 2.0 + 1e-6, 3.0 + 1e-6)) all.equal(a, b)  # TRUE #> [1] \"Arrays are not all close within tolerance\"  c <- as_mlx(c(1.0, 2.0, 10.0)) all.equal(a, c)  # Character vector describing difference #> [1] \"Arrays are not all close within tolerance\""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.array.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert MLX array to R array — as.array.mlx","title":"Convert MLX array to R array — as.array.mlx","text":"Convert MLX array R array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.array.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert MLX array to R array — as.array.mlx","text":"","code":"# S3 method for class 'mlx' as.array(x, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.array.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert MLX array to R array — as.array.mlx","text":"x mlx array. ... Additional arguments (ignored)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.array.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert MLX array to R array — as.array.mlx","text":"numeric array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.array.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert MLX array to R array — as.array.mlx","text":"","code":"x <- as_mlx(matrix(1:8, 2, 4)) as.array(x) #>      [,1] [,2] [,3] [,4] #> [1,]    1    3    5    7 #> [2,]    2    4    6    8"},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.matrix.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert MLX array to R matrix/array — as.matrix.mlx","title":"Convert MLX array to R matrix/array — as.matrix.mlx","text":"MLX arrays without dimension returned R vectors.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.matrix.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert MLX array to R matrix/array — as.matrix.mlx","text":"","code":"# S3 method for class 'mlx' as.matrix(x, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.matrix.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert MLX array to R matrix/array — as.matrix.mlx","text":"x mlx array. ... Additional arguments (ignored)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.matrix.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert MLX array to R matrix/array — as.matrix.mlx","text":"vector, matrix array (numeric logical depending dtype)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.matrix.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert MLX array to R matrix/array — as.matrix.mlx","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) as.matrix(x) #>      [,1] [,2] #> [1,]    1    3 #> [2,]    2    4"},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.vector.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert MLX array to R vector — as.vector.mlx","title":"Convert MLX array to R vector — as.vector.mlx","text":"Converts MLX array R vector. multi-dimensional arrays (2+ dimensions), warning issued array flattened column-major order (R's default).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.vector.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert MLX array to R vector — as.vector.mlx","text":"","code":"# S3 method for class 'mlx' as.vector(x, mode = \"any\")"},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.vector.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert MLX array to R vector — as.vector.mlx","text":"x mlx array. mode Character string specifying type vector return (passed base::.vector())","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.vector.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert MLX array to R vector — as.vector.mlx","text":"vector specified mode","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.vector.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert MLX array to R vector — as.vector.mlx","text":"","code":"x <- as_mlx(1:5) as.vector(x) #> [1] 1 2 3 4 5  # Multi-dimensional arrays produce a warning m <- as_mlx(matrix(1:6, 2, 3)) v <- suppressWarnings(as.vector(m))  # Flattened in column-major order"},{"path":"https://hughjonesd.github.io/Rmlx/reference/as_mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Create MLX array from R object — as_mlx","title":"Create MLX array from R object — as_mlx","text":"Create MLX array R object","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as_mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create MLX array from R object — as_mlx","text":"","code":"as_mlx(   x,   dtype = c(\"float32\", \"float64\", \"bool\", \"complex64\", \"int8\", \"int16\", \"int32\", \"int64\",     \"uint8\", \"uint16\", \"uint32\", \"uint64\"),   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/as_mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create MLX array from R object — as_mlx","text":"x Numeric, logical, complex vector, matrix, array convert dtype Data type MLX array. One : Floating point: \"float32\", \"float64\" Integer signed: \"int8\", \"int16\", \"int32\", \"int64\" Integer unsigned: \"uint8\", \"uint16\", \"uint32\", \"uint64\" : \"bool\", \"complex64\" specified, defaults \"float32\" numeric, \"bool\" logical, \"complex64\" complex inputs. device Device: \"gpu\" (default) \"cpu\"","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as_mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create MLX array from R object — as_mlx","text":"object class mlx","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/as_mlx.html","id":"default-type-behavior","dir":"Reference","previous_headings":"","what":"Default type behavior","title":"Create MLX array from R object — as_mlx","text":"dtype specified: Numeric vectors/arrays (including R integers 1:10) → float32 Logical vectors/arrays → bool Complex vectors/arrays → complex64","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as_mlx.html","id":"integer-types-require-explicit-dtype","dir":"Reference","previous_headings":"","what":"Integer types require explicit dtype","title":"Create MLX array from R object — as_mlx","text":"Important: R integer vectors (like 1:10) convert float32 default. create integer MLX arrays, must explicitly specify dtype:   design avoids unintentional integer promotion, since R creates integers many contexts floating-point intended.","code":"x <- as_mlx(1:10, dtype = \"int32\")  # Creates int32 array x <- as_mlx(1:10)                    # Creates float32 array"},{"path":"https://hughjonesd.github.io/Rmlx/reference/as_mlx.html","id":"supported-integer-types","dir":"Reference","previous_headings":"","what":"Supported integer types","title":"Create MLX array from R object — as_mlx","text":"Signed: int8 (-128 127), int16, int32, int64 Unsigned: uint8 (0 255), uint16, uint32, uint64","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as_mlx.html","id":"type-precision-notes","dir":"Reference","previous_headings":"","what":"Type precision notes","title":"Create MLX array from R object — as_mlx","text":"float64 supported emits warning downcasts float32 Integer arithmetic may promote types (e.g., int32 + int32 might → int64) Mixed integer/float operations promote float","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as_mlx.html","id":"missing-values","dir":"Reference","previous_headings":"","what":"Missing values","title":"Create MLX array from R object — as_mlx","text":"MLX NA sentinel. pass numeric NA values R, stored NaN inside MLX returned R NaN. Use .nan() MLX arrays (method provided) need detect .","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/as_mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create MLX array from R object — as_mlx","text":"","code":"# Default float32 for numeric x <- as_mlx(c(1.5, 2.5, 3.5)) mlx_dtype(x)  # \"float32\" #> [1] \"float32\"  # R integers also default to float32 x <- as_mlx(1:10) mlx_dtype(x)  # \"float32\" #> [1] \"float32\"  # Explicit integer types x_int <- as_mlx(1:10, dtype = \"int32\") mlx_dtype(x_int)  # \"int32\" #> [1] \"int32\"  # Unsigned integers x_uint <- as_mlx(c(0, 128, 255), dtype = \"uint8\")  # Logical → bool mask <- as_mlx(c(TRUE, FALSE, TRUE)) mlx_dtype(mask)  # \"bool\" #> [1] \"bool\""},{"path":"https://hughjonesd.github.io/Rmlx/reference/cbind.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Column-bind mlx arrays — cbind.mlx","title":"Column-bind mlx arrays — cbind.mlx","text":"Column-bind mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/cbind.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Column-bind mlx arrays — cbind.mlx","text":"","code":"# S3 method for class 'mlx' cbind(..., deparse.level = 1)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/cbind.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Column-bind mlx arrays — cbind.mlx","text":"... Objects bind. mlx arrays kept MLX; inputs coerced via as_mlx(). deparse.level Compatibility argument accepted S3 dispatch; ignored.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/cbind.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Column-bind mlx arrays — cbind.mlx","text":"mlx array stacked along second axis.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/cbind.mlx.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Column-bind mlx arrays — cbind.mlx","text":"Unlike base R's cbind(), function supports arrays 2 dimensions preserves dimensions except second (summed across inputs). Base R's cbind() flattens higher-dimensional arrays matrices binding.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/cbind.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Column-bind mlx arrays — cbind.mlx","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) y <- as_mlx(matrix(5:8, 2, 2)) cbind(x, y) #> mlx array [2 x 4] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] [,4] #> [1,]    1    3    5    7 #> [2,]    2    4    6    8"},{"path":"https://hughjonesd.github.io/Rmlx/reference/chol.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Cholesky decomposition for mlx arrays — chol.mlx","title":"Cholesky decomposition for mlx arrays — chol.mlx","text":"x symmetric positive semi-definite, \"behaviour undefined\" according MLX documentation.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/chol.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cholesky decomposition for mlx arrays — chol.mlx","text":"","code":"# S3 method for class 'mlx' chol(x, pivot = FALSE, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/chol.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cholesky decomposition for mlx arrays — chol.mlx","text":"x mlx matrix (2-dimensional array). pivot Ignored; pivoted decomposition supported. ... Additional arguments (unused).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/chol.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cholesky decomposition for mlx arrays — chol.mlx","text":"Upper-triangular Cholesky factor mlx matrix.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/chol.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cholesky decomposition for mlx arrays — chol.mlx","text":"","code":"x <- as_mlx(matrix(c(4, 1, 1, 3), 2, 2)) chol(x) #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1]     [,2] #> [1,]    2 0.500000 #> [2,]    0 1.658312"},{"path":"https://hughjonesd.github.io/Rmlx/reference/chol2inv.html","id":null,"dir":"Reference","previous_headings":"","what":"Inverse from Cholesky decomposition — chol2inv","title":"Inverse from Cholesky decomposition — chol2inv","text":"Compute inverse symmetric, positive definite matrix Cholesky decomposition. input x upper triangular matrix chol().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/chol2inv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inverse from Cholesky decomposition — chol2inv","text":"","code":"chol2inv(x, size = NCOL(x), ...)  # Default S3 method chol2inv(x, size = NCOL(x), ...)  # S3 method for class 'mlx' chol2inv(x, size = NCOL(x), ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/chol2inv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inverse from Cholesky decomposition — chol2inv","text":"x mlx matrix (2-dimensional array). size Ignored; included compatibility base R. ... Additional arguments (unused).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/chol2inv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inverse from Cholesky decomposition — chol2inv","text":"inverse original matrix (Cholesky decomposition).","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/chol2inv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inverse from Cholesky decomposition — chol2inv","text":"","code":"A <- as_mlx(matrix(c(4, 1, 1, 3), 2, 2)) U <- chol(A) A_inv <- chol2inv(U) # Verify: A %*% A_inv should be identity as.matrix(A %*% A_inv) #>      [,1] [,2] #> [1,]    1    0 #> [2,]    0    1"},{"path":"https://hughjonesd.github.io/Rmlx/reference/colMeans.html","id":null,"dir":"Reference","previous_headings":"","what":"Column means for mlx arrays — colMeans","title":"Column means for mlx arrays — colMeans","text":"Column means mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/colMeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Column means for mlx arrays — colMeans","text":"","code":"colMeans(x, ...)  # Default S3 method colMeans(x, na.rm = FALSE, dims = 1, ...)  # S3 method for class 'mlx' colMeans(x, na.rm = FALSE, dims = 1, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/colMeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Column means for mlx arrays — colMeans","text":"x array mlx array. ... Additional arguments forwarded base implementation. na.rm Logical; currently ignored mlx arrays. dims Dimensions passed base implementation x mlx array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/colMeans.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Column means for mlx arrays — colMeans","text":"mlx array x mlx, otherwise numeric vector.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/colMeans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Column means for mlx arrays — colMeans","text":"","code":"x <- as_mlx(matrix(1:6, 3, 2)) colMeans(x) #> mlx array [2] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 2 5"},{"path":"https://hughjonesd.github.io/Rmlx/reference/colSums.html","id":null,"dir":"Reference","previous_headings":"","what":"Column sums for mlx arrays — colSums","title":"Column sums for mlx arrays — colSums","text":"Column sums mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/colSums.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Column sums for mlx arrays — colSums","text":"","code":"colSums(x, ...)  # Default S3 method colSums(x, na.rm = FALSE, dims = 1, ...)  # S3 method for class 'mlx' colSums(x, na.rm = FALSE, dims = 1, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/colSums.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Column sums for mlx arrays — colSums","text":"x array mlx array. ... Additional arguments forwarded base implementation. na.rm Logical; currently ignored mlx arrays. dims Dimensions passed base implementation x mlx array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/colSums.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Column sums for mlx arrays — colSums","text":"mlx array x mlx, otherwise numeric vector.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/colSums.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Column sums for mlx arrays — colSums","text":"","code":"x <- as_mlx(matrix(1:6, 3, 2)) colSums(x) #> mlx array [2] #>   dtype: float32 #>   device: gpu #>   values: #> [1]  6 15"},{"path":"https://hughjonesd.github.io/Rmlx/reference/common_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Common Parameter Documentation — common_params","title":"Common Parameter Documentation — common_params","text":"Common Parameter Documentation","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/common_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Common Parameter Documentation — common_params","text":"device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Default: mlx_default_device(). dtype Data type string. Supported types include: Floating point: \"float32\", \"float64\" Integer: \"int8\", \"int16\", \"int32\", \"int64\", \"uint8\", \"uint16\", \"uint32\", \"uint64\" : \"bool\", \"complex64\" functions support types. See individual function documentation. axis Axis axes operate (1-indexed). Negative values count end. NULL operates axes entire array. drop TRUE (default), drop dimensions length 1. FALSE, retain dimensions. Equivalent keepdims = TRUE underlying mlx functions. dim Integer vector specifying array dimensions (shape). x mlx array, R array/matrix/vector converted via as_mlx().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/conv_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Common Convolution Parameters — conv_params","title":"Common Convolution Parameters — conv_params","text":"Common Convolution Parameters","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/conv_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Common Convolution Parameters — conv_params","text":"input Input mlx array. Shape depends dimensionality (see individual functions). weight Weight array. Shape depends dimensionality (see individual functions). stride Stride convolution. Can scalar vector (length depends dimensionality). Default: 1 1D, c(1,1) 2D, c(1,1,1) 3D. padding Amount zero padding. Can scalar vector (length depends dimensionality). Default: 0 1D, c(0,0) 2D, c(0,0,0) 3D. dilation Spacing kernel elements. Can scalar vector (length depends dimensionality). Default: 1 1D, c(1,1) 2D, c(1,1,1) 3D. groups Number blocked connections input output channels. Default: 1.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/crossprod.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross product — crossprod.mlx","title":"Cross product — crossprod.mlx","text":"Cross product","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/crossprod.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross product — crossprod.mlx","text":"","code":"# S3 method for class 'mlx' crossprod(x, y = NULL, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/crossprod.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross product — crossprod.mlx","text":"x mlx matrix (2-dimensional array). y mlx matrix (default: NULL, uses x) ... Additional arguments passed base::crossprod.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/crossprod.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross product — crossprod.mlx","text":"t(x) %*% y mlx object","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/crossprod.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross product — crossprod.mlx","text":"","code":"x <- as_mlx(matrix(1:6, 2, 3)) crossprod(x) #> mlx array [3 x 3] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] #> [1,]    5   11   17 #> [2,]   11   25   39 #> [3,]   17   39   61"},{"path":"https://hughjonesd.github.io/Rmlx/reference/diag.html","id":null,"dir":"Reference","previous_headings":"","what":"Diagonal matrix extraction and construction — diag","title":"Diagonal matrix extraction and construction — diag","text":"Generic function extracting/constructing diagonal matrices.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/diag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Diagonal matrix extraction and construction — diag","text":"","code":"diag(x = 1, nrow, ncol, names = TRUE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/diag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Diagonal matrix extraction and construction — diag","text":"x object. nrow, ncol Optional dimensions matrix construction. names Logical indicating whether use names.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/dim-set-.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Set dimensions of MLX array — dim<-.mlx","title":"Set dimensions of MLX array — dim<-.mlx","text":"Reshapes MLX array specified dimensions. total number elements must remain .","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/dim-set-.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set dimensions of MLX array — dim<-.mlx","text":"","code":"# S3 method for class 'mlx' dim(x) <- value"},{"path":"https://hughjonesd.github.io/Rmlx/reference/dim-set-.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set dimensions of MLX array — dim<-.mlx","text":"x mlx array, R array/matrix/vector converted via as_mlx(). value Integer vector new dimensions","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/dim-set-.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set dimensions of MLX array — dim<-.mlx","text":"Reshaped mlx object","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/dim-set-.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set dimensions of MLX array — dim<-.mlx","text":"","code":"x <- as_mlx(1:12) dim(x) <- c(3, 4) dim(x) #> [1] 3 4"},{"path":"https://hughjonesd.github.io/Rmlx/reference/dim.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Get dimensions of MLX array — dim.mlx","title":"Get dimensions of MLX array — dim.mlx","text":"Get dimensions MLX array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/dim.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get dimensions of MLX array — dim.mlx","text":"","code":"# S3 method for class 'mlx' dim(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/dim.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get dimensions of MLX array — dim.mlx","text":"x mlx array, R array/matrix/vector converted via as_mlx().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/dim.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get dimensions of MLX array — dim.mlx","text":"Integer vector dimensions","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/dim.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get dimensions of MLX array — dim.mlx","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) dim(x) #> [1] 2 2"},{"path":"https://hughjonesd.github.io/Rmlx/reference/fft.html","id":null,"dir":"Reference","previous_headings":"","what":"Fast Fourier Transform — fft","title":"Fast Fourier Transform — fft","text":"Extends stats::fft() work mlx objects delegating standard R implementation inputs.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/fft.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fast Fourier Transform — fft","text":"","code":"fft(z, inverse = FALSE, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/fft.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fast Fourier Transform — fft","text":"z Input transform. May numeric, complex, mlx object. inverse Logical flag; TRUE compute inverse transform. ... Passed default method.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/fft.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fast Fourier Transform — fft","text":"mlx inputs, mlx object containing complex frequency coefficients; otherwise base R result.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/fft.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fast Fourier Transform — fft","text":"","code":"z <- as_mlx(c(1, 2, 3, 4)) fft(z) #> mlx array [4] #>   dtype: complex64 #>   device: gpu #>   values: #> [1] 10+0i -2+2i -2+0i -2-2i fft(z, inverse = TRUE) #> mlx array [4] #>   dtype: complex64 #>   device: gpu #>   values: #> [1] 10+0i -2-2i -2+0i -2+2i"},{"path":"https://hughjonesd.github.io/Rmlx/reference/grapes-times-grapes-.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Matrix multiplication for MLX arrays — %*%.mlx","title":"Matrix multiplication for MLX arrays — %*%.mlx","text":"Matrix multiplication MLX arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/grapes-times-grapes-.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matrix multiplication for MLX arrays — %*%.mlx","text":"","code":"# S3 method for class 'mlx' x %*% y"},{"path":"https://hughjonesd.github.io/Rmlx/reference/grapes-times-grapes-.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matrix multiplication for MLX arrays — %*%.mlx","text":"x, y numeric complex matrices vectors.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/grapes-times-grapes-.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Matrix multiplication for MLX arrays — %*%.mlx","text":"mlx object","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/grapes-times-grapes-.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Matrix multiplication for MLX arrays — %*%.mlx","text":"","code":"if (FALSE) { # \\dontrun{ x <- as_mlx(matrix(1:6, 2, 3)) y <- as_mlx(matrix(1:6, 3, 2)) x %*% y } # }"},{"path":"https://hughjonesd.github.io/Rmlx/reference/is.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Test if object is an MLX array — is.mlx","title":"Test if object is an MLX array — is.mlx","text":"Test object MLX array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/is.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test if object is an MLX array — is.mlx","text":"","code":"is.mlx(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/is.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test if object is an MLX array — is.mlx","text":"x Object test","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/is.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test if object is an MLX array — is.mlx","text":"Logical","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/is.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test if object is an MLX array — is.mlx","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) is.mlx(x) #> [1] TRUE"},{"path":"https://hughjonesd.github.io/Rmlx/reference/kronecker.html","id":null,"dir":"Reference","previous_headings":"","what":"Kronecker product dispatcher — kronecker","title":"Kronecker product dispatcher — kronecker","text":"Wrapper around base::kronecker() enables S3 dispatch mlx arrays delegating base R inputs. Ensures base kronecker() generic can dispatch S3 mlx objects S4 dispatch unavailable.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/kronecker.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kronecker product dispatcher — kronecker","text":"","code":"kronecker(X, Y, FUN = \"*\", make.dimnames = FALSE, ...)  kronecker.default(X, Y, FUN = \"*\", make.dimnames = FALSE, ...)  # S4 method for class 'mlx,mlx' kronecker(X, Y, FUN = \"*\", make.dimnames = FALSE, ...)  # S4 method for class 'mlx,ANY' kronecker(X, Y, FUN = \"*\", make.dimnames = FALSE, ...)  # S4 method for class 'ANY,mlx' kronecker(X, Y, FUN = \"*\", make.dimnames = FALSE, ...)  # S3 method for class 'mlx' kronecker(X, Y, FUN = \"*\", ..., make.dimnames = FALSE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/kronecker.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kronecker product dispatcher — kronecker","text":"X vector array. Y vector array. FUN Must '*' (functions unsupported MLX tensors). make.dimnames logical: provide dimnames product    dimnames X Y. ... Passed maintain signature compatibility base kronecker().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/kronecker.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Kronecker product dispatcher — kronecker","text":"mlx array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/length.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Get length of MLX array — length.mlx","title":"Get length of MLX array — length.mlx","text":"Get length MLX array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/length.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get length of MLX array — length.mlx","text":"","code":"# S3 method for class 'mlx' length(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/length.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get length of MLX array — length.mlx","text":"x mlx array, R array/matrix/vector converted via as_mlx().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/length.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get length of MLX array — length.mlx","text":"Total number elements","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/length.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get length of MLX array — length.mlx","text":"","code":"x <- as_mlx(matrix(1:6, 2, 3)) length(x) #> [1] 6"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mean.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean of MLX array elements — mean.mlx","title":"Mean of MLX array elements — mean.mlx","text":"Mean MLX array elements","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mean.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean of MLX array elements — mean.mlx","text":"","code":"# S3 method for class 'mlx' mean(x, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mean.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean of MLX array elements — mean.mlx","text":"x mlx array. ... Additional arguments (ignored)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mean.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean of MLX array elements — mean.mlx","text":"mlx scalar","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mean.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mean of MLX array elements — mean.mlx","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) mean(x) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 2.5"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Base R generics with mlx methods — mlx-methods","title":"Base R generics with mlx methods — mlx-methods","text":"Rmlx provides S3 methods number base R generics common operations keep working converting objects as_mlx(). main entry points :","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx-methods.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Base R generics with mlx methods — mlx-methods","text":"%*% matrix multiplication [ [<- extraction assignment Ops Math elementwise arithmetic math Summary reductions sum() max(); also mean(), length() .equal(). diag(), dim() dim<- .matrix(), .array(), .vector() conversion back base R cbind() rbind() binding arrays along rows columns; also abind() function modelled abind::abind(). rowMeans(), colMeans(), rowSums(), colSums() axis-wise summaries aperm(), t(), dim<- shape manipulation kronecker(), outer(), crossprod(), tcrossprod() linear algebra helpers fft(), chol(), chol2inv(), solve() numerical routines .finite(), .infinite() .nan()","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_addmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Fused matrix multiply and add for MLX arrays — mlx_addmm","title":"Fused matrix multiply and add for MLX arrays — mlx_addmm","text":"Computes beta * input + alpha * (mat1 %*% mat2) single MLX kernel. operands promoted common dtype/device prior evaluation.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_addmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fused matrix multiply and add for MLX arrays — mlx_addmm","text":"","code":"mlx_addmm(input, mat1, mat2, alpha = 1, beta = 1)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_addmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fused matrix multiply and add for MLX arrays — mlx_addmm","text":"input Matrix-like object providing additive term. mat1 Left matrix operand. mat2 Right matrix operand. alpha, beta Numeric scalars controlling fused linear combination.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_addmm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fused matrix multiply and add for MLX arrays — mlx_addmm","text":"mlx matrix shape input.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_addmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fused matrix multiply and add for MLX arrays — mlx_addmm","text":"","code":"if (FALSE) { # \\dontrun{ input <- as_mlx(diag(3)) mat1 <- as_mlx(matrix(rnorm(9), 3, 3)) mat2 <- as_mlx(matrix(rnorm(9), 3, 3)) mlx_addmm(input, mat1, mat2, alpha = 0.5, beta = 2) } # }"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_allclose.html","id":null,"dir":"Reference","previous_headings":"","what":"Test if all elements of two arrays are close — mlx_allclose","title":"Test if all elements of two arrays are close — mlx_allclose","text":"Returns boolean scalar indicating whether elements two arrays close within specified tolerances.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_allclose.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test if all elements of two arrays are close — mlx_allclose","text":"","code":"mlx_allclose(   a,   b,   rtol = 1e-05,   atol = 1e-08,   equal_nan = FALSE,   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_allclose.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test if all elements of two arrays are close — mlx_allclose","text":", b MLX arrays objects coercible MLX arrays rtol Relative tolerance (default: 1e-5) atol Absolute tolerance (default: 1e-8) equal_nan TRUE, NaN values considered equal (default: FALSE) device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Default: mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_allclose.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test if all elements of two arrays are close — mlx_allclose","text":"mlx array containing single boolean value","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_allclose.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Test if all elements of two arrays are close — mlx_allclose","text":"Two values considered close : abs(- b) <= (atol + rtol * abs(b)) function returns TRUE elements close. Supports NumPy-style broadcasting.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_allclose.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test if all elements of two arrays are close — mlx_allclose","text":"","code":"a <- as_mlx(c(1.0, 2.0, 3.0)) b <- as_mlx(c(1.0 + 1e-6, 2.0 + 1e-6, 3.0 + 1e-6)) as.logical(as.matrix(mlx_allclose(a, b)))  # TRUE #> [1] TRUE"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_arange.html","id":null,"dir":"Reference","previous_headings":"","what":"Numerical ranges on MLX devices — mlx_arange","title":"Numerical ranges on MLX devices — mlx_arange","text":"mlx_arange() mirrors base::seq() mlx arrays: creates evenly spaced values starting start (default 0), stepping step (default 1), stopping stop.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_arange.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Numerical ranges on MLX devices — mlx_arange","text":"","code":"mlx_arange(   stop,   start = NULL,   step = NULL,   dtype = c(\"float32\", \"float64\", \"int8\", \"int16\", \"int32\", \"int64\", \"uint8\", \"uint16\",     \"uint32\", \"uint64\"),   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_arange.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Numerical ranges on MLX devices — mlx_arange","text":"stop Exclusive upper bound. start Optional starting value (defaults 0). step Optional step size (defaults 1). dtype MLX dtype (\"float32\" \"float64\"). device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_arange.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Numerical ranges on MLX devices — mlx_arange","text":"1D mlx array.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_arange.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Numerical ranges on MLX devices — mlx_arange","text":"","code":"mlx_arange(5)                    # 0, 1, 2, 3, 4 #> mlx array [5] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 0 1 2 3 4 mlx_arange(5, start = 1, step = 2) # 1, 3 #> mlx array [2] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 1 3"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_argmax.html","id":null,"dir":"Reference","previous_headings":"","what":"Argmax and argmin on mlx arrays — mlx_argmax","title":"Argmax and argmin on mlx arrays — mlx_argmax","text":"Argmax argmin mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_argmax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Argmax and argmin on mlx arrays — mlx_argmax","text":"","code":"mlx_argmax(x, axis = NULL, drop = TRUE)  mlx_argmin(x, axis = NULL, drop = TRUE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_argmax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Argmax and argmin on mlx arrays — mlx_argmax","text":"x mlx array, R array/matrix/vector converted via as_mlx(). axis Optional axis operate (1-indexed like R). NULL, array flattened first. drop Logical; TRUE (default) reduced axis removed. Set FALSE keep axis length one.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_argmax.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Argmax and argmin on mlx arrays — mlx_argmax","text":"mlx array indices. Indices 1-based match R's conventions.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_argmax.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Argmax and argmin on mlx arrays — mlx_argmax","text":"","code":"x <- as_mlx(matrix(c(1, 5, 3, 2), 2, 2)) mlx_argmax(x) #> mlx array [] #>   dtype: int64 #>   device: gpu #>   values: #> [1] 3 mlx_argmax(x, axis = 1) #> mlx array [2] #>   dtype: int64 #>   device: gpu #>   values: #> [1] 2 1 mlx_argmin(x) #> mlx array [] #>   dtype: int64 #>   device: gpu #>   values: #> [1] 1"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_array_required.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters for Functions Requiring MLX Arrays — mlx_array_required","title":"Parameters for Functions Requiring MLX Arrays — mlx_array_required","text":"Parameters Functions Requiring MLX Arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_array_required.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters for Functions Requiring MLX Arrays — mlx_array_required","text":"x mlx array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_batch_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"Batch normalization — mlx_batch_norm","title":"Batch normalization — mlx_batch_norm","text":"Normalizes inputs across batch dimension.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_batch_norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Batch normalization — mlx_batch_norm","text":"","code":"mlx_batch_norm(   num_features,   eps = 1e-05,   momentum = 0.1,   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_batch_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Batch normalization — mlx_batch_norm","text":"num_features Number feature channels. eps Small constant numerical stability (default: 1e-5). momentum Momentum running statistics (default: 0.1). device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Default: mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_batch_norm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Batch normalization — mlx_batch_norm","text":"mlx_module applying batch normalization.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_batch_norm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Batch normalization — mlx_batch_norm","text":"","code":"set.seed(1) bn <- mlx_batch_norm(4) x <- as_mlx(matrix(rnorm(12), 3, 4)) mlx_forward(bn, x) #> mlx array [3 x 4] #>   dtype: float32 #>   device: gpu #>   values: #>            [,1]        [,2]       [,3]       [,4] #> [1,] -0.4556868  1.24383128 -1.0877743 -1.1186367 #> [2,]  1.3872330 -0.03912285  1.3256620  1.3086261 #> [3,] -0.9315463 -1.20470834 -0.2378886 -0.1899893"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_binary_cross_entropy.html","id":null,"dir":"Reference","previous_headings":"","what":"Binary cross-entropy loss — mlx_binary_cross_entropy","title":"Binary cross-entropy loss — mlx_binary_cross_entropy","text":"Computes binary cross-entropy loss predictions binary targets.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_binary_cross_entropy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binary cross-entropy loss — mlx_binary_cross_entropy","text":"","code":"mlx_binary_cross_entropy(   predictions,   targets,   reduction = c(\"mean\", \"sum\", \"none\") )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_binary_cross_entropy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Binary cross-entropy loss — mlx_binary_cross_entropy","text":"predictions Predicted probabilities mlx array (values [0,1]). targets Binary target values mlx array (0 1). reduction Type reduction: \"mean\" (default), \"sum\", \"none\".","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_binary_cross_entropy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Binary cross-entropy loss — mlx_binary_cross_entropy","text":"mlx array containing loss.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_binary_cross_entropy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Binary cross-entropy loss — mlx_binary_cross_entropy","text":"","code":"preds <- as_mlx(matrix(c(0.9, 0.2, 0.8), 3, 1)) targets <- as_mlx(matrix(c(1, 0, 1), 3, 1)) mlx_binary_cross_entropy(preds, targets) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 0.1838825"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_broadcast_arrays.html","id":null,"dir":"Reference","previous_headings":"","what":"Broadcast multiple arrays to a shared shape — mlx_broadcast_arrays","title":"Broadcast multiple arrays to a shared shape — mlx_broadcast_arrays","text":"mlx_broadcast_arrays() mirrors mlx.core.broadcast_arrays(), returning list inputs expanded common shape.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_broadcast_arrays.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Broadcast multiple arrays to a shared shape — mlx_broadcast_arrays","text":"","code":"mlx_broadcast_arrays(..., device = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_broadcast_arrays.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Broadcast multiple arrays to a shared shape — mlx_broadcast_arrays","text":"... One arrays (single list) convertible via as_mlx(). device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Default: mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_broadcast_arrays.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Broadcast multiple arrays to a shared shape — mlx_broadcast_arrays","text":"list broadcast mlx arrays.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_broadcast_arrays.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Broadcast multiple arrays to a shared shape — mlx_broadcast_arrays","text":"","code":"a <- as_mlx(matrix(1:3, nrow = 1)) b <- as_mlx(matrix(1:3, ncol = 1)) outs <- mlx_broadcast_arrays(a, b) lapply(outs, dim) #> [[1]] #> [1] 3 3 #>  #> [[2]] #> [1] 3 3 #>"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_broadcast_to.html","id":null,"dir":"Reference","previous_headings":"","what":"Broadcast an array to a new shape — mlx_broadcast_to","title":"Broadcast an array to a new shape — mlx_broadcast_to","text":"mlx_broadcast_to() mirrors mlx.core.broadcast_to(), repeating singleton dimensions without copying data.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_broadcast_to.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Broadcast an array to a new shape — mlx_broadcast_to","text":"","code":"mlx_broadcast_to(x, shape, device = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_broadcast_to.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Broadcast an array to a new shape — mlx_broadcast_to","text":"x mlx array. shape Integer vector describing broadcasted shape. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Default: mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_broadcast_to.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Broadcast an array to a new shape — mlx_broadcast_to","text":"mlx array requested dimensions.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_broadcast_to.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Broadcast an array to a new shape — mlx_broadcast_to","text":"","code":"x <- as_mlx(matrix(1:3, nrow = 1)) broadcast <- mlx_broadcast_to(x, c(5, 3)) dim(broadcast) #> [1] 5 3"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cholesky_inv.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute matrix inverse via Cholesky decomposition — mlx_cholesky_inv","title":"Compute matrix inverse via Cholesky decomposition — mlx_cholesky_inv","text":"Computes inverse positive definite matrix Cholesky factor. Note: x Cholesky factor (L U), original matrix.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cholesky_inv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute matrix inverse via Cholesky decomposition — mlx_cholesky_inv","text":"","code":"mlx_cholesky_inv(x, upper = FALSE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cholesky_inv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute matrix inverse via Cholesky decomposition — mlx_cholesky_inv","text":"x mlx array. upper Logical; TRUE, x upper triangular, otherwise lower triangular.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cholesky_inv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute matrix inverse via Cholesky decomposition — mlx_cholesky_inv","text":"inverse original matrix (^-1 = LL' = U'U).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cholesky_inv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute matrix inverse via Cholesky decomposition — mlx_cholesky_inv","text":"R-like interface, see chol2inv().","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cholesky_inv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute matrix inverse via Cholesky decomposition — mlx_cholesky_inv","text":"","code":"# Create a positive definite matrix A <- matrix(rnorm(9), 3, 3) A <- t(A) %*% A # Compute Cholesky factor L <- chol(A, pivot = FALSE, upper = FALSE) # Get inverse from Cholesky factor A_inv <- mlx_cholesky_inv(as_mlx(L))"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_clip.html","id":null,"dir":"Reference","previous_headings":"","what":"Clip mlx array values into a range — mlx_clip","title":"Clip mlx array values into a range — mlx_clip","text":"Clip mlx array values range","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_clip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clip mlx array values into a range — mlx_clip","text":"","code":"mlx_clip(x, min = NULL, max = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_clip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clip mlx array values into a range — mlx_clip","text":"x mlx array, R array/matrix/vector converted via as_mlx(). min, max Scalar bounds. Use NULL leave bound open.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_clip.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clip mlx array values into a range — mlx_clip","text":"mlx array values clipped [min, max].","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_clip.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Clip mlx array values into a range — mlx_clip","text":"","code":"if (FALSE) { # \\dontrun{ x <- as_mlx(rnorm(4)) mlx_clip(x, min = -1, max = 1) } # }"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_compile.html","id":null,"dir":"Reference","previous_headings":"","what":"Compile an MLX Function for Optimized Execution — mlx_compile","title":"Compile an MLX Function for Optimized Execution — mlx_compile","text":"Returns compiled version function traces optimizes computation graph first call, reuses compiled graph subsequent calls matching input shapes types.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_compile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compile an MLX Function for Optimized Execution — mlx_compile","text":"","code":"mlx_compile(f, shapeless = FALSE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_compile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compile an MLX Function for Optimized Execution — mlx_compile","text":"f R function takes MLX arrays arguments returns MLX array(s). function must pure (side effects) use MLX operations. shapeless Logical. TRUE, compiled function recompile input shapes change. However, changing input dtypes number dimensions still triggers recompilation. Default: FALSE","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_compile.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compile an MLX Function for Optimized Execution — mlx_compile","text":"compiled function signature f. first call slow (tracing compilation), subsequent calls much faster.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_compile.html","id":"how-compilation-works","dir":"Reference","previous_headings":"","what":"How Compilation Works","title":"Compile an MLX Function for Optimized Execution — mlx_compile","text":"call mlx_compile(f), returns new function immediately without tracing. actual compilation happens first call compiled function: First call: MLX traces function placeholder inputs, builds computation graph, optimizes (fusing operations, eliminating redundancy), caches result. slow. Subsequent calls: inputs shapes dtypes, MLX reuses cached compiled graph. fast. Recompilation: Occurs input shapes change (unless shapeless = TRUE), input dtypes change, number arguments changes.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_compile.html","id":"requirements-for-compiled-functions","dir":"Reference","previous_headings":"","what":"Requirements for Compiled Functions","title":"Compile an MLX Function for Optimized Execution — mlx_compile","text":"function must: Accept MLX arrays arguments Return MLX array(s) - either single mlx object list mlx objects Use MLX operations (conversion R) pure (side effects, external state modification) function : Print evaluate arrays execution (print(), .matrix(), .numeric(), [[ extraction, etc.) Use control flow based array values ((x > 0) x array) Modify external variables side effects Return non-MLX values","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_compile.html","id":"performance-benefits","dir":"Reference","previous_headings":"","what":"Performance Benefits","title":"Compile an MLX Function for Optimized Execution — mlx_compile","text":"Operation fusion: Combines multiple operations optimized kernels Memory reduction: Eliminates intermediate allocations Overhead reduction: Bypasses R/C++ call overhead fused operations Typical speedups range 2-10x operation-heavy functions.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_compile.html","id":"shapeless-compilation","dir":"Reference","previous_headings":"","what":"Shapeless Compilation","title":"Compile an MLX Function for Optimized Execution — mlx_compile","text":"Setting shapeless = TRUE allows compiled function handle varying input shapes without recompilation:   Shapeless mode sacrifices optimization opportunities avoids recompilation costs. Use processing variable-sized batches.","code":"# Regular compilation - recompiles for each new shape fast_fn <- mlx_compile(matmul_fn) fast_fn(mlx_zeros(c(10, 64)), weights)  # Compiles for shape (10, 64) fast_fn(mlx_zeros(c(20, 64)), weights)  # Recompiles for shape (20, 64)  # Shapeless compilation - compiles once fast_fn <- mlx_compile(matmul_fn, shapeless = TRUE) fast_fn(mlx_zeros(c(10, 64)), weights)  # Compiles once fast_fn(mlx_zeros(c(20, 64)), weights)  # No recompilation!"},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_compile.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compile an MLX Function for Optimized Execution — mlx_compile","text":"","code":"if (FALSE) { # \\dontrun{ # Simple example matmul_add <- function(x, w, b) {   (x %*% w) + b }  # Compile it (returns immediately, no tracing yet) fast_fn <- mlx_compile(matmul_add)  # First call: slow (traces and compiles) x <- mlx_rand_normal(c(32, 128)) w <- mlx_rand_normal(c(256, 128)) b <- mlx_rand_normal(c(256)) result <- fast_fn(x, w, b)  # Compiles during this call  # Subsequent calls: fast (uses cached graph) for (i in 1:1000) {   result <- fast_fn(batch_data[[i]], w, b)  # Very fast! }  # Multiple returns forward_and_norm <- function(x, w) {   y <- x %*% w   norm <- sqrt(sum(y * y))   list(y, norm)  # Return list of mlx objects }  compiled_fn <- mlx_compile(forward_and_norm) results <- compiled_fn(x, w)  # Returns list(y, norm) } # }"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_compile_control.html","id":null,"dir":"Reference","previous_headings":"","what":"Control Global Compilation Behavior — mlx_disable_compile","title":"Control Global Compilation Behavior — mlx_disable_compile","text":"mlx_disable_compile() prevents compilation globally. Compiled functions execute without optimization. mlx_enable_compile() enables compilation (overrides MLX_DISABLE_COMPILE environment variable).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_compile_control.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Control Global Compilation Behavior — mlx_disable_compile","text":"","code":"mlx_disable_compile()  mlx_enable_compile()"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_compile_control.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Control Global Compilation Behavior — mlx_disable_compile","text":"Invisibly returns NULL.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_compile_control.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Control Global Compilation Behavior — mlx_disable_compile","text":"functions control whether MLX compilation enabled globally. useful debugging (check compilation causing issues) benchmarking (measure compilation overhead vs speedup). can also disable compilation setting MLX_DISABLE_COMPILE environment variable loading package.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_compile_control.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Control Global Compilation Behavior — mlx_disable_compile","text":"","code":"if (FALSE) { # \\dontrun{ # Disable compilation for debugging mlx_disable_compile() result <- compiled_fn(x)  # Runs without optimization  # Re-enable compilation mlx_enable_compile() result <- compiled_fn(x)  # Runs with optimization } # }"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_contiguous.html","id":null,"dir":"Reference","previous_headings":"","what":"Ensure contiguous memory layout — mlx_contiguous","title":"Ensure contiguous memory layout — mlx_contiguous","text":"Returns copy x contiguous strides requested device stream.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_contiguous.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ensure contiguous memory layout — mlx_contiguous","text":"","code":"mlx_contiguous(x, device = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_contiguous.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ensure contiguous memory layout — mlx_contiguous","text":"x mlx array. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Default: mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_contiguous.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ensure contiguous memory layout — mlx_contiguous","text":"mlx array backed contiguous storage specified device.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_contiguous.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ensure contiguous memory layout — mlx_contiguous","text":"","code":"x <- mlx_swapaxes(as_mlx(matrix(1:4, 2, 2)), axis1 = 1, axis2 = 2) y <- mlx_contiguous(x) identical(as.array(x), as.array(y)) #> [1] TRUE"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv1d.html","id":null,"dir":"Reference","previous_headings":"","what":"1D Convolution — mlx_conv1d","title":"1D Convolution — mlx_conv1d","text":"Applies 1D convolution input signal.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"1D Convolution — mlx_conv1d","text":"","code":"mlx_conv1d(   input,   weight,   stride = 1L,   padding = 0L,   dilation = 1L,   groups = 1L,   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"1D Convolution — mlx_conv1d","text":"input Input mlx array. Shape depends dimensionality (see individual functions). weight Weight array. Shape depends dimensionality (see individual functions). stride Stride convolution. Can scalar vector (length depends dimensionality). Default: 1 1D, c(1,1) 2D, c(1,1,1) 3D. padding Amount zero padding. Can scalar vector (length depends dimensionality). Default: 0 1D, c(0,0) 2D, c(0,0,0) 3D. dilation Spacing kernel elements. Can scalar vector (length depends dimensionality). Default: 1 1D, c(1,1) 2D, c(1,1,1) 3D. groups Number blocked connections input output channels. Default: 1. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Default: mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv1d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"1D Convolution — mlx_conv1d","text":"Convolved output array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv1d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"1D Convolution — mlx_conv1d","text":"Input shape (N, L, C_in) N batch size, L sequence length, C_in number input channels. Weight shape (C_out, kernel_size, C_in).","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv2d.html","id":null,"dir":"Reference","previous_headings":"","what":"2D Convolution — mlx_conv2d","title":"2D Convolution — mlx_conv2d","text":"Applies 2D convolution input image.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"2D Convolution — mlx_conv2d","text":"","code":"mlx_conv2d(   input,   weight,   stride = c(1L, 1L),   padding = c(0L, 0L),   dilation = c(1L, 1L),   groups = 1L,   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"2D Convolution — mlx_conv2d","text":"input Input mlx array. Shape depends dimensionality (see individual functions). weight Weight array. Shape depends dimensionality (see individual functions). stride Stride convolution. Can scalar vector (length depends dimensionality). Default: 1 1D, c(1,1) 2D, c(1,1,1) 3D. padding Amount zero padding. Can scalar vector (length depends dimensionality). Default: 0 1D, c(0,0) 2D, c(0,0,0) 3D. dilation Spacing kernel elements. Can scalar vector (length depends dimensionality). Default: 1 1D, c(1,1) 2D, c(1,1,1) 3D. groups Number blocked connections input output channels. Default: 1. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Default: mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv2d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"2D Convolution — mlx_conv2d","text":"Convolved output array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv2d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"2D Convolution — mlx_conv2d","text":"Input shape (N, H, W, C_in) N batch size, H W height width, C_in number input channels. Weight shape (C_out, kernel_h, kernel_w, C_in).","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv2d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"2D Convolution — mlx_conv2d","text":"","code":"# Create a simple 2D convolution input <- as_mlx(array(rnorm(1*28*28*3), dim = c(1, 28, 28, 3)))  # Batch of 1 RGB image weight <- as_mlx(array(rnorm(16*3*3*3), dim = c(16, 3, 3, 3)))  # 16 filters, 3x3 kernel output <- mlx_conv2d(input, weight, stride = c(1, 1), padding = c(1, 1))"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv3d.html","id":null,"dir":"Reference","previous_headings":"","what":"3D Convolution — mlx_conv3d","title":"3D Convolution — mlx_conv3d","text":"Applies 3D convolution input volume.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"3D Convolution — mlx_conv3d","text":"","code":"mlx_conv3d(   input,   weight,   stride = c(1L, 1L, 1L),   padding = c(0L, 0L, 0L),   dilation = c(1L, 1L, 1L),   groups = 1L,   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"3D Convolution — mlx_conv3d","text":"input Input mlx array. Shape depends dimensionality (see individual functions). weight Weight array. Shape depends dimensionality (see individual functions). stride Stride convolution. Can scalar vector (length depends dimensionality). Default: 1 1D, c(1,1) 2D, c(1,1,1) 3D. padding Amount zero padding. Can scalar vector (length depends dimensionality). Default: 0 1D, c(0,0) 2D, c(0,0,0) 3D. dilation Spacing kernel elements. Can scalar vector (length depends dimensionality). Default: 1 1D, c(1,1) 2D, c(1,1,1) 3D. groups Number blocked connections input output channels. Default: 1. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Default: mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv3d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"3D Convolution — mlx_conv3d","text":"Convolved output array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv3d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"3D Convolution — mlx_conv3d","text":"Input shape (N, D, H, W, C_in) N batch size, D, H, W depth, height width, C_in number input channels. Weight shape (C_out, kernel_d, kernel_h, kernel_w, C_in).","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose1d.html","id":null,"dir":"Reference","previous_headings":"","what":"1D Transposed Convolution — mlx_conv_transpose1d","title":"1D Transposed Convolution — mlx_conv_transpose1d","text":"Applies 1D transposed convolution (also called deconvolution) input signal. Transposed convolutions used upsample spatial dimensions input.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"1D Transposed Convolution — mlx_conv_transpose1d","text":"","code":"mlx_conv_transpose1d(   input,   weight,   stride = 1L,   padding = 0L,   dilation = 1L,   output_padding = 0L,   groups = 1L,   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"1D Transposed Convolution — mlx_conv_transpose1d","text":"input Input mlx array. Shape depends dimensionality (see individual functions). weight Weight array. Shape depends dimensionality (see individual functions). stride Stride convolution. Can scalar vector (length depends dimensionality). Default: 1 1D, c(1,1) 2D, c(1,1,1) 3D. padding Amount zero padding. Can scalar vector (length depends dimensionality). Default: 0 1D, c(0,0) 2D, c(0,0,0) 3D. dilation Spacing kernel elements. Can scalar vector (length depends dimensionality). Default: 1 1D, c(1,1) 2D, c(1,1,1) 3D. output_padding Additional size added output shape. Default: 0 groups Number blocked connections input output channels. Default: 1. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Default: mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose1d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"1D Transposed Convolution — mlx_conv_transpose1d","text":"mlx array transposed convolution result","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose1d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"1D Transposed Convolution — mlx_conv_transpose1d","text":"Input shape (batch, length, in_channels) 'NWC' layout. Weight shape (out_channels, kernel_size, in_channels).","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose2d.html","id":null,"dir":"Reference","previous_headings":"","what":"2D Transposed Convolution — mlx_conv_transpose2d","title":"2D Transposed Convolution — mlx_conv_transpose2d","text":"Applies 2D transposed convolution (also called deconvolution) input signal. Transposed convolutions commonly used image generation upsampling tasks.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"2D Transposed Convolution — mlx_conv_transpose2d","text":"","code":"mlx_conv_transpose2d(   input,   weight,   stride = c(1L, 1L),   padding = c(0L, 0L),   dilation = c(1L, 1L),   output_padding = c(0L, 0L),   groups = 1L,   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"2D Transposed Convolution — mlx_conv_transpose2d","text":"input Input mlx array. Shape depends dimensionality (see individual functions). weight Weight array. Shape depends dimensionality (see individual functions). stride Stride convolution. Can scalar vector (length depends dimensionality). Default: 1 1D, c(1,1) 2D, c(1,1,1) 3D. padding Amount zero padding. Can scalar vector (length depends dimensionality). Default: 0 1D, c(0,0) 2D, c(0,0,0) 3D. dilation Spacing kernel elements. Can scalar vector (length depends dimensionality). Default: 1 1D, c(1,1) 2D, c(1,1,1) 3D. output_padding Additional size added output shape. Can scalar length-2 vector. Default: c(0, 0) groups Number blocked connections input output channels. Default: 1. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Default: mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose2d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"2D Transposed Convolution — mlx_conv_transpose2d","text":"mlx array transposed convolution result","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose2d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"2D Transposed Convolution — mlx_conv_transpose2d","text":"Input shape (batch, height, width, in_channels) 'NHWC' layout. Weight shape (out_channels, kernel_h, kernel_w, in_channels).","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose3d.html","id":null,"dir":"Reference","previous_headings":"","what":"3D Transposed Convolution — mlx_conv_transpose3d","title":"3D Transposed Convolution — mlx_conv_transpose3d","text":"Applies 3D transposed convolution (also called deconvolution) input signal. Useful 3D volumetric data upsampling, medical imaging video generation.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"3D Transposed Convolution — mlx_conv_transpose3d","text":"","code":"mlx_conv_transpose3d(   input,   weight,   stride = c(1L, 1L, 1L),   padding = c(0L, 0L, 0L),   dilation = c(1L, 1L, 1L),   output_padding = c(0L, 0L, 0L),   groups = 1L,   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"3D Transposed Convolution — mlx_conv_transpose3d","text":"input Input mlx array. Shape depends dimensionality (see individual functions). weight Weight array. Shape depends dimensionality (see individual functions). stride Stride convolution. Can scalar vector (length depends dimensionality). Default: 1 1D, c(1,1) 2D, c(1,1,1) 3D. padding Amount zero padding. Can scalar vector (length depends dimensionality). Default: 0 1D, c(0,0) 2D, c(0,0,0) 3D. dilation Spacing kernel elements. Can scalar vector (length depends dimensionality). Default: 1 1D, c(1,1) 2D, c(1,1,1) 3D. output_padding Additional size added output shape. Can scalar length-3 vector. Default: c(0, 0, 0) groups Number blocked connections input output channels. Default: 1. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Default: mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose3d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"3D Transposed Convolution — mlx_conv_transpose3d","text":"mlx array transposed convolution result","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose3d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"3D Transposed Convolution — mlx_conv_transpose3d","text":"Input shape (batch, depth, height, width, in_channels) 'NDHWC' layout. Weight shape (out_channels, kernel_d, kernel_h, kernel_w, in_channels).","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_creation_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Common parameters for MLX array creation — mlx_creation_params","title":"Common parameters for MLX array creation — mlx_creation_params","text":"Common parameters MLX array creation","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_creation_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Common parameters for MLX array creation — mlx_creation_params","text":"dim Integer vector specifying array shape/dimensions. dtype Character string specifying MLX data type. Common options: Floating point: \"float32\", \"float64\" Integer: \"int8\", \"int16\", \"int32\", \"int64\", \"uint8\", \"uint16\", \"uint32\", \"uint64\" : \"bool\", \"complex64\" Supported types vary function; see individual function documentation. device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cross.html","id":null,"dir":"Reference","previous_headings":"","what":"Vector cross product with mlx arrays — mlx_cross","title":"Vector cross product with mlx arrays — mlx_cross","text":"Vector cross product mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cross.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Vector cross product with mlx arrays — mlx_cross","text":"","code":"mlx_cross(a, b, axis = -1L)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cross.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Vector cross product with mlx arrays — mlx_cross","text":", b Input mlx arrays containing 3D vectors. axis Axis along compute cross product (1-indexed, default last).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cross.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Vector cross product with mlx arrays — mlx_cross","text":"mlx array cross products.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cross.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Vector cross product with mlx arrays — mlx_cross","text":"","code":"u <- as_mlx(c(1, 0, 0)) v <- as_mlx(c(0, 1, 0)) mlx_cross(u, v) #> mlx array [3] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 0 0 1"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cross_entropy.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-entropy loss — mlx_cross_entropy","title":"Cross-entropy loss — mlx_cross_entropy","text":"Computes cross-entropy loss multi-class classification.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cross_entropy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-entropy loss — mlx_cross_entropy","text":"","code":"mlx_cross_entropy(logits, targets, reduction = c(\"mean\", \"sum\", \"none\"))"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cross_entropy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-entropy loss — mlx_cross_entropy","text":"logits Unnormalized predictions (logits) mlx array. targets Target class indices mlx array integer vector. reduction Type reduction: \"mean\" (default), \"sum\", \"none\".","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cross_entropy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-entropy loss — mlx_cross_entropy","text":"mlx array containing loss.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cross_entropy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-entropy loss — mlx_cross_entropy","text":"","code":"# Logits for 3 samples, 4 classes logits <- as_mlx(matrix(rnorm(12), 3, 4)) targets <- as_mlx(c(1, 3, 2))  # 0-indexed class labels mlx_cross_entropy(logits, targets) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 1.120893"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cumsum.html","id":null,"dir":"Reference","previous_headings":"","what":"Cumulative sum and product — mlx_cumsum","title":"Cumulative sum and product — mlx_cumsum","text":"Compute cumulative sums products along axis.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cumsum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cumulative sum and product — mlx_cumsum","text":"","code":"mlx_cumsum(x, axis = NULL, reverse = FALSE, inclusive = TRUE)  mlx_cumprod(x, axis = NULL, reverse = FALSE, inclusive = TRUE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cumsum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cumulative sum and product — mlx_cumsum","text":"x mlx array. axis Optional axis along compute cumulative operation. NULL (default), array flattened first. reverse TRUE, compute reverse order. inclusive TRUE (default), include current element cumulative operation. FALSE, cumulative operation exclusive (starts identity element).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cumsum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cumulative sum and product — mlx_cumsum","text":"mlx array cumulative sums products.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cumsum.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cumulative sum and product — mlx_cumsum","text":"","code":"x <- as_mlx(1:5) mlx_cumsum(x)  # [1, 3, 6, 10, 15] #> mlx array [5] #>   dtype: float32 #>   device: gpu #>   values: #> [1]  1  3  6 10 15  mat <- as_mlx(matrix(1:12, 3, 4)) mlx_cumsum(mat, axis = 1)  # cumsum down rows #> mlx array [3 x 4] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] [,4] #> [1,]    1    4    7   10 #> [2,]    3    9   15   21 #> [3,]    6   15   24   33"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_default_device.html","id":null,"dir":"Reference","previous_headings":"","what":"Get or set default MLX device — mlx_default_device","title":"Get or set default MLX device — mlx_default_device","text":"Get set default MLX device","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_default_device.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get or set default MLX device — mlx_default_device","text":"","code":"mlx_default_device(value)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_default_device.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get or set default MLX device — mlx_default_device","text":"value New default device (\"gpu\" \"cpu\"). missing, returns current default.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_default_device.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get or set default MLX device — mlx_default_device","text":"Current default device (character)","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_default_device.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get or set default MLX device — mlx_default_device","text":"","code":"mlx_default_device()  # Get current default #> [1] \"gpu\" mlx_default_device(\"cpu\")  # Set to CPU #> [1] \"cpu\" mlx_default_device(\"gpu\")  # Set back to GPU #> [1] \"gpu\" mlx_default_device() #> [1] \"gpu\""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_degrees.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert between radians and degrees — mlx_degrees","title":"Convert between radians and degrees — mlx_degrees","text":"mlx_degrees() mlx_radians() mirror mlx.core.degrees() mlx.core.radians(), converting angular values elementwise using MLX kernels.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_degrees.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert between radians and degrees — mlx_degrees","text":"","code":"mlx_degrees(x)  mlx_radians(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_degrees.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert between radians and degrees — mlx_degrees","text":"x mlx array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_degrees.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert between radians and degrees — mlx_degrees","text":"mlx array transformed angular units.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_degrees.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert between radians and degrees — mlx_degrees","text":"","code":"x <- as_mlx(pi / 2) as.matrix(mlx_degrees(x))  # 90 #> [1] 90 angles <- mlx_radians(as_mlx(c(0, 90, 180))) as.matrix(angles) #> [1] 0.000000 1.570796 3.141593"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dequantize.html","id":null,"dir":"Reference","previous_headings":"","what":"Dequantize a Matrix — mlx_dequantize","title":"Dequantize a Matrix — mlx_dequantize","text":"Reconstructs approximate floating-point matrix quantized representation produced mlx_quantize().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dequantize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dequantize a Matrix — mlx_dequantize","text":"","code":"mlx_dequantize(   w,   scales,   biases = NULL,   group_size = 64L,   bits = 4L,   mode = \"affine\",   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dequantize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dequantize a Matrix — mlx_dequantize","text":"w mlx array (quantized weight matrix) scales mlx array (quantization scales) biases optional mlx array (quantization biases affine mode). Default: NULL group_size group size used quantization. Default: 64 bits number bits used quantization. Default: 4 mode quantization mode used: \"affine\" \"mxfp4\". Default: \"affine\" device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Default: mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dequantize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Dequantize a Matrix — mlx_dequantize","text":"mlx array dequantized (approximate) floating-point weights","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dequantize.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Dequantize a Matrix — mlx_dequantize","text":"Dequantization unpacks low-precision quantized weights applies scales (biases) reconstruct approximate floating-point values. Note precision lost quantization recovered.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dequantize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dequantize a Matrix — mlx_dequantize","text":"","code":"if (FALSE) { # \\dontrun{ w <- mlx_random_normal(c(512, 256)) quant <- mlx_quantize(w) w_reconstructed <- mlx_dequantize(quant$w_q, quant$scales, quant$biases) } # }"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_diagonal.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract diagonal or construct diagonal matrix for mlx arrays — diag.mlx","title":"Extract diagonal or construct diagonal matrix for mlx arrays — diag.mlx","text":"Extract diagonal matrix construct diagonal matrix vector.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_diagonal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract diagonal or construct diagonal matrix for mlx arrays — diag.mlx","text":"","code":"# S3 method for class 'mlx' diag(x, nrow, ncol, names = TRUE)  mlx_diagonal(x, offset = 0L, axis1 = 1L, axis2 = 2L)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_diagonal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract diagonal or construct diagonal matrix for mlx arrays — diag.mlx","text":"x mlx array. 1D, creates diagonal matrix. 2D higher, extracts diagonal. nrow, ncol Diagonal offset (nrow ; ncol ignored). diag.mlx() R interface mlx_diagonal() semantics base::diag(). names Unused. offset Diagonal offset (0 main diagonal, positive , negative ). axis1, axis2 multi-dimensional arrays, axes define 2D planes (1-indexed).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_diagonal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract diagonal or construct diagonal matrix for mlx arrays — diag.mlx","text":"mlx array.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_diagonal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract diagonal or construct diagonal matrix for mlx arrays — diag.mlx","text":"","code":"# Extract diagonal x <- as_mlx(matrix(1:9, 3, 3)) mlx_diagonal(x) #> mlx array [3] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 1 5 9 if (FALSE) { # \\dontrun{ # Create diagonal matrix (not yet supported for 1D input) v <- as_mlx(c(1, 2, 3)) mlx_diagonal(v) } # }"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dim.html","id":null,"dir":"Reference","previous_headings":"","what":"Get dimensions helper — mlx_dim","title":"Get dimensions helper — mlx_dim","text":"Get dimensions helper","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get dimensions helper — mlx_dim","text":"","code":"mlx_dim(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get dimensions helper — mlx_dim","text":"x mlx array, R array/matrix/vector converted via as_mlx().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get dimensions helper — mlx_dim","text":"Dimensions","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get dimensions helper — mlx_dim","text":"","code":"x <- as_mlx(matrix(1:6, 2, 3)) mlx_dim(x) #> [1] 2 3"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dropout.html","id":null,"dir":"Reference","previous_headings":"","what":"Dropout layer — mlx_dropout","title":"Dropout layer — mlx_dropout","text":"Dropout layer","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dropout.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dropout layer — mlx_dropout","text":"","code":"mlx_dropout(p = 0.5)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dropout.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dropout layer — mlx_dropout","text":"p Probability dropping element (default: 0.5).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dropout.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Dropout layer — mlx_dropout","text":"mlx_module applying dropout training.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dropout.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dropout layer — mlx_dropout","text":"","code":"set.seed(1) dropout <- mlx_dropout(p = 0.3) x <- as_mlx(matrix(1:12, 3, 4)) mlx_forward(dropout, x) #> mlx array [3 x 4] #>   dtype: float32 #>   device: gpu #>   values: #>          [,1]     [,2]     [,3]     [,4] #> [1,] 0.000000 0.000000 10.00000 14.28571 #> [2,] 2.857143 7.142857 11.42857 15.71429 #> [3,] 4.285714 0.000000 12.85714  0.00000"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dtype.html","id":null,"dir":"Reference","previous_headings":"","what":"Get data type helper — mlx_dtype","title":"Get data type helper — mlx_dtype","text":"Get data type helper","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dtype.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get data type helper — mlx_dtype","text":"","code":"mlx_dtype(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dtype.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get data type helper — mlx_dtype","text":"x mlx array, R array/matrix/vector converted via as_mlx().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dtype.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get data type helper — mlx_dtype","text":"Data type string","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dtype.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get data type helper — mlx_dtype","text":"","code":"x <- as_mlx(matrix(1:6, 2, 3)) mlx_dtype(x) #> [1] \"float32\""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eig.html","id":null,"dir":"Reference","previous_headings":"","what":"Eigen decomposition for mlx arrays — mlx_eig","title":"Eigen decomposition for mlx arrays — mlx_eig","text":"Eigen decomposition mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eig.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Eigen decomposition for mlx arrays — mlx_eig","text":"","code":"mlx_eig(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eig.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Eigen decomposition for mlx arrays — mlx_eig","text":"x mlx matrix (2-dimensional array).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eig.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Eigen decomposition for mlx arrays — mlx_eig","text":"list components values vectors, mlx arrays.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eig.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Eigen decomposition for mlx arrays — mlx_eig","text":"","code":"x <- as_mlx(matrix(c(2, -1, 0, 2), 2, 2)) eig <- mlx_eig(x) eig$values #> mlx array [2] #>   dtype: complex64 #>   device: gpu #>   values: #> [1] 2+0i 2+0i eig$vectors #> mlx array [2 x 2] #>   dtype: complex64 #>   device: gpu #>   values: #>                 [,1] [,2] #> [1,] 2.384186e-07+0i 0+0i #> [2,] 1.000000e+00+0i 1+0i"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigh.html","id":null,"dir":"Reference","previous_headings":"","what":"Eigen decomposition of Hermitian mlx arrays — mlx_eigh","title":"Eigen decomposition of Hermitian mlx arrays — mlx_eigh","text":"Eigen decomposition Hermitian mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Eigen decomposition of Hermitian mlx arrays — mlx_eigh","text":"","code":"mlx_eigh(x, uplo = c(\"L\", \"U\"))"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Eigen decomposition of Hermitian mlx arrays — mlx_eigh","text":"x mlx matrix (2-dimensional array). uplo Character string indicating triangle use (\"L\" \"U\").","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Eigen decomposition of Hermitian mlx arrays — mlx_eigh","text":"list components values vectors.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Eigen decomposition of Hermitian mlx arrays — mlx_eigh","text":"","code":"x <- as_mlx(matrix(c(2, 1, 1, 3), 2, 2)) mlx_eigh(x) #> $values #> mlx array [2] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 1.381966 3.618034 #>  #> $vectors #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>            [,1]      [,2] #> [1,] -0.8506508 0.5257311 #> [2,]  0.5257311 0.8506508 #>"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigvals.html","id":null,"dir":"Reference","previous_headings":"","what":"Eigenvalues of mlx arrays — mlx_eigvals","title":"Eigenvalues of mlx arrays — mlx_eigvals","text":"Eigenvalues mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigvals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Eigenvalues of mlx arrays — mlx_eigvals","text":"","code":"mlx_eigvals(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigvals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Eigenvalues of mlx arrays — mlx_eigvals","text":"x mlx matrix (2-dimensional array).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigvals.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Eigenvalues of mlx arrays — mlx_eigvals","text":"mlx array containing eigenvalues.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigvals.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Eigenvalues of mlx arrays — mlx_eigvals","text":"","code":"x <- as_mlx(matrix(c(3, 1, 0, 2), 2, 2)) mlx_eigvals(x) #> mlx array [2] #>   dtype: complex64 #>   device: gpu #>   values: #> [1] 3+0i 2+0i"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigvalsh.html","id":null,"dir":"Reference","previous_headings":"","what":"Eigenvalues of Hermitian mlx arrays — mlx_eigvalsh","title":"Eigenvalues of Hermitian mlx arrays — mlx_eigvalsh","text":"Eigenvalues Hermitian mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigvalsh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Eigenvalues of Hermitian mlx arrays — mlx_eigvalsh","text":"","code":"mlx_eigvalsh(x, uplo = c(\"L\", \"U\"))"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigvalsh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Eigenvalues of Hermitian mlx arrays — mlx_eigvalsh","text":"x mlx matrix (2-dimensional array). uplo Character string indicating triangle use (\"L\" \"U\").","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigvalsh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Eigenvalues of Hermitian mlx arrays — mlx_eigvalsh","text":"mlx array containing eigenvalues.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigvalsh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Eigenvalues of Hermitian mlx arrays — mlx_eigvalsh","text":"","code":"x <- as_mlx(matrix(c(2, 1, 1, 3), 2, 2)) mlx_eigvalsh(x) #> mlx array [2] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 1.381966 3.618034"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_embedding.html","id":null,"dir":"Reference","previous_headings":"","what":"Embedding layer — mlx_embedding","title":"Embedding layer — mlx_embedding","text":"Maps discrete tokens continuous vectors.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_embedding.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Embedding layer — mlx_embedding","text":"","code":"mlx_embedding(num_embeddings, embedding_dim, device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_embedding.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Embedding layer — mlx_embedding","text":"num_embeddings Size vocabulary. embedding_dim Dimension embedding vectors. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Default: mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_embedding.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Embedding layer — mlx_embedding","text":"mlx_module token embeddings.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_embedding.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Embedding layer — mlx_embedding","text":"","code":"set.seed(1) emb <- mlx_embedding(num_embeddings = 100, embedding_dim = 16) # Token indices (0-indexed) tokens <- as_mlx(matrix(c(5, 10, 3, 7), 2, 2)) mlx_forward(emb, tokens) #> mlx array [2 x 2 x 16] #>   dtype: float32 #>   device: gpu #>   (64 elements, not shown)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eval.html","id":null,"dir":"Reference","previous_headings":"","what":"Force evaluation of lazy MLX operations — mlx_eval","title":"Force evaluation of lazy MLX operations — mlx_eval","text":"Force evaluation lazy MLX operations","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Force evaluation of lazy MLX operations — mlx_eval","text":"","code":"mlx_eval(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Force evaluation of lazy MLX operations — mlx_eval","text":"x mlx array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Force evaluation of lazy MLX operations — mlx_eval","text":"input object (invisibly)","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eval.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Force evaluation of lazy MLX operations — mlx_eval","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) mlx_eval(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_expand_dims.html","id":null,"dir":"Reference","previous_headings":"","what":"Insert singleton dimensions — mlx_expand_dims","title":"Insert singleton dimensions — mlx_expand_dims","text":"Insert singleton dimensions","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_expand_dims.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Insert singleton dimensions — mlx_expand_dims","text":"","code":"mlx_expand_dims(x, axis)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_expand_dims.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Insert singleton dimensions — mlx_expand_dims","text":"x mlx array. axis Integer vector axis positions (1-indexed) new singleton dimensions inserted.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_expand_dims.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Insert singleton dimensions — mlx_expand_dims","text":"mlx array additional dimensions length one.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_expand_dims.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Insert singleton dimensions — mlx_expand_dims","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) mlx_expand_dims(x, axis = 1) #> mlx array [1 x 2 x 2] #>   dtype: float32 #>   device: gpu #>   (4 elements, not shown)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eye.html","id":null,"dir":"Reference","previous_headings":"","what":"Identity-like matrices on MLX devices — mlx_eye","title":"Identity-like matrices on MLX devices — mlx_eye","text":"Identity-like matrices MLX devices","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eye.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identity-like matrices on MLX devices — mlx_eye","text":"","code":"mlx_eye(   n,   m = n,   k = 0L,   dtype = c(\"float32\", \"float64\"),   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eye.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identity-like matrices on MLX devices — mlx_eye","text":"n Number rows. m Optional number columns (defaults n). k Diagonal index: 0 main diagonal, positive values shift upward, negative values shift downward. dtype MLX dtype use. One \"float32\", \"float64\", \"int8\", \"int16\", \"int32\", \"int64\", \"uint8\", \"uint16\", \"uint32\", \"uint64\", \"bool\", \"complex64\". device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eye.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identity-like matrices on MLX devices — mlx_eye","text":"mlx matrix ones selected diagonal zeros elsewhere.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eye.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identity-like matrices on MLX devices — mlx_eye","text":"","code":"eye <- mlx_eye(3) upper_eye <- mlx_eye(3, k = 1)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_fft.html","id":null,"dir":"Reference","previous_headings":"","what":"Fast Fourier transforms for MLX arrays — mlx_fft","title":"Fast Fourier transforms for MLX arrays — mlx_fft","text":"mlx_fft(), mlx_fft2(), mlx_fftn() wrap MLX FFT kernels R-friendly defaults. Inputs converted as_mlx() results returned mlx arrays.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_fft.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fast Fourier transforms for MLX arrays — mlx_fft","text":"","code":"mlx_fft(x, axis = -1L, inverse = FALSE, device = NULL)  mlx_fft2(x, axes = c(-2L, -1L), inverse = FALSE, device = NULL)  mlx_fftn(x, axes = NULL, inverse = FALSE, device = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_fft.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fast Fourier transforms for MLX arrays — mlx_fft","text":"x Array-like object coercible mlx. axis Optional integer axis (1-indexed, negatives count end) one-dimensional transform. inverse Logical flag; TRUE, compute inverse transform. inverse un-normalised match base R's fft(), .e. results multiplied product transformed axis lengths. device Target device stream. Defaults input array's device (mlx_default_device() non-mlx inputs). axes Optional integer vector axes multi-dimensional transforms. NULL, MLX uses axes.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_fft.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fast Fourier transforms for MLX arrays — mlx_fft","text":"mlx array containing complex frequency coefficients.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_fft.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fast Fourier transforms for MLX arrays — mlx_fft","text":"","code":"x <- as_mlx(c(1, 2, 3, 4)) mlx_fft(x) #> mlx array [4] #>   dtype: complex64 #>   device: gpu #>   values: #> [1] 10+0i -2+2i -2+0i -2-2i mlx_fft(x, inverse = TRUE) #> mlx array [4] #>   dtype: complex64 #>   device: gpu #>   values: #> [1] 10+0i -2-2i -2+0i -2+2i mat <- matrix(1:9, 3, 3) mlx_fft2(as_mlx(mat)) #> mlx array [3 x 3] #>   dtype: complex64 #>   device: gpu #>   values: #>                [,1]            [,2]            [,3] #> [1,] 45.0+0.000000i -13.5+7.794229i -13.5-7.794229i #> [2,] -4.5+2.598076i   0.0+0.000000i   0.0+0.000000i #> [3,] -4.5-2.598076i   0.0+0.000000i   0.0+0.000000i arr <- as_mlx(array(1:8, dim = c(2, 2, 2))) mlx_fftn(arr) #> mlx array [2 x 2 x 2] #>   dtype: complex64 #>   device: gpu #>   (8 elements, not shown)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_flatten.html","id":null,"dir":"Reference","previous_headings":"","what":"Flatten axes of an mlx array — mlx_flatten","title":"Flatten axes of an mlx array — mlx_flatten","text":"mlx_flatten() mirrors mlx.core.flatten(), collapsing contiguous range axes single dimension.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_flatten.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flatten axes of an mlx array — mlx_flatten","text":"","code":"mlx_flatten(x, start_axis = 1L, end_axis = -1L)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_flatten.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flatten axes of an mlx array — mlx_flatten","text":"x mlx array. start_axis First axis (1-indexed, negatives count end) flattened range. end_axis Last axis (1-indexed, negatives count end) flattened range.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_flatten.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flatten axes of an mlx array — mlx_flatten","text":"mlx array selected axes collapsed.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_flatten.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flatten axes of an mlx array — mlx_flatten","text":"","code":"x <- as_mlx(array(1:12, dim = c(2, 3, 2))) mlx_flatten(x) #> mlx array [12] #>   dtype: float32 #>   device: gpu #>   values: #>  [1]  1  7  3  9  5 11  2  8  4 10  6 12 mlx_flatten(x, start_axis = 2, end_axis = 3) #> mlx array [2 x 6] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] [,4] [,5] [,6] #> [1,]    1    7    3    9    5   11 #> [2,]    2    8    4   10    6   12"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_forward.html","id":null,"dir":"Reference","previous_headings":"","what":"Forward pass utility — mlx_forward","title":"Forward pass utility — mlx_forward","text":"Forward pass utility","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_forward.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forward pass utility — mlx_forward","text":"","code":"mlx_forward(module, x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_forward.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forward pass utility — mlx_forward","text":"module mlx_module. x mlx array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_forward.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forward pass utility — mlx_forward","text":"Output array.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_forward.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Forward pass utility — mlx_forward","text":"","code":"set.seed(1) layer <- mlx_linear(2, 1) input <- as_mlx(matrix(c(1, 2), 1, 2)) mlx_forward(layer, input) #> mlx array [1 x 1] #>   dtype: float32 #>   device: gpu #>   values: #>            [,1] #> [1,] -0.2591672"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_full.html","id":null,"dir":"Reference","previous_headings":"","what":"Fill an mlx array with a constant value — mlx_full","title":"Fill an mlx array with a constant value — mlx_full","text":"Fill mlx array constant value","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_full.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fill an mlx array with a constant value — mlx_full","text":"","code":"mlx_full(dim, value, dtype = NULL, device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_full.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fill an mlx array with a constant value — mlx_full","text":"dim Integer vector specifying array shape/dimensions. value Scalar value used fill array. Numeric, logical, complex. dtype MLX dtype (\"float32\", \"float64\", \"bool\", \"complex64\"). omitted, defaults \"complex64\" complex scalars, \"bool\" logical scalars, \"float32\" otherwise. device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_full.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fill an mlx array with a constant value — mlx_full","text":"mlx array filled supplied value.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_full.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fill an mlx array with a constant value — mlx_full","text":"","code":"filled <- mlx_full(c(2, 2), 3.14) complex_full <- mlx_full(c(2, 2), 1+2i, dtype = \"complex64\")"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_gather.html","id":null,"dir":"Reference","previous_headings":"","what":"Gather elements from an mlx array — mlx_gather","title":"Gather elements from an mlx array — mlx_gather","text":"Mirrors mlx.core.gather(), selecting elements according index tensors along specified axes. current implementation supports gathering along single axis time.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_gather.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gather elements from an mlx array — mlx_gather","text":"","code":"mlx_gather(x, indices, axes = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_gather.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gather elements from an mlx array — mlx_gather","text":"x mlx array. indices List index tensors. element can numeric/logical vector, array, mlx array integer type. Shapes must broadcast common result. axes Integer vector axes (1-indexed, negatives count end) corresponding indices. Defaults first length(indices) axes.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_gather.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gather elements from an mlx array — mlx_gather","text":"mlx array containing gathered elements.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_gather.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gather elements from an mlx array — mlx_gather","text":"","code":"x <- as_mlx(matrix(1:9, 3, 3)) idx_rows <- c(1L, 3L) gathered <- mlx_gather(x, list(idx_rows), axes = 1L) as.matrix(gathered) #>      [,1] [,2] [,3] #> [1,]    1    4    7 #> [2,]    3    6    9"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_gather_qmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Gather-based Quantized Matrix Multiplication — mlx_gather_qmm","title":"Gather-based Quantized Matrix Multiplication — mlx_gather_qmm","text":"Performs quantized matrix multiplication optional gather operations inputs. useful combining embedding lookups quantized linear transformations, common pattern transformer models.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_gather_qmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gather-based Quantized Matrix Multiplication — mlx_gather_qmm","text":"","code":"mlx_gather_qmm(   x,   w,   scales,   biases = NULL,   lhs_indices = NULL,   rhs_indices = NULL,   transpose = TRUE,   group_size = 64L,   bits = 4L,   mode = \"affine\",   sorted_indices = FALSE,   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_gather_qmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gather-based Quantized Matrix Multiplication — mlx_gather_qmm","text":"x mlx array. w mlx array (quantized weight matrix) scales mlx array (quantization scales) biases optional mlx array (biases add). Default: NULL lhs_indices optional mlx array (indices gathering x). Default: NULL rhs_indices optional mlx array (indices gathering w). Default: NULL transpose Whether transpose weight matrix. Default: TRUE group_size group size quantization. Default: 64 bits number bits quantization (typically 4 8). Default: 4 mode quantization mode, either \"affine\" \"mxfp4\". Default: \"affine\" sorted_indices Whether indices sorted (enables optimizations). Default: FALSE device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Default: mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_gather_qmm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gather-based Quantized Matrix Multiplication — mlx_gather_qmm","text":"mlx array result gather-based quantized matrix multiplication","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_gather_qmm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gather-based Quantized Matrix Multiplication — mlx_gather_qmm","text":"function combines gather operations (indexed lookups) quantized matrix multiplication. lhs_indices provided, performs x[lhs_indices] multiplication. Similarly, rhs_indices gathers weight matrix. particularly efficient transformer models need look token embeddings apply quantized linear transformation one fused operation.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_gelu.html","id":null,"dir":"Reference","previous_headings":"","what":"GELU activation — mlx_gelu","title":"GELU activation — mlx_gelu","text":"Gaussian Error Linear Unit activation function.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_gelu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"GELU activation — mlx_gelu","text":"","code":"mlx_gelu()"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_gelu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"GELU activation — mlx_gelu","text":"mlx_module applying GELU activation.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_gelu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"GELU activation — mlx_gelu","text":"","code":"act <- mlx_gelu() x <- as_mlx(matrix(c(-2, -1, 0, 1, 2), 5, 1)) mlx_forward(act, x) #> mlx array [5 x 1] #>   dtype: float32 #>   device: gpu #>   values: #>             [,1] #> [1,] -0.04540229 #> [2,] -0.15880799 #> [3,]  0.00000000 #> [4,]  0.84119201 #> [5,]  1.95459771"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_grad.html","id":null,"dir":"Reference","previous_headings":"","what":"Automatic differentiation for MLX functions — mlx_grad","title":"Automatic differentiation for MLX functions — mlx_grad","text":"mlx_grad() computes gradients R function operates mlx arrays. function must keep differentiable computations MLX (e.g., via as_mlx() MLX operators) return mlx object.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_grad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Automatic differentiation for MLX functions — mlx_grad","text":"","code":"mlx_grad(f, ..., argnums = NULL, value = FALSE)  mlx_value_grad(f, ..., argnums = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_grad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Automatic differentiation for MLX functions — mlx_grad","text":"f R function. arguments mlx objects, return value must mlx array (typically scalar loss). ... Arguments pass f. coerced mlx needed. argnums Indices (1-based) identifying arguments differentiate respect . Defaults arguments. value function value returned alongside gradients? Set TRUE receive list components value grads.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_grad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Automatic differentiation for MLX functions — mlx_grad","text":"value = FALSE (default), list mlx arrays containing gradients order argnums. value = TRUE, list elements value (function output mlx) grads.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_grad.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Automatic differentiation for MLX functions — mlx_grad","text":"Keep differentiated closure inside MLX operations. Coercing arrays back base R objects (.matrix(), .numeric(), [[ extraction) breaks gradient tape results error.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_grad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Automatic differentiation for MLX functions — mlx_grad","text":"","code":"loss <- function(w, x, y) {   preds <- x %*% w   resids <- preds - y   sum(resids * resids) / length(y) } x <- as_mlx(matrix(1:8, 4, 2)) y <- as_mlx(matrix(c(1, 3, 2, 4), 4, 1)) w <- as_mlx(matrix(0, 2, 1)) mlx_grad(loss, w, x, y)[[1]] #> mlx array [2 x 1] #>   dtype: float32 #>   device: gpu #>   values: #>       [,1] #> [1,] -14.5 #> [2,] -34.5 loss <- function(w, x) sum((x %*% w) * (x %*% w)) x <- as_mlx(matrix(1:4, 2, 2)) w <- as_mlx(matrix(c(1, -1), 2, 1)) mlx_value_grad(loss, w, x) #> $value #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 8 #>  #> $grads #> $grads[[1]] #> mlx array [2 x 1] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] #> [1,]  -12 #> [2,]  -28 #>  #> $grads[[2]] #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]   -4    4 #> [2,]   -4    4 #>  #>"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_hadamard_transform.html","id":null,"dir":"Reference","previous_headings":"","what":"Hadamard transform for MLX arrays — mlx_hadamard_transform","title":"Hadamard transform for MLX arrays — mlx_hadamard_transform","text":"Multiplies last dimension x Sylvester-Hadamard matrix corresponding size. transform expects length last axis power two.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_hadamard_transform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hadamard transform for MLX arrays — mlx_hadamard_transform","text":"","code":"mlx_hadamard_transform(x, scale = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_hadamard_transform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hadamard transform for MLX arrays — mlx_hadamard_transform","text":"x mlx array, R array/matrix/vector converted via as_mlx(). scale Optional numeric scalar applied result. MLX defaults 1 / sqrt(n) n size transformed axis; set scale override factor (example, scale = 1 yields unnormalised Hadamard transform).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_hadamard_transform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hadamard transform for MLX arrays — mlx_hadamard_transform","text":"mlx array containing Hadamard-transformed values.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_hadamard_transform.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hadamard transform for MLX arrays — mlx_hadamard_transform","text":"","code":"x <- as_mlx(c(1, -1)) as.vector(mlx_hadamard_transform(x)) #> [1] 0.000000 1.414214 as.vector(mlx_hadamard_transform(x, scale = 1)) #> [1] 0 2"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_identity.html","id":null,"dir":"Reference","previous_headings":"","what":"Identity matrices on MLX devices — mlx_identity","title":"Identity matrices on MLX devices — mlx_identity","text":"Identity matrices MLX devices","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_identity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identity matrices on MLX devices — mlx_identity","text":"","code":"mlx_identity(n, dtype = c(\"float32\", \"float64\"), device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_identity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identity matrices on MLX devices — mlx_identity","text":"n Size square matrix. dtype MLX dtype use. One \"float32\", \"float64\", \"int8\", \"int16\", \"int32\", \"int64\", \"uint8\", \"uint16\", \"uint32\", \"uint64\", \"bool\", \"complex64\". device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_identity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identity matrices on MLX devices — mlx_identity","text":"mlx identity matrix.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_identity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identity matrices on MLX devices — mlx_identity","text":"","code":"I4 <- mlx_identity(4)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_inv.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute matrix inverse — mlx_inv","title":"Compute matrix inverse — mlx_inv","text":"Computes inverse square matrix.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_inv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute matrix inverse — mlx_inv","text":"","code":"mlx_inv(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_inv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute matrix inverse — mlx_inv","text":"x mlx array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_inv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute matrix inverse — mlx_inv","text":"inverse x.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_inv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute matrix inverse — mlx_inv","text":"","code":"A <- as_mlx(matrix(c(4, 7, 2, 6), 2, 2)) A_inv <- mlx_inv(A) # Verify: A %*% A_inv should be identity as.matrix(A %*% A_inv) #>              [,1] [,2] #> [1,] 1.000000e+00    0 #> [2,] 3.576279e-07    1"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isclose.html","id":null,"dir":"Reference","previous_headings":"","what":"Element-wise approximate equality — mlx_isclose","title":"Element-wise approximate equality — mlx_isclose","text":"Returns boolean array indicating elements two arrays close within specified tolerances.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isclose.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Element-wise approximate equality — mlx_isclose","text":"","code":"mlx_isclose(   a,   b,   rtol = 1e-05,   atol = 1e-08,   equal_nan = FALSE,   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isclose.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Element-wise approximate equality — mlx_isclose","text":", b MLX arrays objects coercible MLX arrays rtol Relative tolerance (default: 1e-5) atol Absolute tolerance (default: 1e-8) equal_nan TRUE, NaN values considered equal (default: FALSE) device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Default: mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isclose.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Element-wise approximate equality — mlx_isclose","text":"mlx array booleans element-wise comparison results","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isclose.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Element-wise approximate equality — mlx_isclose","text":"Two values considered close : abs(- b) <= (atol + rtol * abs(b)) Infinite values matching signs considered equal. Supports NumPy-style broadcasting.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isclose.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Element-wise approximate equality — mlx_isclose","text":"","code":"a <- as_mlx(c(1.0, 2.0, 3.0)) b <- as_mlx(c(1.0 + 1e-6, 2.0 + 1e-6, 3.0 + 1e-3)) mlx_isclose(a, b)  # First two TRUE, last FALSE #> mlx array [3] #>   dtype: bool #>   device: gpu #>   values: #> [1]  TRUE  TRUE FALSE"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isnan.html","id":null,"dir":"Reference","previous_headings":"","what":"Elementwise NaN and infinity predicates — mlx_isnan","title":"Elementwise NaN and infinity predicates — mlx_isnan","text":"mlx_isnan(), mlx_isinf(), mlx_isfinite() wrap corresponding MLX elementwise predicates, returning boolean arrays.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isnan.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Elementwise NaN and infinity predicates — mlx_isnan","text":"","code":"mlx_isnan(x)  mlx_isinf(x)  mlx_isfinite(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isnan.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Elementwise NaN and infinity predicates — mlx_isnan","text":"x mlx array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isnan.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Elementwise NaN and infinity predicates — mlx_isnan","text":"mlx boolean array.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isposinf.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect signed infinities in mlx arrays — mlx_isposinf","title":"Detect signed infinities in mlx arrays — mlx_isposinf","text":"mlx_isposinf() mlx_isneginf() mirror mlx.core.isposinf() mlx.core.isneginf(), returning boolean masks positive negative infinities.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isposinf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect signed infinities in mlx arrays — mlx_isposinf","text":"","code":"mlx_isposinf(x)  mlx_isneginf(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isposinf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect signed infinities in mlx arrays — mlx_isposinf","text":"x mlx array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isposinf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect signed infinities in mlx arrays — mlx_isposinf","text":"mlx boolean array highlighting infinite entries.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isposinf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect signed infinities in mlx arrays — mlx_isposinf","text":"","code":"vals <- as_mlx(c(-Inf, -1, 0, Inf)) as.matrix(mlx_isposinf(vals)) #> [1] FALSE FALSE FALSE  TRUE as.matrix(mlx_isneginf(vals)) #> [1]  TRUE FALSE FALSE FALSE"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_key.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct MLX random number generator keys — mlx_key","title":"Construct MLX random number generator keys — mlx_key","text":"mlx_key() provides access MLX's stateless PRNG. Given 64-bit seed returns key can passed random helpers. Use mlx_key_split() derive multiple independent keys existing key.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_key.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct MLX random number generator keys — mlx_key","text":"","code":"mlx_key(seed)  mlx_key_split(key, num = 2L)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_key.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct MLX random number generator keys — mlx_key","text":"seed Integer numeric seed (converted unsigned 64-bit). key mlx key array returned mlx_key(). num Number subkeys produce (default 2L).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_key.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct MLX random number generator keys — mlx_key","text":"mlx array holding PRNG key. list num mlx key arrays.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_key.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct MLX random number generator keys — mlx_key","text":"","code":"k <- mlx_key(42) subkeys <- mlx_key_split(k, num = 2)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_key_bits.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate raw random bits on MLX arrays — mlx_key_bits","title":"Generate raw random bits on MLX arrays — mlx_key_bits","text":"Generate raw random bits MLX arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_key_bits.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate raw random bits on MLX arrays — mlx_key_bits","text":"","code":"mlx_key_bits(dim, width = 4L, key = NULL, device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_key_bits.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate raw random bits on MLX arrays — mlx_key_bits","text":"dim Integer vector specifying array shape/dimensions. width Number bytes per element (default 4 = 32 bits). Must positive. key Optional mlx key array. omitted, MLX's default generator used. device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_key_bits.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate raw random bits on MLX arrays — mlx_key_bits","text":"mlx array unsigned integers filled random bits.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_key_bits.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate raw random bits on MLX arrays — mlx_key_bits","text":"","code":"k <- mlx_key(12) raw_bits <- mlx_key_bits(c(4, 4), key = k)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_kron.html","id":null,"dir":"Reference","previous_headings":"","what":"Kronecker product for mlx arrays — mlx_kron","title":"Kronecker product for mlx arrays — mlx_kron","text":"Computes Kronecker (tensor) product two mlx arrays. Inputs automatically cast common dtype device evaluation.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_kron.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kronecker product for mlx arrays — mlx_kron","text":"","code":"mlx_kron(a, b)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_kron.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kronecker product for mlx arrays — mlx_kron","text":", b Objects coercible mlx.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_kron.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Kronecker product for mlx arrays — mlx_kron","text":"mlx array representing Kronecker product.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_kron.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Kronecker product for mlx arrays — mlx_kron","text":"","code":"A <- as_mlx(matrix(1:4, 2, 2)) B <- as_mlx(matrix(c(0, 5, 6, 7), 2, 2)) mlx_kron(A, B) #> mlx array [4 x 4] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] [,4] #> [1,]    0    6    0   18 #> [2,]    5    7   15   21 #> [3,]    0   12    0   24 #> [4,]   10   14   20   28"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_l1_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"L1 loss (Mean Absolute Error) — mlx_l1_loss","title":"L1 loss (Mean Absolute Error) — mlx_l1_loss","text":"Computes mean absolute error predictions targets.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_l1_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"L1 loss (Mean Absolute Error) — mlx_l1_loss","text":"","code":"mlx_l1_loss(predictions, targets, reduction = c(\"mean\", \"sum\", \"none\"))"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_l1_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"L1 loss (Mean Absolute Error) — mlx_l1_loss","text":"predictions Predicted values mlx array. targets Target values mlx array. reduction Type reduction: \"mean\" (default), \"sum\", \"none\".","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_l1_loss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"L1 loss (Mean Absolute Error) — mlx_l1_loss","text":"mlx array containing loss.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_l1_loss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"L1 loss (Mean Absolute Error) — mlx_l1_loss","text":"","code":"preds <- as_mlx(matrix(c(1.5, 2.3, 0.8), 3, 1)) targets <- as_mlx(matrix(c(1, 2, 1), 3, 1)) mlx_l1_loss(preds, targets) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 0.3333333"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_layer_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"Layer normalization — mlx_layer_norm","title":"Layer normalization — mlx_layer_norm","text":"Normalizes inputs across feature dimension.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_layer_norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Layer normalization — mlx_layer_norm","text":"","code":"mlx_layer_norm(normalized_shape, eps = 1e-05, device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_layer_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Layer normalization — mlx_layer_norm","text":"normalized_shape Size feature dimension normalize. eps Small constant numerical stability (default: 1e-5). device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Default: mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_layer_norm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Layer normalization — mlx_layer_norm","text":"mlx_module applying layer normalization.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_layer_norm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Layer normalization — mlx_layer_norm","text":"","code":"set.seed(1) ln <- mlx_layer_norm(4) x <- as_mlx(matrix(rnorm(12), 3, 4)) mlx_forward(ln, x) #> mlx array [3 x 4] #>   dtype: float32 #>   device: gpu #>   values: #>            [,1]       [,2]       [,3]       [,4] #> [1,] -1.0668312  1.5259182 0.23306273 -0.6921500 #> [2,] -0.9833397 -0.7005272 0.09211669  1.5917501 #> [3,] -1.0064702 -0.9834564 1.13609314  0.8538334"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_leaky_relu.html","id":null,"dir":"Reference","previous_headings":"","what":"Leaky ReLU activation — mlx_leaky_relu","title":"Leaky ReLU activation — mlx_leaky_relu","text":"Leaky ReLU activation","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_leaky_relu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Leaky ReLU activation — mlx_leaky_relu","text":"","code":"mlx_leaky_relu(negative_slope = 0.01)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_leaky_relu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Leaky ReLU activation — mlx_leaky_relu","text":"negative_slope Slope negative values (default: 0.01).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_leaky_relu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Leaky ReLU activation — mlx_leaky_relu","text":"mlx_module applying Leaky ReLU activation.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_leaky_relu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Leaky ReLU activation — mlx_leaky_relu","text":"","code":"act <- mlx_leaky_relu(negative_slope = 0.1) x <- as_mlx(matrix(c(-2, -1, 0, 1, 2), 5, 1)) mlx_forward(act, x) #> mlx array [5 x 1] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] #> [1,] -0.2 #> [2,] -0.1 #> [3,]  0.0 #> [4,]  1.0 #> [5,]  2.0"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_linear.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a learnable linear transformation — mlx_linear","title":"Create a learnable linear transformation — mlx_linear","text":"Create learnable linear transformation","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_linear.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a learnable linear transformation — mlx_linear","text":"","code":"mlx_linear(   in_features,   out_features,   bias = TRUE,   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_linear.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a learnable linear transformation — mlx_linear","text":"in_features Number input features. out_features Number output features. bias bias term included? device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Default: mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_linear.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a learnable linear transformation — mlx_linear","text":"object class mlx_module.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_linear.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a learnable linear transformation — mlx_linear","text":"","code":"set.seed(1) layer <- mlx_linear(3, 2) x <- as_mlx(matrix(1:6, 2, 3)) mlx_forward(layer, x) #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>           [,1]       [,2] #> [1,] -3.473105 -1.2398810 #> [2,] -4.516946 -0.3382074"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_linspace.html","id":null,"dir":"Reference","previous_headings":"","what":"Evenly spaced ranges on MLX devices — mlx_linspace","title":"Evenly spaced ranges on MLX devices — mlx_linspace","text":"mlx_linspace() creates num evenly spaced values start stop, inclusive. Unlike mlx_arange(), specify many samples want rather step size.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_linspace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evenly spaced ranges on MLX devices — mlx_linspace","text":"","code":"mlx_linspace(   start,   stop,   num = 50L,   dtype = c(\"float32\", \"float64\"),   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_linspace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evenly spaced ranges on MLX devices — mlx_linspace","text":"start Starting value. stop Final value (inclusive). num Number samples generate. dtype MLX dtype (\"float32\" \"float64\"). device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_linspace.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evenly spaced ranges on MLX devices — mlx_linspace","text":"1D mlx array.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_linspace.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evenly spaced ranges on MLX devices — mlx_linspace","text":"","code":"mlx_linspace(0, 1, num = 5) #> mlx array [5] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 0.00 0.25 0.50 0.75 1.00"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_load.html","id":null,"dir":"Reference","previous_headings":"","what":"Load an MLX array from disk — mlx_load","title":"Load an MLX array from disk — mlx_load","text":"Restores array saved mlx_save() optionally places specified device.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_load.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load an MLX array from disk — mlx_load","text":"","code":"mlx_load(file, device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_load.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load an MLX array from disk — mlx_load","text":"file Path .npy file. extension appended automatically missing. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Default: mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_load.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load an MLX array from disk — mlx_load","text":"mlx array containing file contents.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_load.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Load an MLX array from disk — mlx_load","text":"Use mlx_stream mlx_new_stream() load directly onto specific stream; otherwise array placed current mlx_default_device().","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_load_gguf.html","id":null,"dir":"Reference","previous_headings":"","what":"Load MLX tensors from the GGUF format — mlx_load_gguf","title":"Load MLX tensors from the GGUF format — mlx_load_gguf","text":"Load MLX tensors GGUF format","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_load_gguf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load MLX tensors from the GGUF format — mlx_load_gguf","text":"","code":"mlx_load_gguf(file, device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_load_gguf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load MLX tensors from the GGUF format — mlx_load_gguf","text":"file Path .npy file. extension appended automatically missing. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Default: mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_load_gguf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load MLX tensors from the GGUF format — mlx_load_gguf","text":"list containing: tensors Named list mlx arrays. metadata Named list values NULL, character vectors, mlx arrays depending GGUF entry type.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_load_safetensors.html","id":null,"dir":"Reference","previous_headings":"","what":"Load MLX arrays from the safetensors format — mlx_load_safetensors","title":"Load MLX arrays from the safetensors format — mlx_load_safetensors","text":"Load MLX arrays safetensors format","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_load_safetensors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load MLX arrays from the safetensors format — mlx_load_safetensors","text":"","code":"mlx_load_safetensors(file, device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_load_safetensors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load MLX arrays from the safetensors format — mlx_load_safetensors","text":"file Path .npy file. extension appended automatically missing. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Default: mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_load_safetensors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load MLX arrays from the safetensors format — mlx_load_safetensors","text":"list containing: tensors Named list mlx arrays. metadata Named character vector serialized metadata.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_logcumsumexp.html","id":null,"dir":"Reference","previous_headings":"","what":"Log cumulative sum exponential for mlx arrays — mlx_logcumsumexp","title":"Log cumulative sum exponential for mlx arrays — mlx_logcumsumexp","text":"Log cumulative sum exponential mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_logcumsumexp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log cumulative sum exponential for mlx arrays — mlx_logcumsumexp","text":"","code":"mlx_logcumsumexp(x, axis = NULL, reverse = FALSE, inclusive = TRUE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_logcumsumexp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log cumulative sum exponential for mlx arrays — mlx_logcumsumexp","text":"x mlx array, R array/matrix/vector converted via as_mlx(). axis Optional axis (single integer) operate . reverse Logical flag reverse accumulation. inclusive Logical flag controlling inclusivity.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_logcumsumexp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log cumulative sum exponential for mlx arrays — mlx_logcumsumexp","text":"mlx array.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_logcumsumexp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log cumulative sum exponential for mlx arrays — mlx_logcumsumexp","text":"","code":"x <- as_mlx(1:4) as.vector(as.matrix(mlx_logcumsumexp(x))) #> [1] 1.000000 2.313262 3.407606 4.440190 m <- as_mlx(matrix(1:6, 2, 3)) as.matrix(mlx_logcumsumexp(m, axis = 2)) #>      [,1]     [,2]     [,3] #> [1,]    1 3.126928 5.142931 #> [2,]    2 4.126928 6.142931"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_logsumexp.html","id":null,"dir":"Reference","previous_headings":"","what":"Log-sum-exp reduction for mlx arrays — mlx_logsumexp","title":"Log-sum-exp reduction for mlx arrays — mlx_logsumexp","text":"Log-sum-exp reduction mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_logsumexp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log-sum-exp reduction for mlx arrays — mlx_logsumexp","text":"","code":"mlx_logsumexp(x, axis = NULL, drop = TRUE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_logsumexp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log-sum-exp reduction for mlx arrays — mlx_logsumexp","text":"x mlx array, R array/matrix/vector converted via as_mlx(). axis Optional axis operate (1-indexed like R). NULL, array flattened first. drop Logical indicating whether reduced axes dropped (default TRUE).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_logsumexp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log-sum-exp reduction for mlx arrays — mlx_logsumexp","text":"mlx array containing log-sum-exp results.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_logsumexp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log-sum-exp reduction for mlx arrays — mlx_logsumexp","text":"","code":"x <- as_mlx(matrix(1:6, 2, 3)) as.matrix(mlx_logsumexp(x)) #> [1] 6.456193 as.matrix(mlx_logsumexp(x, axis = 2)) #> [1] 5.142931 6.142931"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_lu.html","id":null,"dir":"Reference","previous_headings":"","what":"LU factorization — mlx_lu","title":"LU factorization — mlx_lu","text":"Computes LU factorization matrix.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_lu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"LU factorization — mlx_lu","text":"","code":"mlx_lu(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_lu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"LU factorization — mlx_lu","text":"x mlx array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_lu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"LU factorization — mlx_lu","text":"list components p (pivot indices), l (lower triangular), u (upper triangular). relationship = L[P, ] %*% U.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_lu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"LU factorization — mlx_lu","text":"","code":"A <- as_mlx(matrix(rnorm(16), 4, 4)) lu_result <- mlx_lu(A) P <- lu_result$p  # Pivot indices L <- lu_result$l  # Lower triangular U <- lu_result$u  # Upper triangular"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_matrix_required.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters for Functions Requiring MLX Matrices — mlx_matrix_required","title":"Parameters for Functions Requiring MLX Matrices — mlx_matrix_required","text":"Parameters Functions Requiring MLX Matrices","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_matrix_required.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters for Functions Requiring MLX Matrices — mlx_matrix_required","text":"x mlx matrix (2-dimensional array).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_maximum.html","id":null,"dir":"Reference","previous_headings":"","what":"Elementwise maximum of two mlx arrays — mlx_maximum","title":"Elementwise maximum of two mlx arrays — mlx_maximum","text":"Elementwise maximum two mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_maximum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Elementwise maximum of two mlx arrays — mlx_maximum","text":"","code":"mlx_maximum(x, y)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_maximum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Elementwise maximum of two mlx arrays — mlx_maximum","text":"x, y mlx arrays objects coercible as_mlx().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_maximum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Elementwise maximum of two mlx arrays — mlx_maximum","text":"mlx array containing elementwise maximum.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_maximum.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Elementwise maximum of two mlx arrays — mlx_maximum","text":"","code":"if (FALSE) { # \\dontrun{ mlx_maximum(1:3, c(3, 2, 1)) } # }"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_meshgrid.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct coordinate arrays from input vectors — mlx_meshgrid","title":"Construct coordinate arrays from input vectors — mlx_meshgrid","text":"mlx_meshgrid() mirrors mlx.core.meshgrid(), returning coordinate arrays suitable vectorised evaluation MLX devices.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_meshgrid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct coordinate arrays from input vectors — mlx_meshgrid","text":"","code":"mlx_meshgrid(..., sparse = FALSE, indexing = c(\"xy\", \"ij\"), device = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_meshgrid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct coordinate arrays from input vectors — mlx_meshgrid","text":"... One arrays (single list) convertible via as_mlx() representing coordinate vectors. sparse Logical flag producing broadcast-friendly outputs TRUE. indexing Either \"xy\" (Cartesian) \"ij\" (matrix) indexing. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Default: mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_meshgrid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct coordinate arrays from input vectors — mlx_meshgrid","text":"list mlx arrays matching number inputs.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_meshgrid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct coordinate arrays from input vectors — mlx_meshgrid","text":"","code":"xs <- as_mlx(1:3) ys <- as_mlx(1:2) grids <- mlx_meshgrid(xs, ys, indexing = \"xy\") lapply(grids, as.matrix) #> [[1]] #>      [,1] [,2] [,3] #> [1,]    1    2    3 #> [2,]    1    2    3 #>  #> [[2]] #>      [,1] [,2] [,3] #> [1,]    1    1    1 #> [2,]    2    2    2 #>"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_minimum.html","id":null,"dir":"Reference","previous_headings":"","what":"Elementwise minimum of two mlx arrays — mlx_minimum","title":"Elementwise minimum of two mlx arrays — mlx_minimum","text":"Elementwise minimum two mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_minimum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Elementwise minimum of two mlx arrays — mlx_minimum","text":"","code":"mlx_minimum(x, y)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_minimum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Elementwise minimum of two mlx arrays — mlx_minimum","text":"x, y mlx arrays objects coercible as_mlx().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_minimum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Elementwise minimum of two mlx arrays — mlx_minimum","text":"mlx array containing elementwise minimum.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_minimum.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Elementwise minimum of two mlx arrays — mlx_minimum","text":"","code":"if (FALSE) { # \\dontrun{ a <- as_mlx(matrix(1:4, 2, 2)) b <- as_mlx(matrix(c(4, 3, 2, 1), 2, 2)) mlx_minimum(a, b) } # }"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_moveaxis.html","id":null,"dir":"Reference","previous_headings":"","what":"Reorder mlx array axes — mlx_moveaxis","title":"Reorder mlx array axes — mlx_moveaxis","text":"mlx_moveaxis() repositions one axes new locations. aperm.mlx() provides familiar R interface, permuting axes according perm via repeated calls mlx_moveaxis().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_moveaxis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reorder mlx array axes — mlx_moveaxis","text":"","code":"mlx_moveaxis(x, source, destination)  # S3 method for class 'mlx' aperm(a, perm = NULL, resize = TRUE, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_moveaxis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reorder mlx array axes — mlx_moveaxis","text":"x, object coercible mlx via as_mlx(). source Integer vector axis indices move (1-indexed; negatives count end). destination Integer vector giving target positions source axes (1-indexed; negatives count end). Must length source. perm Integer permutation describing desired axis order, matching semantics base::aperm(). resize Logical flag base::aperm(). TRUE currently supported mlx arrays. ... Additional arguments accepted compatibility; ignored.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_moveaxis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reorder mlx array axes — mlx_moveaxis","text":"mlx array axes permuted.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_moveaxis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reorder mlx array axes — mlx_moveaxis","text":"","code":"x <- as_mlx(array(1:8, dim = c(2, 2, 2))) moved <- mlx_moveaxis(x, source = 1, destination = 3) permuted <- aperm(x, c(2, 1, 3))"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_mse_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean squared error loss — mlx_mse_loss","title":"Mean squared error loss — mlx_mse_loss","text":"Computes mean squared error predictions targets.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_mse_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean squared error loss — mlx_mse_loss","text":"","code":"mlx_mse_loss(predictions, targets, reduction = c(\"mean\", \"sum\", \"none\"))"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_mse_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean squared error loss — mlx_mse_loss","text":"predictions Predicted values mlx array. targets Target values mlx array. reduction Type reduction: \"mean\" (default), \"sum\", \"none\".","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_mse_loss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean squared error loss — mlx_mse_loss","text":"mlx array containing loss.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_mse_loss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mean squared error loss — mlx_mse_loss","text":"","code":"preds <- as_mlx(matrix(c(1.5, 2.3, 0.8), 3, 1)) targets <- as_mlx(matrix(c(1, 2, 1), 3, 1)) mlx_mse_loss(preds, targets) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 0.1266666"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_nan_to_num.html","id":null,"dir":"Reference","previous_headings":"","what":"Replace NaN and infinite values with finite numbers — mlx_nan_to_num","title":"Replace NaN and infinite values with finite numbers — mlx_nan_to_num","text":"mlx_nan_to_num() mirrors mlx.core.nan_to_num(), filling non-finite entries user-provided finite substitutes.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_nan_to_num.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replace NaN and infinite values with finite numbers — mlx_nan_to_num","text":"","code":"mlx_nan_to_num(x, nan = 0, posinf = NULL, neginf = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_nan_to_num.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replace NaN and infinite values with finite numbers — mlx_nan_to_num","text":"x mlx array. nan Replacement NaN values (default 0). Use NULL retain MLX's default. posinf Optional replacement positive infinity. neginf Optional replacement negative infinity.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_nan_to_num.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Replace NaN and infinite values with finite numbers — mlx_nan_to_num","text":"mlx array non-finite values replaced.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_nan_to_num.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Replace NaN and infinite values with finite numbers — mlx_nan_to_num","text":"","code":"x <- as_mlx(c(-Inf, -1, NaN, 3, Inf)) as.matrix(mlx_nan_to_num(x, nan = 0, posinf = 10, neginf = -10)) #> [1] -10  -1   0   3  10"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_new_stream.html","id":null,"dir":"Reference","previous_headings":"","what":"MLX streams for asynchronous execution — mlx_new_stream","title":"MLX streams for asynchronous execution — mlx_new_stream","text":"Streams provide independent execution queues device, allowing overlap computation finer control scheduling. mlx_default_stream() returns current default stream device.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_new_stream.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MLX streams for asynchronous execution — mlx_new_stream","text":"","code":"mlx_new_stream(device = mlx_default_device())  mlx_default_stream(device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_new_stream.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MLX streams for asynchronous execution — mlx_new_stream","text":"device Device identifier (\"gpu\" \"cpu\"). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_new_stream.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MLX streams for asynchronous execution — mlx_new_stream","text":"object class mlx_stream.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_new_stream.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MLX streams for asynchronous execution — mlx_new_stream","text":"","code":"stream <- mlx_new_stream() stream #> mlx stream [gpu] index=2"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"Matrix and vector norms for mlx arrays — mlx_norm","title":"Matrix and vector norms for mlx arrays — mlx_norm","text":"Matrix vector norms mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matrix and vector norms for mlx arrays — mlx_norm","text":"","code":"mlx_norm(x, ord = NULL, axis = NULL, drop = TRUE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matrix and vector norms for mlx arrays — mlx_norm","text":"x mlx array. ord Numeric character norm order. Use NULL default 2-norm. axis Optional integer vector axes (1-indexed) along compute norm. drop TRUE (default), drop dimensions length 1. FALSE, retain dimensions. Equivalent keepdims = TRUE underlying mlx functions.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_norm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Matrix and vector norms for mlx arrays — mlx_norm","text":"mlx array containing requested norm.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_norm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Matrix and vector norms for mlx arrays — mlx_norm","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) mlx_norm(x) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 5.477226 mlx_norm(x, ord = 2) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 5.464986 mlx_norm(x, axis = 2) #> mlx array [2] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 3.162278 4.472136"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_ones.html","id":null,"dir":"Reference","previous_headings":"","what":"Create arrays of ones on MLX devices — mlx_ones","title":"Create arrays of ones on MLX devices — mlx_ones","text":"Create arrays ones MLX devices","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_ones.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create arrays of ones on MLX devices — mlx_ones","text":"","code":"mlx_ones(   dim,   dtype = c(\"float32\", \"float64\", \"int8\", \"int16\", \"int32\", \"int64\", \"uint8\", \"uint16\",     \"uint32\", \"uint64\", \"bool\", \"complex64\"),   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_ones.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create arrays of ones on MLX devices — mlx_ones","text":"dim Integer vector specifying array shape/dimensions. dtype MLX dtype use. One \"float32\", \"float64\", \"int8\", \"int16\", \"int32\", \"int64\", \"uint8\", \"uint16\", \"uint32\", \"uint64\", \"bool\", \"complex64\". device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_ones.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create arrays of ones on MLX devices — mlx_ones","text":"mlx array filled ones.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_ones.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create arrays of ones on MLX devices — mlx_ones","text":"","code":"ones <- mlx_ones(c(2, 2), dtype = \"float64\", device = \"cpu\") ones_int <- mlx_ones(c(3, 3), dtype = \"int32\")"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_ones_like.html","id":null,"dir":"Reference","previous_headings":"","what":"Ones shaped like an existing mlx array — mlx_ones_like","title":"Ones shaped like an existing mlx array — mlx_ones_like","text":"mlx_ones_like() mirrors mlx.core.ones_like(), creating array ones shape. Optionally override dtype device.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_ones_like.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ones shaped like an existing mlx array — mlx_ones_like","text":"","code":"mlx_ones_like(x, dtype = NULL, device = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_ones_like.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ones shaped like an existing mlx array — mlx_ones_like","text":"x mlx array. dtype Optional MLX dtype override. Defaults source array's dtype. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Default: mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_ones_like.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ones shaped like an existing mlx array — mlx_ones_like","text":"mlx array ones matching x.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_ones_like.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ones shaped like an existing mlx array — mlx_ones_like","text":"","code":"base <- mlx_full(c(2, 3), 5) ones <- mlx_ones_like(base) as.matrix(ones) #>      [,1] [,2] [,3] #> [1,]    1    1    1 #> [2,]    1    1    1"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_optimizer_sgd.html","id":null,"dir":"Reference","previous_headings":"","what":"Stochastic gradient descent optimizer — mlx_optimizer_sgd","title":"Stochastic gradient descent optimizer — mlx_optimizer_sgd","text":"Stochastic gradient descent optimizer","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_optimizer_sgd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stochastic gradient descent optimizer — mlx_optimizer_sgd","text":"","code":"mlx_optimizer_sgd(params, lr = 0.01)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_optimizer_sgd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stochastic gradient descent optimizer — mlx_optimizer_sgd","text":"params List parameters (mlx_parameters()). lr Learning rate.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_optimizer_sgd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stochastic gradient descent optimizer — mlx_optimizer_sgd","text":"optimizer object step() method.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_optimizer_sgd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stochastic gradient descent optimizer — mlx_optimizer_sgd","text":"","code":"set.seed(1) model <- mlx_linear(2, 1, bias = FALSE) opt <- mlx_optimizer_sgd(mlx_parameters(model), lr = 0.1)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_pad.html","id":null,"dir":"Reference","previous_headings":"","what":"Pad or split mlx arrays — mlx_pad","title":"Pad or split mlx arrays — mlx_pad","text":"mlx_pad() mirrors MLX padding primitive, enlarging axis according pad_width. Values added symmetrically (pad_width[, 1] , pad_width[, 2] ) using specified mode. mlx_split() divides array along axis either equal sections (sections scalar) explicit 1-based split points (sections vector), returning list mlx arrays.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_pad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pad or split mlx arrays — mlx_pad","text":"","code":"mlx_pad(   x,   pad_width,   value = 0,   mode = c(\"constant\", \"edge\", \"reflect\", \"symmetric\"),   axes = NULL )  mlx_split(x, sections, axis = 1L)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_pad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pad or split mlx arrays — mlx_pad","text":"x mlx array, R array/matrix/vector converted via as_mlx(). pad_width Padding extents. Supply single integer, length-two numeric vector, matrix/list one (, ) pair per padded axis. value Constant fill value used mode = \"constant\". mode Padding mode passed MLX (e.g., \"constant\", \"edge\", \"reflect\"). axes Optional integer vector axes (1-indexed, negatives count end) pad_width applies. Unlisted axes receive zero padding. sections Either single integer (number equal parts) integer vector 1-based split points along axis. axis Axis (1-indexed, negatives count end) operate .","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_pad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pad or split mlx arrays — mlx_pad","text":"mlx_pad(), mlx array; mlx_split(), list mlx arrays.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_pad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pad or split mlx arrays — mlx_pad","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) padded <- mlx_pad(x, pad_width = 1) padded_cols <- mlx_pad(x, pad_width = c(0, 1), axes = 2) parts <- mlx_split(x, sections = 2, axis = 1) custom_parts <- mlx_split(x, sections = c(1), axis = 2)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_param_set_values.html","id":null,"dir":"Reference","previous_headings":"","what":"Assign arrays back to parameters — mlx_param_set_values","title":"Assign arrays back to parameters — mlx_param_set_values","text":"Assign arrays back parameters","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_param_set_values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assign arrays back to parameters — mlx_param_set_values","text":"","code":"mlx_param_set_values(params, values)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_param_set_values.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assign arrays back to parameters — mlx_param_set_values","text":"params list mlx_param. values list arrays.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_param_set_values.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assign arrays back to parameters — mlx_param_set_values","text":"","code":"set.seed(1) layer <- mlx_linear(2, 1) params <- mlx_parameters(layer) current <- mlx_param_values(params) mlx_param_set_values(params, current)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_param_values.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve parameter arrays — mlx_param_values","title":"Retrieve parameter arrays — mlx_param_values","text":"Retrieve parameter arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_param_values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve parameter arrays — mlx_param_values","text":"","code":"mlx_param_values(params)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_param_values.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve parameter arrays — mlx_param_values","text":"params list mlx_param.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_param_values.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve parameter arrays — mlx_param_values","text":"List mlx arrays.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_param_values.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve parameter arrays — mlx_param_values","text":"","code":"set.seed(1) layer <- mlx_linear(2, 1) vals <- mlx_param_values(mlx_parameters(layer))"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Collect parameters from modules — mlx_parameters","title":"Collect parameters from modules — mlx_parameters","text":"Collect parameters modules","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Collect parameters from modules — mlx_parameters","text":"","code":"mlx_parameters(module)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Collect parameters from modules — mlx_parameters","text":"module mlx_module list modules.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Collect parameters from modules — mlx_parameters","text":"list mlx_param objects.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_parameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Collect parameters from modules — mlx_parameters","text":"","code":"set.seed(1) layer <- mlx_linear(2, 1) mlx_parameters(layer) #> [[1]] #> $env #> <environment: 0x11cb5b8a0> #>  #> $name #> [1] \"weight\" #>  #> attr(,\"class\") #> [1] \"mlx_param\" #>  #> [[2]] #> $env #> <environment: 0x11cb5b8a0> #>  #> $name #> [1] \"bias\" #>  #> attr(,\"class\") #> [1] \"mlx_param\" #>"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantize.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantize a Matrix — mlx_quantize","title":"Quantize a Matrix — mlx_quantize","text":"Quantizes weight matrix low-precision representation (typically 4-bit 8-bit). reduces memory usage enables faster computation inference.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantize a Matrix — mlx_quantize","text":"","code":"mlx_quantize(   w,   group_size = 64L,   bits = 4L,   mode = \"affine\",   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantize a Matrix — mlx_quantize","text":"w mlx array (weight matrix quantize) group_size group size quantization. Smaller groups provide better accuracy slightly higher memory. Default: 64 bits number bits quantization (typically 4 8). Default: 4 mode quantization mode: \"affine\" (scales biases) \"mxfp4\" (4-bit floating point group_size=32). Default: \"affine\" device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Default: mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quantize a Matrix — mlx_quantize","text":"list containing: w_q quantized weight matrix (packed uint32) scales quantization scales dequantization biases quantization biases (NULL symmetric mode)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantize.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Quantize a Matrix — mlx_quantize","text":"Quantization converts floating-point weights low-precision integers, reducing memory 8x 4-bit quantization. scales (optionally biases) stored enable approximate reconstruction original values.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantize a Matrix — mlx_quantize","text":"","code":"if (FALSE) { # \\dontrun{ w <- mlx_random_normal(c(512, 256)) quant <- mlx_quantize(w, group_size = 64, bits = 4) # Use quant$w_q, quant$scales, quant$biases with mlx_quantized_matmul() } # }"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantized_matmul.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantized Matrix Multiplication — mlx_quantized_matmul","title":"Quantized Matrix Multiplication — mlx_quantized_matmul","text":"Performs matrix multiplication quantized weight matrix. operation essential efficient inference quantized models, significantly reducing memory usage computation time maintaining reasonable accuracy.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantized_matmul.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantized Matrix Multiplication — mlx_quantized_matmul","text":"","code":"mlx_quantized_matmul(   x,   w,   scales = NULL,   biases = NULL,   transpose = TRUE,   group_size = 64L,   bits = 4L,   mode = \"affine\",   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantized_matmul.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantized Matrix Multiplication — mlx_quantized_matmul","text":"x mlx array. w mlx array. Either: quantized weight matrix (uint32) mlx_quantize(), unquantized weight matrix quantized automatically scales optional mlx array (quantization scales). NULL w unquantized, w quantized automatically. Default: NULL biases optional mlx array (biases add). affine quantization, quantization biases w pre-quantized. Default: NULL transpose Whether transpose weight matrix. Default: TRUE group_size group size quantization. Default: 64 bits number bits quantization (typically 4 8). Default: 4 mode quantization mode, either \"affine\" \"mxfp4\". Default: \"affine\" device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Default: mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantized_matmul.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quantized Matrix Multiplication — mlx_quantized_matmul","text":"mlx array result quantized matrix multiplication","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantized_matmul.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Quantized Matrix Multiplication — mlx_quantized_matmul","text":"Quantized matrix multiplication uses low-precision representations (typically 4-bit 8-bit integers) weights, reduces memory footprint 8x compared float32. scales parameter contains dequantization factors needed reconstruct approximate float values computation. group_size parameter controls granularity quantization - smaller groups provide better accuracy slightly higher memory usage. Automatic Quantization: w provided (without scales), function automatically quantize w using mlx_quantize() performing multiplication. repeated operations, efficient pre-quantize weights using mlx_quantize() reuse .","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantized_matmul.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantized Matrix Multiplication — mlx_quantized_matmul","text":"","code":"if (FALSE) { # \\dontrun{ # Automatic quantization (convenient but slower for repeated use) x <- mlx_random_normal(c(10, 256)) w <- mlx_random_normal(c(512, 256)) result <- mlx_quantized_matmul(x, w)  # Pre-quantized weights (faster for repeated operations) quant <- mlx_quantize(w, group_size = 64, bits = 4) result <- mlx_quantized_matmul(x, quant$w_q, quant$scales, quant$biases) } # }"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_bernoulli.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample Bernoulli random variables on mlx arrays — mlx_rand_bernoulli","title":"Sample Bernoulli random variables on mlx arrays — mlx_rand_bernoulli","text":"Sample Bernoulli random variables mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_bernoulli.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample Bernoulli random variables on mlx arrays — mlx_rand_bernoulli","text":"","code":"mlx_rand_bernoulli(dim, prob = 0.5, device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_bernoulli.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample Bernoulli random variables on mlx arrays — mlx_rand_bernoulli","text":"dim Integer vector specifying array shape/dimensions. prob Probability one. device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_bernoulli.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample Bernoulli random variables on mlx arrays — mlx_rand_bernoulli","text":"mlx boolean array.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_bernoulli.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample Bernoulli random variables on mlx arrays — mlx_rand_bernoulli","text":"","code":"mask <- mlx_rand_bernoulli(c(4, 4), prob = 0.3)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_categorical.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from a categorical distribution on mlx arrays — mlx_rand_categorical","title":"Sample from a categorical distribution on mlx arrays — mlx_rand_categorical","text":"Samples indices categorical distributions. row (slice along specified axis) represents separate categorical distribution classes.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_categorical.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from a categorical distribution on mlx arrays — mlx_rand_categorical","text":"","code":"mlx_rand_categorical(logits, axis = -1L, num_samples = 1L)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_categorical.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from a categorical distribution on mlx arrays — mlx_rand_categorical","text":"logits matrix mlx array log-probabilities. values need normalized (function applies softmax internally). single distribution K classes, use 1×K matrix. multiple independent distributions, use N×K matrix row distribution. axis axis along sample. Default -1 (last axis, typically class dimension). num_samples Number samples draw distribution.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_categorical.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from a categorical distribution on mlx arrays — mlx_rand_categorical","text":"mlx array integer indices (0-indexed) sampled categorical distributions.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_categorical.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample from a categorical distribution on mlx arrays — mlx_rand_categorical","text":"","code":"# Single distribution over 3 classes logits <- matrix(c(0.5, 0.2, 0.3), 1, 3) samples <- mlx_rand_categorical(logits, num_samples = 10)  # Multiple distributions logits <- matrix(c(1, 2, 3,                    3, 2, 1), nrow = 2, byrow = TRUE) samples <- mlx_rand_categorical(logits, num_samples = 5)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_gumbel.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from the Gumbel distribution on mlx arrays — mlx_rand_gumbel","title":"Sample from the Gumbel distribution on mlx arrays — mlx_rand_gumbel","text":"Sample Gumbel distribution mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_gumbel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from the Gumbel distribution on mlx arrays — mlx_rand_gumbel","text":"","code":"mlx_rand_gumbel(   dim,   dtype = c(\"float32\", \"float64\"),   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_gumbel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from the Gumbel distribution on mlx arrays — mlx_rand_gumbel","text":"dim Integer vector specifying array shape/dimensions. dtype Desired MLX dtype (\"float32\" \"float64\"). device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_gumbel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from the Gumbel distribution on mlx arrays — mlx_rand_gumbel","text":"mlx array Gumbel-distributed entries.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_gumbel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample from the Gumbel distribution on mlx arrays — mlx_rand_gumbel","text":"","code":"samples <- mlx_rand_gumbel(c(2, 3))"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_laplace.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from the Laplace distribution on mlx arrays — mlx_rand_laplace","title":"Sample from the Laplace distribution on mlx arrays — mlx_rand_laplace","text":"Sample Laplace distribution mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_laplace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from the Laplace distribution on mlx arrays — mlx_rand_laplace","text":"","code":"mlx_rand_laplace(   dim,   loc = 0,   scale = 1,   dtype = c(\"float32\", \"float64\"),   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_laplace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from the Laplace distribution on mlx arrays — mlx_rand_laplace","text":"dim Integer vector specifying array shape/dimensions. loc Location parameter (mean) Laplace distribution. scale Scale parameter (diversity) Laplace distribution. dtype Desired MLX dtype (\"float32\" \"float64\"). device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_laplace.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from the Laplace distribution on mlx arrays — mlx_rand_laplace","text":"mlx array Laplace-distributed entries.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_laplace.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample from the Laplace distribution on mlx arrays — mlx_rand_laplace","text":"","code":"samples <- mlx_rand_laplace(c(2, 3), loc = 0, scale = 1)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_multivariate_normal.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from a multivariate normal distribution on mlx arrays — mlx_rand_multivariate_normal","title":"Sample from a multivariate normal distribution on mlx arrays — mlx_rand_multivariate_normal","text":"Sample multivariate normal distribution mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_multivariate_normal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from a multivariate normal distribution on mlx arrays — mlx_rand_multivariate_normal","text":"","code":"mlx_rand_multivariate_normal(   dim,   mean,   cov,   dtype = c(\"float32\", \"float64\"),   device = \"cpu\" )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_multivariate_normal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from a multivariate normal distribution on mlx arrays — mlx_rand_multivariate_normal","text":"dim Integer vector specifying array shape/dimensions. mean mlx array vector mean. cov mlx array matrix covariance. dtype Desired MLX dtype (\"float32\" \"float64\"). device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_multivariate_normal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from a multivariate normal distribution on mlx arrays — mlx_rand_multivariate_normal","text":"mlx array samples multivariate normal.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_multivariate_normal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sample from a multivariate normal distribution on mlx arrays — mlx_rand_multivariate_normal","text":"Samples generated CPU: GPU execution currently unavailable covariance factorisation runs host. Supply CPU stream (via mlx_new_stream()) integrate asynchronous flows.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_multivariate_normal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample from a multivariate normal distribution on mlx arrays — mlx_rand_multivariate_normal","text":"","code":"mean <- as_mlx(c(0, 0), device = \"cpu\") cov <- as_mlx(matrix(c(1, 0, 0, 1), 2, 2), device = \"cpu\") samples <- mlx_rand_multivariate_normal(c(100, 2), mean, cov, device = \"cpu\")"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_normal.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from a normal distribution on mlx arrays — mlx_rand_normal","title":"Sample from a normal distribution on mlx arrays — mlx_rand_normal","text":"Sample normal distribution mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_normal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from a normal distribution on mlx arrays — mlx_rand_normal","text":"","code":"mlx_rand_normal(   dim,   mean = 0,   sd = 1,   dtype = c(\"float32\", \"float64\"),   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_normal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from a normal distribution on mlx arrays — mlx_rand_normal","text":"dim Integer vector specifying array shape/dimensions. mean Mean normal distribution. sd Standard deviation normal distribution. dtype Desired MLX dtype (\"float32\" \"float64\"). device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_normal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from a normal distribution on mlx arrays — mlx_rand_normal","text":"mlx array normally distributed entries.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_normal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample from a normal distribution on mlx arrays — mlx_rand_normal","text":"","code":"weights <- mlx_rand_normal(c(3, 3), mean = 0, sd = 0.1)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_permutation.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate random permutations on mlx arrays — mlx_rand_permutation","title":"Generate random permutations on mlx arrays — mlx_rand_permutation","text":"Generate random permutation integers permute entries array along specified axis.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_permutation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate random permutations on mlx arrays — mlx_rand_permutation","text":"","code":"mlx_rand_permutation(x, axis = 0L, device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_permutation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate random permutations on mlx arrays — mlx_rand_permutation","text":"x Either integer n (generate permutation 0:(n-1)), mlx array matrix permute. axis axis along permute x array. Default 0 (permute rows). device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Default: mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_permutation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate random permutations on mlx arrays — mlx_rand_permutation","text":"mlx array containing random permutation.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_permutation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate random permutations on mlx arrays — mlx_rand_permutation","text":"x integer, result created specified device stream; otherwise permutation follows input array's device.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_permutation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate random permutations on mlx arrays — mlx_rand_permutation","text":"","code":"# Generate a random permutation of 0:9 perm <- mlx_rand_permutation(10)  # Permute the rows of a matrix mat <- matrix(1:12, 4, 3) perm_mat <- mlx_rand_permutation(mat)  # Permute columns instead perm_cols <- mlx_rand_permutation(mat, axis = 1)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_randint.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample random integers on mlx arrays — mlx_rand_randint","title":"Sample random integers on mlx arrays — mlx_rand_randint","text":"Generates random integers uniformly distributed interval [low, high).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_randint.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample random integers on mlx arrays — mlx_rand_randint","text":"","code":"mlx_rand_randint(   dim,   low,   high,   dtype = c(\"int32\", \"int64\", \"uint32\", \"uint64\"),   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_randint.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample random integers on mlx arrays — mlx_rand_randint","text":"dim Integer vector specifying array shape/dimensions. low Lower bound (inclusive). high Upper bound (exclusive). dtype Desired integer dtype (\"int32\", \"int64\", \"uint32\", \"uint64\"). device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_randint.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample random integers on mlx arrays — mlx_rand_randint","text":"mlx array random integers.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_randint.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample random integers on mlx arrays — mlx_rand_randint","text":"","code":"# Random integers from 0 to 9 samples <- mlx_rand_randint(c(3, 3), low = 0, high = 10)  # Random integers from -5 to 4 samples <- mlx_rand_randint(c(2, 5), low = -5, high = 5)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_truncated_normal.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from a truncated normal distribution on mlx arrays — mlx_rand_truncated_normal","title":"Sample from a truncated normal distribution on mlx arrays — mlx_rand_truncated_normal","text":"Sample truncated normal distribution mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_truncated_normal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from a truncated normal distribution on mlx arrays — mlx_rand_truncated_normal","text":"","code":"mlx_rand_truncated_normal(   lower,   upper,   dim,   dtype = c(\"float32\", \"float64\"),   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_truncated_normal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from a truncated normal distribution on mlx arrays — mlx_rand_truncated_normal","text":"lower Lower bound truncated normal. upper Upper bound truncated normal. dim Integer vector specifying array shape/dimensions. dtype Desired MLX dtype (\"float32\" \"float64\"). device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_truncated_normal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from a truncated normal distribution on mlx arrays — mlx_rand_truncated_normal","text":"mlx array truncated normally distributed entries.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_truncated_normal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample from a truncated normal distribution on mlx arrays — mlx_rand_truncated_normal","text":"","code":"samples <- mlx_rand_truncated_normal(-1, 1, c(5, 5))"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_uniform.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from a uniform distribution on mlx arrays — mlx_rand_uniform","title":"Sample from a uniform distribution on mlx arrays — mlx_rand_uniform","text":"Sample uniform distribution mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_uniform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from a uniform distribution on mlx arrays — mlx_rand_uniform","text":"","code":"mlx_rand_uniform(   dim,   min = 0,   max = 1,   dtype = c(\"float32\", \"float64\"),   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_uniform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from a uniform distribution on mlx arrays — mlx_rand_uniform","text":"dim Integer vector specifying array shape/dimensions. min Lower bound uniform distribution. max Upper bound uniform distribution. dtype Desired MLX dtype (\"float32\" \"float64\"). device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_uniform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from a uniform distribution on mlx arrays — mlx_rand_uniform","text":"mlx array whose entries sampled uniformly.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_uniform.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample from a uniform distribution on mlx arrays — mlx_rand_uniform","text":"","code":"noise <- mlx_rand_uniform(c(2, 2), min = -1, max = 1)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_real.html","id":null,"dir":"Reference","previous_headings":"","what":"Complex-valued helpers for mlx arrays — mlx_real","title":"Complex-valued helpers for mlx arrays — mlx_real","text":"mlx_real(), mlx_imag(), mlx_conjugate() expose MLX's complex helpers extract real part, imaginary part, complex conjugate mlx array. Corresponding S3 methods Re(), Im(), Conj() also provided.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_real.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Complex-valued helpers for mlx arrays — mlx_real","text":"","code":"mlx_real(x)  mlx_imag(x)  mlx_conjugate(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_real.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Complex-valued helpers for mlx arrays — mlx_real","text":"x mlx array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_real.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Complex-valued helpers for mlx arrays — mlx_real","text":"mlx array containing requested component.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_real.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Complex-valued helpers for mlx arrays — mlx_real","text":"","code":"z <- as_mlx(1:4 + 1i * (4:1)) mlx_real(z) #> mlx array [4] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 1 2 3 4 Im(z) #> mlx array [4] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 4 3 2 1"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_reduction_base.html","id":null,"dir":"Reference","previous_headings":"","what":"Shared arguments for MLX/base reduction helpers. — mlx_reduction_base","title":"Shared arguments for MLX/base reduction helpers. — mlx_reduction_base","text":"Shared arguments MLX/base reduction helpers.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_reduction_base.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shared arguments for MLX/base reduction helpers. — mlx_reduction_base","text":"x array mlx array. na.rm Logical; currently ignored mlx arrays. dims Dimensions passed base implementation x mlx array. ... Additional arguments forwarded base implementation.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_relu.html","id":null,"dir":"Reference","previous_headings":"","what":"Rectified linear activation module — mlx_relu","title":"Rectified linear activation module — mlx_relu","text":"Rectified linear activation module","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_relu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rectified linear activation module — mlx_relu","text":"","code":"mlx_relu()"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_relu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rectified linear activation module — mlx_relu","text":"mlx_module applying ReLU.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_relu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rectified linear activation module — mlx_relu","text":"","code":"act <- mlx_relu() x <- as_mlx(matrix(c(-1, 0, 2), 3, 1)) mlx_forward(act, x) #> mlx array [3 x 1] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] #> [1,]    0 #> [2,]    0 #> [3,]    2"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_repeat.html","id":null,"dir":"Reference","previous_headings":"","what":"Repeat array elements — mlx_repeat","title":"Repeat array elements — mlx_repeat","text":"Repeat array elements","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_repeat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Repeat array elements — mlx_repeat","text":"","code":"mlx_repeat(x, repeats, axis = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_repeat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Repeat array elements — mlx_repeat","text":"x mlx array. repeats Number repetitions. axis Optional axis along repeat. NULL, array flattened repetition (matching NumPy semantics).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_repeat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Repeat array elements — mlx_repeat","text":"mlx array repeated values.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_repeat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Repeat array elements — mlx_repeat","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) mlx_repeat(x, repeats = 2, axis = 2) #> mlx array [2 x 4] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] [,4] #> [1,]    1    1    3    3 #> [2,]    2    2    4    4"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_reshape.html","id":null,"dir":"Reference","previous_headings":"","what":"Reshape an mlx array — mlx_reshape","title":"Reshape an mlx array — mlx_reshape","text":"Reshape mlx array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_reshape.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reshape an mlx array — mlx_reshape","text":"","code":"mlx_reshape(x, newshape)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_reshape.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reshape an mlx array — mlx_reshape","text":"x mlx array. newshape Integer vector specifying new dimensions.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_reshape.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reshape an mlx array — mlx_reshape","text":"mlx array specified shape.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_reshape.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reshape an mlx array — mlx_reshape","text":"","code":"x <- as_mlx(1:12) mlx_reshape(x, c(3, 4)) #> mlx array [3 x 4] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] [,4] #> [1,]    1    2    3    4 #> [2,]    5    6    7    8 #> [3,]    9   10   11   12 mlx_reshape(x, c(2, 6)) #> mlx array [2 x 6] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] [,4] [,5] [,6] #> [1,]    1    2    3    4    5    6 #> [2,]    7    8    9   10   11   12"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_roll.html","id":null,"dir":"Reference","previous_headings":"","what":"Roll array elements — mlx_roll","title":"Roll array elements — mlx_roll","text":"Roll array elements","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_roll.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Roll array elements — mlx_roll","text":"","code":"mlx_roll(x, shift, axis = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_roll.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Roll array elements — mlx_roll","text":"x mlx array. shift Integer vector giving number places elements shifted. axis Optional axis (axes) along elements shifted. NULL, array flattened shifted.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_roll.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Roll array elements — mlx_roll","text":"mlx array elements circularly shifted.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_roll.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Roll array elements — mlx_roll","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) mlx_roll(x, shift = 1, axis = 2) #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]    3    1 #> [2,]    4    2"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_save.html","id":null,"dir":"Reference","previous_headings":"","what":"Save an MLX array to disk — mlx_save","title":"Save an MLX array to disk — mlx_save","text":"Persists MLX array .npy file using MLX's native serialization.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_save.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save an MLX array to disk — mlx_save","text":"","code":"mlx_save(x, file)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_save.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save an MLX array to disk — mlx_save","text":"x Object coercible mlx. file Path output file. file end .npy, extension appended automatically.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_save.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save an MLX array to disk — mlx_save","text":"Invisibly returns full path written, including .npy suffix.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_save.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Save an MLX array to disk — mlx_save","text":"","code":"if (FALSE) { # \\dontrun{ path <- tempfile(fileext = \".mlx\") mlx_save(as_mlx(matrix(1:4, 2, 2), device = \"cpu\"), path) restored <- mlx_load(path, device = \"cpu\") } # }"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_save_gguf.html","id":null,"dir":"Reference","previous_headings":"","what":"Save MLX arrays to the GGUF format — mlx_save_gguf","title":"Save MLX arrays to the GGUF format — mlx_save_gguf","text":"Save MLX arrays GGUF format","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_save_gguf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save MLX arrays to the GGUF format — mlx_save_gguf","text":"","code":"mlx_save_gguf(file, arrays, metadata = list())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_save_gguf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save MLX arrays to the GGUF format — mlx_save_gguf","text":"file Output path. .safetensors appended automatically omitted. arrays Named list objects coercible mlx. metadata Optional named list describing GGUF metadata. Values may character vectors mlx arrays.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_save_gguf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save MLX arrays to the GGUF format — mlx_save_gguf","text":"Invisibly returns full path written.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_save_safetensors.html","id":null,"dir":"Reference","previous_headings":"","what":"Save MLX arrays to the safetensors format — mlx_save_safetensors","title":"Save MLX arrays to the safetensors format — mlx_save_safetensors","text":"Save MLX arrays safetensors format","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_save_safetensors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save MLX arrays to the safetensors format — mlx_save_safetensors","text":"","code":"mlx_save_safetensors(file, arrays, metadata = character())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_save_safetensors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save MLX arrays to the safetensors format — mlx_save_safetensors","text":"file Output path. .safetensors appended automatically omitted. arrays Named list objects coercible mlx. metadata Optional named character vector metadata entries.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_save_safetensors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save MLX arrays to the safetensors format — mlx_save_safetensors","text":"Invisibly returns full path written.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sequential.html","id":null,"dir":"Reference","previous_headings":"","what":"Compose modules sequentially — mlx_sequential","title":"Compose modules sequentially — mlx_sequential","text":"Compose modules sequentially","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sequential.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compose modules sequentially — mlx_sequential","text":"","code":"mlx_sequential(...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sequential.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compose modules sequentially — mlx_sequential","text":"... Modules compose.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sequential.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compose modules sequentially — mlx_sequential","text":"mlx_module.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sequential.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compose modules sequentially — mlx_sequential","text":"","code":"set.seed(1) net <- mlx_sequential(mlx_linear(2, 3), mlx_relu(), mlx_linear(3, 1)) input <- as_mlx(matrix(c(1, 2), 1, 2)) mlx_forward(net, input) #> mlx array [1 x 1] #>   dtype: float32 #>   device: gpu #>   values: #>          [,1] #> [1,] 1.419647"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_set_default_stream.html","id":null,"dir":"Reference","previous_headings":"","what":"Set the default MLX stream — mlx_set_default_stream","title":"Set the default MLX stream — mlx_set_default_stream","text":"Set default MLX stream","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_set_default_stream.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set the default MLX stream — mlx_set_default_stream","text":"","code":"mlx_set_default_stream(stream)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_set_default_stream.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set the default MLX stream — mlx_set_default_stream","text":"stream object created mlx_new_stream() mlx_default_stream().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_set_default_stream.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set the default MLX stream — mlx_set_default_stream","text":"Invisibly returns stream.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_set_default_stream.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set the default MLX stream — mlx_set_default_stream","text":"","code":"stream <- mlx_new_stream() old <- mlx_default_stream() mlx_set_default_stream(stream) mlx_set_default_stream(old)  # restore"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_set_training.html","id":null,"dir":"Reference","previous_headings":"","what":"Toggle training mode for MLX modules — mlx_set_training","title":"Toggle training mode for MLX modules — mlx_set_training","text":"mlx_set_training() switches modules training evaluation modes. Layers implement training-specific behaviour ignore call.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_set_training.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Toggle training mode for MLX modules — mlx_set_training","text":"","code":"mlx_set_training(module, mode = TRUE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_set_training.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Toggle training mode for MLX modules — mlx_set_training","text":"module object inheriting mlx_module. mode Logical flag; TRUE training mode, FALSE evaluation.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_set_training.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Toggle training mode for MLX modules — mlx_set_training","text":"input module (invisibly).","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_set_training.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Toggle training mode for MLX modules — mlx_set_training","text":"","code":"model <- mlx_sequential(mlx_linear(2, 4), mlx_dropout(0.5)) mlx_set_training(model, FALSE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sigmoid.html","id":null,"dir":"Reference","previous_headings":"","what":"Sigmoid activation — mlx_sigmoid","title":"Sigmoid activation — mlx_sigmoid","text":"Sigmoid activation","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sigmoid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sigmoid activation — mlx_sigmoid","text":"","code":"mlx_sigmoid()"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sigmoid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sigmoid activation — mlx_sigmoid","text":"mlx_module applying sigmoid activation.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sigmoid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sigmoid activation — mlx_sigmoid","text":"","code":"act <- mlx_sigmoid() x <- as_mlx(matrix(c(-2, -1, 0, 1, 2), 5, 1)) mlx_forward(act, x) #> mlx array [5 x 1] #>   dtype: float32 #>   device: gpu #>   values: #>           [,1] #> [1,] 0.1192029 #> [2,] 0.2689414 #> [3,] 0.5000000 #> [4,] 0.7310586 #> [5,] 0.8807970"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_silu.html","id":null,"dir":"Reference","previous_headings":"","what":"SiLU (Swish) activation — mlx_silu","title":"SiLU (Swish) activation — mlx_silu","text":"Sigmoid Linear Unit, also known Swish activation.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_silu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"SiLU (Swish) activation — mlx_silu","text":"","code":"mlx_silu()"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_silu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"SiLU (Swish) activation — mlx_silu","text":"mlx_module applying SiLU activation.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_silu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"SiLU (Swish) activation — mlx_silu","text":"","code":"act <- mlx_silu() x <- as_mlx(matrix(c(-2, -1, 0, 1, 2), 5, 1)) mlx_forward(act, x) #> mlx array [5 x 1] #>   dtype: float32 #>   device: gpu #>   values: #>            [,1] #> [1,] -0.2384058 #> [2,] -0.2689414 #> [3,]  0.0000000 #> [4,]  0.7310586 #> [5,]  1.7615941"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_slice_update.html","id":null,"dir":"Reference","previous_headings":"","what":"Update a slice of an mlx array — mlx_slice_update","title":"Update a slice of an mlx array — mlx_slice_update","text":"Wrapper around mlx.core.slice_update() replaces contiguous strided region value.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_slice_update.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update a slice of an mlx array — mlx_slice_update","text":"","code":"mlx_slice_update(x, value, start, stop, strides = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_slice_update.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update a slice of an mlx array — mlx_slice_update","text":"x mlx array. value Replacement mlx (coercible) array. Must broadcast slice determined start, stop, strides. start Integer vector (0-indexed) giving starting index axis. stop Integer vector (exclusive) giving stopping index axis. strides Optional integer vector strides (defaults ones).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_slice_update.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update a slice of an mlx array — mlx_slice_update","text":"mlx array specified slice replaced.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_slice_update.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Update a slice of an mlx array — mlx_slice_update","text":"","code":"x <- as_mlx(matrix(1:9, 3, 3)) replacement <- as_mlx(matrix(100:103, nrow = 2)) updated <- mlx_slice_update(x, replacement, start = c(0L, 1L), stop = c(2L, 3L)) as.matrix(updated) #>      [,1] [,2] [,3] #> [1,]    1  100  102 #> [2,]    2  101  103 #> [3,]    3    6    9"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_softmax.html","id":null,"dir":"Reference","previous_headings":"","what":"Softmax for mlx arrays — mlx_softmax","title":"Softmax for mlx arrays — mlx_softmax","text":"Softmax mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_softmax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Softmax for mlx arrays — mlx_softmax","text":"","code":"mlx_softmax(x, axis = NULL, precise = FALSE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_softmax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Softmax for mlx arrays — mlx_softmax","text":"x mlx array, R array/matrix/vector converted via as_mlx(). axis Optional axis operate (1-indexed like R). NULL, array flattened first. precise Logical; compute higher precision stability.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_softmax.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Softmax for mlx arrays — mlx_softmax","text":"mlx array normalized probabilities.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_softmax.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Softmax for mlx arrays — mlx_softmax","text":"","code":"x <- as_mlx(matrix(c(1, 2, 3, 4, 5, 6), 2, 3)) sm <- mlx_softmax(x, axis = 2) rowSums(as.matrix(sm)) #> [1] 1 1"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_softmax_layer.html","id":null,"dir":"Reference","previous_headings":"","what":"Softmax activation — mlx_softmax_layer","title":"Softmax activation — mlx_softmax_layer","text":"Softmax activation","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_softmax_layer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Softmax activation — mlx_softmax_layer","text":"","code":"mlx_softmax_layer(axis = -1L)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_softmax_layer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Softmax activation — mlx_softmax_layer","text":"axis Axis along apply softmax (default: -1, last axis).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_softmax_layer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Softmax activation — mlx_softmax_layer","text":"mlx_module applying softmax activation.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_softmax_layer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Softmax activation — mlx_softmax_layer","text":"","code":"act <- mlx_softmax_layer() x <- as_mlx(matrix(1:6, 2, 3)) mlx_forward(act, x) #> mlx array [2 x 3] #>   dtype: float32 #>   device: gpu #>   values: #>            [,1]      [,2]      [,3] #> [1,] 0.01587624 0.1173104 0.8668134 #> [2,] 0.01587624 0.1173104 0.8668134"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_solve_triangular.html","id":null,"dir":"Reference","previous_headings":"","what":"Solve triangular systems with mlx arrays — mlx_solve_triangular","title":"Solve triangular systems with mlx arrays — mlx_solve_triangular","text":"Solve triangular systems mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_solve_triangular.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solve triangular systems with mlx arrays — mlx_solve_triangular","text":"","code":"mlx_solve_triangular(a, b, upper = FALSE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_solve_triangular.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solve triangular systems with mlx arrays — mlx_solve_triangular","text":"mlx triangular matrix. b Right-hand side matrix vector. upper Logical; TRUE, upper triangular, otherwise lower.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_solve_triangular.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solve triangular systems with mlx arrays — mlx_solve_triangular","text":"mlx array solution.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_solve_triangular.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Solve triangular systems with mlx arrays — mlx_solve_triangular","text":"","code":"a <- as_mlx(matrix(c(2, 1, 0, 3), 2, 2)) b <- as_mlx(matrix(c(1, 5), 2, 1)) mlx_solve_triangular(a, b, upper = FALSE) #> mlx array [2 x 1] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] #> [1,]  0.5 #> [2,]  1.5"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sort.html","id":null,"dir":"Reference","previous_headings":"","what":"Sort and argsort for mlx arrays — mlx_sort","title":"Sort and argsort for mlx arrays — mlx_sort","text":"mlx_sort() returns sorted values along specified axis. mlx_argsort() returns indices sort array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sort.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sort and argsort for mlx arrays — mlx_sort","text":"","code":"mlx_sort(x, axis = NULL)  mlx_argsort(x, axis = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sort.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sort and argsort for mlx arrays — mlx_sort","text":"x mlx array, R array/matrix/vector converted via as_mlx(). axis Optional axis operate (1-indexed like R). NULL, array flattened first.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sort.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sort and argsort for mlx arrays — mlx_sort","text":"mlx array containing sorted values (mlx_sort()) 1-based indices (mlx_argsort()). indices follow R's indexing convention can used directly R's [ operator.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sort.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sort and argsort for mlx arrays — mlx_sort","text":"mlx_argsort() returns 1-based indices sort array ascending order. follows R's indexing convention (unlike underlying MLX library uses 0-based indexing). returned indices can used directly reorder original array. partial sorting (finding elements certain rank without fully sorting), see mlx_partition() mlx_argpartition().","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sort.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sort and argsort for mlx arrays — mlx_sort","text":"","code":"x <- as_mlx(c(3, 1, 4, 2)) mlx_sort(x) #> mlx array [4] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 1 2 3 4  # Returns 1-based indices idx <- mlx_argsort(x) as.integer(as.matrix(idx))  # [1] 2 4 1 3 #> [1] 2 4 1 3  # Can be used directly with R indexing original <- c(3, 1, 4, 2) sorted_idx <- as.integer(as.matrix(mlx_argsort(as_mlx(original)))) original[sorted_idx]  # [1] 1 2 3 4 #> [1] 1 2 3 4  mlx_sort(as_mlx(matrix(1:6, 2, 3)), axis = 1) #> mlx array [2 x 3] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] #> [1,]    1    3    5 #> [2,]    2    4    6"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_squeeze.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove singleton dimensions — mlx_squeeze","title":"Remove singleton dimensions — mlx_squeeze","text":"Remove singleton dimensions","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_squeeze.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove singleton dimensions — mlx_squeeze","text":"","code":"mlx_squeeze(x, axis = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_squeeze.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove singleton dimensions — mlx_squeeze","text":"x mlx array. axis Optional integer vector axes (1-indexed) remove. NULL axes length one removed.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_squeeze.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove singleton dimensions — mlx_squeeze","text":"mlx array selected axes removed.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_squeeze.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove singleton dimensions — mlx_squeeze","text":"","code":"x <- as_mlx(array(1:4, dim = c(1, 2, 2, 1))) mlx_squeeze(x) #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]    1    3 #> [2,]    2    4 mlx_squeeze(x, axis = 1) #> mlx array [2 x 2 x 1] #>   dtype: float32 #>   device: gpu #>   (4 elements, not shown)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_stack.html","id":null,"dir":"Reference","previous_headings":"","what":"Stack mlx arrays along a new axis — mlx_stack","title":"Stack mlx arrays along a new axis — mlx_stack","text":"Stack mlx arrays along new axis","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_stack.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stack mlx arrays along a new axis — mlx_stack","text":"","code":"mlx_stack(..., axis = 1L)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_stack.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stack mlx arrays along a new axis — mlx_stack","text":"... One arrays (single list arrays) coercible mlx. axis Position new axis (1-indexed, negative values count end).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_stack.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stack mlx arrays along a new axis — mlx_stack","text":"mlx array one additional dimension.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_stack.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stack mlx arrays along a new axis — mlx_stack","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) y <- as_mlx(matrix(5:8, 2, 2)) stacked <- mlx_stack(x, y, axis = 1)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_stop_gradient.html","id":null,"dir":"Reference","previous_headings":"","what":"Stop gradient propagation through an mlx array — mlx_stop_gradient","title":"Stop gradient propagation through an mlx array — mlx_stop_gradient","text":"Stop gradient propagation mlx array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_stop_gradient.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stop gradient propagation through an mlx array — mlx_stop_gradient","text":"","code":"mlx_stop_gradient(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_stop_gradient.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stop gradient propagation through an mlx array — mlx_stop_gradient","text":"x mlx array, R array/matrix/vector converted via as_mlx().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_stop_gradient.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stop gradient propagation through an mlx array — mlx_stop_gradient","text":"new mlx array identical values zero gradient.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_stop_gradient.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stop gradient propagation through an mlx array — mlx_stop_gradient","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) mlx_stop_gradient(x) #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]    1    3 #> [2,]    2    4"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_subset.html","id":null,"dir":"Reference","previous_headings":"","what":"Subset MLX array — mlx_subset","title":"Subset MLX array — mlx_subset","text":"Subset MLX array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_subset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subset MLX array — mlx_subset","text":"","code":"# S3 method for class 'mlx' x[..., drop = FALSE]  # S3 method for class 'mlx' x[...] <- value"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_subset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subset MLX array — mlx_subset","text":"x mlx array, R array/matrix/vector converted via as_mlx(). ... Indices dimension. Provide one per axis; omitted indices select full extent. Logical indices recycle dimension length. drop dimensions dropped? (default: FALSE) value Replacement value(s) \\code{[<-} (scalar, vector, matrix, array) recycled match selection.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_subset.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subset MLX array — mlx_subset","text":"Subsetted mlx object","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_subset.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Subset MLX array — mlx_subset","text":"","code":"x <- as_mlx(matrix(1:9, 3, 3)) x[1, ] #> mlx array [1 x 3] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] #> [1,]    1    4    7"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sum.html","id":null,"dir":"Reference","previous_headings":"","what":"Reduce mlx arrays — mlx_sum","title":"Reduce mlx arrays — mlx_sum","text":"helpers mirror NumPy-style reductions, optionally collapsing one axes. Use drop = FALSE retain reduced axes length one (akin setting drop = FALSE base R).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reduce mlx arrays — mlx_sum","text":"","code":"mlx_sum(x, axis = NULL, drop = TRUE)  mlx_prod(x, axis = NULL, drop = TRUE)  mlx_all(x, axis = NULL, drop = TRUE)  mlx_any(x, axis = NULL, drop = TRUE)  mlx_mean(x, axis = NULL, drop = TRUE)  mlx_var(x, axis = NULL, drop = TRUE, ddof = 0L)  mlx_std(x, axis = NULL, drop = TRUE, ddof = 0L)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reduce mlx arrays — mlx_sum","text":"x mlx array, R array/matrix/vector converted via as_mlx(). axis Optional integer vector axes (1-indexed) reduce. NULL, reduction performed elements. drop Logical flag controlling dimension dropping: TRUE (default) removes reduced axes, FALSE retains length one. ddof Non-negative integer delta degrees freedom variance standard deviation reductions.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reduce mlx arrays — mlx_sum","text":"mlx array containing reduction result.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sum.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reduce mlx arrays — mlx_sum","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) mlx_sum(x) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 10 mlx_sum(x, axis = 1) #> mlx array [2] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 3 7 mlx_prod(x, axis = 2, drop = FALSE) #> mlx array [2 x 1] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] #> [1,]    3 #> [2,]    8 mlx_all(x > 0) #> mlx array [] #>   dtype: bool #>   device: gpu #>   values: #> [1] TRUE mlx_any(x > 3) #> mlx array [] #>   dtype: bool #>   device: gpu #>   values: #> [1] TRUE mlx_mean(x, axis = 1) #> mlx array [2] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 1.5 3.5 mlx_var(x, axis = 2) #> mlx array [2] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 1 1 mlx_std(x, ddof = 1) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 1.290994"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_swapaxes.html","id":null,"dir":"Reference","previous_headings":"","what":"Swap two axes of an mlx array — mlx_swapaxes","title":"Swap two axes of an mlx array — mlx_swapaxes","text":"mlx_swapaxes() mirrors mlx.core.swapaxes(), exchanging two dimensions leaving others intact.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_swapaxes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Swap two axes of an mlx array — mlx_swapaxes","text":"","code":"mlx_swapaxes(x, axis1, axis2)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_swapaxes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Swap two axes of an mlx array — mlx_swapaxes","text":"x mlx array. axis1, axis2 Axes swap (1-indexed, negatives count end).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_swapaxes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Swap two axes of an mlx array — mlx_swapaxes","text":"mlx array specified axes exchanged.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_swapaxes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Swap two axes of an mlx array — mlx_swapaxes","text":"","code":"x <- as_mlx(array(1:24, dim = c(2, 3, 4))) swapped <- mlx_swapaxes(x, axis1 = 1, axis2 = 3) dim(swapped) #> [1] 4 3 2"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_synchronize.html","id":null,"dir":"Reference","previous_headings":"","what":"Synchronize MLX execution — mlx_synchronize","title":"Synchronize MLX execution — mlx_synchronize","text":"Waits outstanding operations specified device stream complete.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_synchronize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Synchronize MLX execution — mlx_synchronize","text":"","code":"mlx_synchronize(device = c(\"gpu\", \"cpu\"))"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_synchronize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Synchronize MLX execution — mlx_synchronize","text":"device Device identifier (\"gpu\" \"cpu\") mlx_stream created mlx_new_stream().","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_synchronize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Synchronize MLX execution — mlx_synchronize","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) mlx_synchronize(\"gpu\") stream <- mlx_new_stream() mlx_synchronize(stream)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tanh.html","id":null,"dir":"Reference","previous_headings":"","what":"Tanh activation — mlx_tanh","title":"Tanh activation — mlx_tanh","text":"Tanh activation","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tanh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tanh activation — mlx_tanh","text":"","code":"mlx_tanh()"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tanh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tanh activation — mlx_tanh","text":"mlx_module applying hyperbolic tangent activation.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tanh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tanh activation — mlx_tanh","text":"","code":"act <- mlx_tanh() x <- as_mlx(matrix(c(-2, -1, 0, 1, 2), 5, 1)) mlx_forward(act, x) #> mlx array [5 x 1] #>   dtype: float32 #>   device: gpu #>   values: #>            [,1] #> [1,] -0.9640276 #> [2,] -0.7615941 #> [3,]  0.0000000 #> [4,]  0.7615941 #> [5,]  0.9640276"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tile.html","id":null,"dir":"Reference","previous_headings":"","what":"Tile an array — mlx_tile","title":"Tile an array — mlx_tile","text":"Tile array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tile an array — mlx_tile","text":"","code":"mlx_tile(x, reps)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tile an array — mlx_tile","text":"x mlx array. reps Integer vector giving number repetitions axis.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tile.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tile an array — mlx_tile","text":"mlx array tiled content.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tile.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tile an array — mlx_tile","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) mlx_tile(x, reps = c(1, 2)) #> mlx array [2 x 4] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] [,4] #> [1,]    1    3    1    3 #> [2,]    2    4    2    4"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_topk.html","id":null,"dir":"Reference","previous_headings":"","what":"Top-k selection and partitioning on mlx arrays — mlx_topk","title":"Top-k selection and partitioning on mlx arrays — mlx_topk","text":"mlx_topk() returns largest k values. mlx_partition() mlx_argpartition() perform partial sorting, rearranging elements element position kth correctly sorted position, smaller elements larger elements . efficient full sorting need elements certain rank.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_topk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Top-k selection and partitioning on mlx arrays — mlx_topk","text":"","code":"mlx_topk(x, k, axis = NULL)  mlx_partition(x, kth, axis = NULL)  mlx_argpartition(x, kth, axis = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_topk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Top-k selection and partitioning on mlx arrays — mlx_topk","text":"x mlx array, R array/matrix/vector converted via as_mlx(). k Positive integer specifying number elements select. axis Optional axis operate (1-indexed like R). NULL, array flattened first. kth Zero-based index element placed -order partitioning.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_topk.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Top-k selection and partitioning on mlx arrays — mlx_topk","text":"mlx array. mlx_argpartition(), returns 1-based indices (following R conventions) showing partition ordering.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_topk.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Top-k selection and partitioning on mlx arrays — mlx_topk","text":"mlx_topk() returns largest k values along specified axis. mlx_partition() rearranges elements kth element correctly positioned. mlx_argpartition() returns 1-based indices partition array. follows R's indexing convention (unlike underlying MLX library uses 0-based indexing). Use mlx_argsort() need fully sorted indices.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_topk.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Top-k selection and partitioning on mlx arrays — mlx_topk","text":"","code":"scores <- as_mlx(c(0.7, 0.2, 0.9, 0.4)) mlx_topk(scores, k = 2) #> mlx array [2] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 0.7 0.9 mlx_partition(scores, kth = 1) #> mlx array [4] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 0.2 0.4 0.7 0.9  # Returns 1-based indices idx <- mlx_argpartition(scores, kth = 1) as.integer(as.matrix(idx))  # 1-based indices #> [1] 2 4 1 3  mlx_topk(as_mlx(matrix(1:6, 2, 3)), k = 1, axis = 1) #> mlx array [1 x 3] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] #> [1,]    2    4    6"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_trace.html","id":null,"dir":"Reference","previous_headings":"","what":"Matrix trace for mlx arrays — mlx_trace","title":"Matrix trace for mlx arrays — mlx_trace","text":"Computes sum diagonal elements 2D array, sum along diagonals higher dimensional array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_trace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matrix trace for mlx arrays — mlx_trace","text":"","code":"mlx_trace(x, offset = 0L, axis1 = 1L, axis2 = 2L)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_trace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matrix trace for mlx arrays — mlx_trace","text":"x mlx array. offset Offset diagonal (0 main diagonal, positive , negative ). axis1, axis2 Axes along diagonals taken (1-indexed, default 1 2).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_trace.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Matrix trace for mlx arrays — mlx_trace","text":"mlx scalar array containing trace.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_trace.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Matrix trace for mlx arrays — mlx_trace","text":"","code":"x <- as_mlx(matrix(1:9, 3, 3)) mlx_trace(x) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 15 mlx_trace(x, offset = 1) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 12"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_train_step.html","id":null,"dir":"Reference","previous_headings":"","what":"Single training step helper — mlx_train_step","title":"Single training step helper — mlx_train_step","text":"Single training step helper","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_train_step.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Single training step helper — mlx_train_step","text":"","code":"mlx_train_step(module, loss_fn, optimizer, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_train_step.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Single training step helper — mlx_train_step","text":"module mlx_module. loss_fn Function module data returning mlx scalar. optimizer Optimizer object mlx_optimizer_sgd(). ... Additional data passed loss_fn.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_train_step.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Single training step helper — mlx_train_step","text":"list current loss.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_train_step.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Single training step helper — mlx_train_step","text":"","code":"set.seed(1) model <- mlx_linear(2, 1, bias = FALSE) opt <- mlx_optimizer_sgd(mlx_parameters(model), lr = 0.1) data_x <- as_mlx(matrix(c(1, 2, 3, 4), 2, 2)) data_y <- as_mlx(matrix(c(1, 2), 2, 1)) loss_fn <- function(mod, x, y) {   preds <- mlx_forward(mod, x)   diff <- preds - y   sum(diff * diff) } mlx_train_step(model, loss_fn, opt, data_x, data_y) #> $loss #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 7.49876 #>"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tri.html","id":null,"dir":"Reference","previous_headings":"","what":"Triangular helpers for MLX arrays — mlx_tri","title":"Triangular helpers for MLX arrays — mlx_tri","text":"mlx_tri() creates lower-triangular mask (ones diagonal, zeros elsewhere). mlx_tril() mlx_triu() retain lower upper triangular part existing array, respectively.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tri.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Triangular helpers for MLX arrays — mlx_tri","text":"","code":"mlx_tri(   n,   m = NULL,   k = 0L,   dtype = c(\"float32\", \"float64\"),   device = mlx_default_device() )  mlx_tril(x, k = 0L)  mlx_triu(x, k = 0L)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tri.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Triangular helpers for MLX arrays — mlx_tri","text":"n Number rows. m Optional number columns (defaults n square output). k Diagonal offset: 0 selects main diagonal, positive values move upper diagonals, negative values lower diagonals. dtype MLX dtype use (\"float32\" \"float64\"). device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device(). x Object coercible mlx.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tri.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Triangular helpers for MLX arrays — mlx_tri","text":"mlx array.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tri.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Triangular helpers for MLX arrays — mlx_tri","text":"","code":"mlx_tri(3)          # 3x3 lower-triangular mask #> mlx array [3 x 3] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] #> [1,]    1    0    0 #> [2,]    1    1    0 #> [3,]    1    1    1 mlx_tril(diag(3) + 2)  # keep lower part of a matrix #> mlx array [3 x 3] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] #> [1,]    3    0    0 #> [2,]    2    3    0 #> [3,]    2    2    3"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tri_inv.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute triangular matrix inverse — mlx_tri_inv","title":"Compute triangular matrix inverse — mlx_tri_inv","text":"Computes inverse triangular matrix.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tri_inv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute triangular matrix inverse — mlx_tri_inv","text":"","code":"mlx_tri_inv(x, upper = FALSE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tri_inv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute triangular matrix inverse — mlx_tri_inv","text":"x mlx array. upper Logical; TRUE, x upper triangular, otherwise lower triangular.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tri_inv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute triangular matrix inverse — mlx_tri_inv","text":"inverse triangular matrix x.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tri_inv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute triangular matrix inverse — mlx_tri_inv","text":"","code":"# Lower triangular matrix L <- as_mlx(matrix(c(1, 2, 0, 3, 0, 0, 4, 5, 6), 3, 3, byrow = TRUE)) L_inv <- mlx_tri_inv(L, upper = FALSE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_unflatten.html","id":null,"dir":"Reference","previous_headings":"","what":"Unflatten an axis into multiple axes — mlx_unflatten","title":"Unflatten an axis into multiple axes — mlx_unflatten","text":"reverse flattening: expands single axis multiple axes given shape.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_unflatten.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unflatten an axis into multiple axes — mlx_unflatten","text":"","code":"mlx_unflatten(x, axis, shape)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_unflatten.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unflatten an axis into multiple axes — mlx_unflatten","text":"x mlx array. axis axis unflatten (1-indexed). shape Integer vector specifying new shape unflattened axis.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_unflatten.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unflatten an axis into multiple axes — mlx_unflatten","text":"mlx array axis expanded.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_unflatten.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unflatten an axis into multiple axes — mlx_unflatten","text":"","code":"# Flatten and unflatten x <- as_mlx(array(1:24, c(2, 3, 4))) x_flat <- mlx_reshape(x, c(2, 12))  # flatten last two dims mlx_unflatten(x_flat, axis = 2, shape = c(3, 4))  # restore original shape #> mlx array [2 x 3 x 4] #>   dtype: float32 #>   device: gpu #>   (24 elements, not shown)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_where.html","id":null,"dir":"Reference","previous_headings":"","what":"Elementwise conditional selection — mlx_where","title":"Elementwise conditional selection — mlx_where","text":"Elementwise conditional selection","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_where.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Elementwise conditional selection — mlx_where","text":"","code":"mlx_where(condition, x, y)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_where.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Elementwise conditional selection — mlx_where","text":"condition Logical mlx array (non-zero values treated TRUE). x, y Arrays broadcastable shape condition.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_where.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Elementwise conditional selection — mlx_where","text":"mlx array elements drawn x condition TRUE, otherwise y.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_where.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Elementwise conditional selection — mlx_where","text":"Behaves like ifelse() arrays, evaluates branches.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_where.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Elementwise conditional selection — mlx_where","text":"","code":"cond <- as_mlx(matrix(c(TRUE, FALSE, TRUE, FALSE), 2, 2)) a <- as_mlx(matrix(1:4, 2, 2)) b <- as_mlx(matrix(5:8, 2, 2)) mlx_where(cond, a, b) #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]    1    3 #> [2,]    6    8"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_zeros.html","id":null,"dir":"Reference","previous_headings":"","what":"Create arrays of zeros on MLX devices — mlx_zeros","title":"Create arrays of zeros on MLX devices — mlx_zeros","text":"Create arrays zeros MLX devices","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_zeros.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create arrays of zeros on MLX devices — mlx_zeros","text":"","code":"mlx_zeros(   dim,   dtype = c(\"float32\", \"float64\", \"int8\", \"int16\", \"int32\", \"int64\", \"uint8\", \"uint16\",     \"uint32\", \"uint64\", \"bool\", \"complex64\"),   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_zeros.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create arrays of zeros on MLX devices — mlx_zeros","text":"dim Integer vector specifying array shape/dimensions. dtype MLX dtype use. One \"float32\", \"float64\", \"int8\", \"int16\", \"int32\", \"int64\", \"uint8\", \"uint16\", \"uint32\", \"uint64\", \"bool\", \"complex64\". device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_zeros.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create arrays of zeros on MLX devices — mlx_zeros","text":"mlx array filled zeros.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_zeros.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create arrays of zeros on MLX devices — mlx_zeros","text":"","code":"zeros <- mlx_zeros(c(2, 3)) zeros_int <- mlx_zeros(c(2, 3), dtype = \"int32\")"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_zeros_like.html","id":null,"dir":"Reference","previous_headings":"","what":"Zeros shaped like an existing mlx array — mlx_zeros_like","title":"Zeros shaped like an existing mlx array — mlx_zeros_like","text":"mlx_zeros_like() mirrors mlx.core.zeros_like(): creates zero-filled array matching source array's shape. Optionally override dtype device.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_zeros_like.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Zeros shaped like an existing mlx array — mlx_zeros_like","text":"","code":"mlx_zeros_like(x, dtype = NULL, device = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_zeros_like.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Zeros shaped like an existing mlx array — mlx_zeros_like","text":"x mlx array. dtype Optional MLX dtype override. Defaults source array's dtype. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Default: mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_zeros_like.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Zeros shaped like an existing mlx array — mlx_zeros_like","text":"mlx array zeros matching x.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_zeros_like.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Zeros shaped like an existing mlx array — mlx_zeros_like","text":"","code":"base <- mlx_ones(c(2, 2)) zeros <- mlx_zeros_like(base) as.matrix(zeros) #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0"},{"path":"https://hughjonesd.github.io/Rmlx/reference/outer.html","id":null,"dir":"Reference","previous_headings":"","what":"Outer product of two vectors — outer","title":"Outer product of two vectors — outer","text":"Outer product two vectors","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/outer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Outer product of two vectors — outer","text":"","code":"outer(X, Y, FUN = \"*\", ...)  # S3 method for class 'mlx' outer(X, Y, FUN = \"*\", ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/outer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Outer product of two vectors — outer","text":"X, Y Numeric vectors mlx arrays. FUN Function apply (default method). ... Additional arguments passed methods.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/outer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Outer product of two vectors — outer","text":"mlx inputs, mlx matrix. Otherwise delegates base::outer.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/outer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Outer product of two vectors — outer","text":"","code":"x <- as_mlx(c(1, 2, 3)) y <- as_mlx(c(4, 5)) outer(x, y) #> mlx array [3 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]    4    5 #> [2,]    8   10 #> [3,]   12   15"},{"path":"https://hughjonesd.github.io/Rmlx/reference/pinv.html","id":null,"dir":"Reference","previous_headings":"","what":"Moore-Penrose pseudoinverse for MLX arrays — pinv","title":"Moore-Penrose pseudoinverse for MLX arrays — pinv","text":"Moore-Penrose pseudoinverse MLX arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/pinv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Moore-Penrose pseudoinverse for MLX arrays — pinv","text":"","code":"pinv(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/pinv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Moore-Penrose pseudoinverse for MLX arrays — pinv","text":"x mlx object coercible matrix.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/pinv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Moore-Penrose pseudoinverse for MLX arrays — pinv","text":"mlx object containing pseudoinverse.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/pinv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Moore-Penrose pseudoinverse for MLX arrays — pinv","text":"","code":"x <- as_mlx(matrix(c(1, 2, 3, 4), 2, 2)) pinv(x) #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1]       [,2] #> [1,]   -2  1.5000004 #> [2,]    1 -0.5000001"},{"path":"https://hughjonesd.github.io/Rmlx/reference/print.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Print MLX array — print.mlx","title":"Print MLX array — print.mlx","text":"Print MLX array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/print.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print MLX array — print.mlx","text":"","code":"# S3 method for class 'mlx' print(x, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/print.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print MLX array — print.mlx","text":"x mlx array, R array/matrix/vector converted via as_mlx(). ... Additional arguments (ignored)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/print.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print MLX array — print.mlx","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) print(x) #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]    1    3 #> [2,]    2    4"},{"path":"https://hughjonesd.github.io/Rmlx/reference/qr.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"QR decomposition for mlx arrays — qr.mlx","title":"QR decomposition for mlx arrays — qr.mlx","text":"QR decomposition mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/qr.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"QR decomposition for mlx arrays — qr.mlx","text":"","code":"# S3 method for class 'mlx' qr(x, tol = 1e-07, LAPACK = FALSE, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/qr.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"QR decomposition for mlx arrays — qr.mlx","text":"x mlx matrix (2-dimensional array). tol Ignored; custom tolerances supported. LAPACK Ignored; set FALSE. ... Additional arguments (unused).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/qr.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"QR decomposition for mlx arrays — qr.mlx","text":"list components Q R, mlx matrix.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/qr.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"QR decomposition for mlx arrays — qr.mlx","text":"","code":"x <- as_mlx(matrix(c(1, 2, 3, 4, 5, 6), 3, 2)) qr(x) #> $Q #> mlx array [3 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>            [,1]       [,2] #> [1,] -0.2672611  0.8728715 #> [2,] -0.5345225  0.2182179 #> [3,] -0.8017837 -0.4364358 #>  #> $R #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>           [,1]      [,2] #> [1,] -3.741657 -8.552359 #> [2,]  0.000000  1.963961 #>  #> attr(,\"class\") #> [1] \"mlx_qr\" \"list\""},{"path":"https://hughjonesd.github.io/Rmlx/reference/rbind.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Row-bind mlx arrays — rbind.mlx","title":"Row-bind mlx arrays — rbind.mlx","text":"Row-bind mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/rbind.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Row-bind mlx arrays — rbind.mlx","text":"","code":"# S3 method for class 'mlx' rbind(..., deparse.level = 1)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/rbind.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Row-bind mlx arrays — rbind.mlx","text":"... Objects bind. mlx arrays kept MLX; inputs coerced via as_mlx(). deparse.level Compatibility argument accepted S3 dispatch; ignored.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/rbind.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Row-bind mlx arrays — rbind.mlx","text":"mlx array stacked along first axis.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/rbind.mlx.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Row-bind mlx arrays — rbind.mlx","text":"Unlike base R's rbind(), function supports arrays 2 dimensions preserves dimensions except first (summed across inputs). Base R's rbind() flattens higher-dimensional arrays matrices binding.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/rbind.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Row-bind mlx arrays — rbind.mlx","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) y <- as_mlx(matrix(5:8, 2, 2)) rbind(x, y) #> mlx array [4 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]    1    3 #> [2,]    2    4 #> [3,]    5    7 #> [4,]    6    8"},{"path":"https://hughjonesd.github.io/Rmlx/reference/rowMeans.html","id":null,"dir":"Reference","previous_headings":"","what":"Row means for mlx arrays — rowMeans","title":"Row means for mlx arrays — rowMeans","text":"Row means mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/rowMeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Row means for mlx arrays — rowMeans","text":"","code":"rowMeans(x, ...)  # Default S3 method rowMeans(x, na.rm = FALSE, dims = 1, ...)  # S3 method for class 'mlx' rowMeans(x, na.rm = FALSE, dims = 1, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/rowMeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Row means for mlx arrays — rowMeans","text":"x array mlx array. ... Additional arguments forwarded base implementation. na.rm Logical; currently ignored mlx arrays. dims Dimensions passed base implementation x mlx array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/rowMeans.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Row means for mlx arrays — rowMeans","text":"mlx array x mlx, otherwise numeric vector.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/rowMeans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Row means for mlx arrays — rowMeans","text":"","code":"x <- as_mlx(matrix(1:6, 3, 2)) rowMeans(x) #> mlx array [3] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 2.5 3.5 4.5"},{"path":"https://hughjonesd.github.io/Rmlx/reference/rowSums.html","id":null,"dir":"Reference","previous_headings":"","what":"Row sums for mlx arrays — rowSums","title":"Row sums for mlx arrays — rowSums","text":"Row sums mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/rowSums.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Row sums for mlx arrays — rowSums","text":"","code":"rowSums(x, ...)  # Default S3 method rowSums(x, na.rm = FALSE, dims = 1, ...)  # S3 method for class 'mlx' rowSums(x, na.rm = FALSE, dims = 1, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/rowSums.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Row sums for mlx arrays — rowSums","text":"x array mlx array. ... Additional arguments forwarded base implementation. na.rm Logical; currently ignored mlx arrays. dims Dimensions passed base implementation x mlx array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/rowSums.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Row sums for mlx arrays — rowSums","text":"mlx array x mlx, otherwise numeric vector.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/rowSums.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Row sums for mlx arrays — rowSums","text":"","code":"x <- as_mlx(matrix(1:6, 3, 2)) rowSums(x) #> mlx array [3] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 5 7 9"},{"path":"https://hughjonesd.github.io/Rmlx/reference/solve.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Solve a system of linear equations — solve.mlx","title":"Solve a system of linear equations — solve.mlx","text":"Solve system linear equations","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/solve.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solve a system of linear equations — solve.mlx","text":"","code":"# S3 method for class 'mlx' solve(a, b = NULL, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/solve.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solve a system of linear equations — solve.mlx","text":"mlx matrix (coefficient matrix) b mlx vector matrix (right-hand side). omitted, computes matrix inverse. ... Additional arguments (compatibility base::solve)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/solve.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solve a system of linear equations — solve.mlx","text":"mlx object containing solution","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/solve.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Solve a system of linear equations — solve.mlx","text":"","code":"a <- as_mlx(matrix(c(3, 1, 1, 2), 2, 2)) b <- as_mlx(c(9, 8)) solve(a, b) #> mlx array [2] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 2 3"},{"path":"https://hughjonesd.github.io/Rmlx/reference/str.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Object structure for MLX array — str.mlx","title":"Object structure for MLX array — str.mlx","text":"Object structure MLX array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/str.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Object structure for MLX array — str.mlx","text":"","code":"# S3 method for class 'mlx' str(object, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/str.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Object structure for MLX array — str.mlx","text":"object mlx object ... Additional arguments (ignored)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/str.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Object structure for MLX array — str.mlx","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) str(x) #> mlx [2 x 2] float32 on gpu"},{"path":"https://hughjonesd.github.io/Rmlx/reference/svd.html","id":null,"dir":"Reference","previous_headings":"","what":"Singular value decomposition — svd","title":"Singular value decomposition — svd","text":"Generic function SVD computation.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/svd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Singular value decomposition — svd","text":"","code":"svd(x, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/svd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Singular value decomposition — svd","text":"x object. ... Additional arguments.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/svd.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Singular value decomposition for mlx arrays — svd.mlx","title":"Singular value decomposition for mlx arrays — svd.mlx","text":"Note mlx's svd returns \"full\" SVD, U V' square matrices. different R's implementation.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/svd.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Singular value decomposition for mlx arrays — svd.mlx","text":"","code":"# S3 method for class 'mlx' svd(x, nu = min(n, p), nv = min(n, p), ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/svd.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Singular value decomposition for mlx arrays — svd.mlx","text":"x mlx matrix (2-dimensional array). nu Number left singular vectors return (0 min(dim(x))). nv Number right singular vectors return (0 min(dim(x))). ... Additional arguments (unused).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/svd.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Singular value decomposition for mlx arrays — svd.mlx","text":"list components d, u, v.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/svd.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Singular value decomposition for mlx arrays — svd.mlx","text":"","code":"x <- as_mlx(matrix(c(1, 0, 0, 2), 2, 2)) svd(x) #> $d #> mlx array [2] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 2 1 #>  #> $u #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]    0    1 #> [2,]    1    0 #>  #> $v #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]    0    1 #> [2,]    1    0 #>"},{"path":"https://hughjonesd.github.io/Rmlx/reference/t.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Transpose of MLX matrix — t.mlx","title":"Transpose of MLX matrix — t.mlx","text":"Transpose MLX matrix","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/t.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transpose of MLX matrix — t.mlx","text":"","code":"# S3 method for class 'mlx' t(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/t.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transpose of MLX matrix — t.mlx","text":"x mlx matrix (2-dimensional array).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/t.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transpose of MLX matrix — t.mlx","text":"Transposed mlx matrix","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/t.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transpose of MLX matrix — t.mlx","text":"","code":"x <- as_mlx(matrix(1:6, 2, 3)) t(x) #> mlx array [3 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]    1    2 #> [2,]    3    4 #> [3,]    5    6"},{"path":"https://hughjonesd.github.io/Rmlx/reference/tcrossprod.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Transposed cross product — tcrossprod.mlx","title":"Transposed cross product — tcrossprod.mlx","text":"Transposed cross product","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/tcrossprod.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transposed cross product — tcrossprod.mlx","text":"","code":"# S3 method for class 'mlx' tcrossprod(x, y = NULL, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/tcrossprod.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transposed cross product — tcrossprod.mlx","text":"x mlx matrix (2-dimensional array). y mlx matrix (default: NULL, uses x) ... Additional arguments passed base::tcrossprod.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/tcrossprod.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transposed cross product — tcrossprod.mlx","text":"x %*% t(y) mlx object","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/tcrossprod.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transposed cross product — tcrossprod.mlx","text":"","code":"x <- as_mlx(matrix(1:6, 2, 3)) tcrossprod(x) #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]   35   44 #> [2,]   44   56"},{"path":"https://hughjonesd.github.io/Rmlx/reference/with_default_device.html","id":null,"dir":"Reference","previous_headings":"","what":"Temporarily set the default MLX device — with_default_device","title":"Temporarily set the default MLX device — with_default_device","text":"Temporarily set default MLX device","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/with_default_device.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temporarily set the default MLX device — with_default_device","text":"","code":"with_default_device(device = c(\"gpu\", \"cpu\"), code)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/with_default_device.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Temporarily set the default MLX device — with_default_device","text":"device Device use (\"gpu\" \"cpu\"). code Expression evaluate device active.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/with_default_device.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Temporarily set the default MLX device — with_default_device","text":"result evaluating code.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/with_default_device.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Temporarily set the default MLX device — with_default_device","text":"","code":"old <- mlx_default_device() with_default_device(\"cpu\", mlx_default_device()) #> [1] \"cpu\" mlx_default_device(old) #> [1] \"gpu\""},{"path":"https://hughjonesd.github.io/Rmlx/news/index.html","id":"rmlx-0109000-development","dir":"Changelog","previous_headings":"","what":"Rmlx 0.1.0.9000 (development)","title":"Rmlx 0.1.0.9000 (development)","text":"Added mlx_fft(), mlx_fft2(), mlx_fftn() wrappers around MLX FFT kernels aligned pkgdown coverage.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/news/index.html","id":"rmlx-010","dir":"Changelog","previous_headings":"","what":"Rmlx 0.1.0","title":"Rmlx 0.1.0","text":"Initial release r-universe.","code":""}]
