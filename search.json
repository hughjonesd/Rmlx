[{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/AGENTS.html","id":"project-structure--module-organization","dir":"","previous_headings":"","what":"Project Structure & Module Organization","title":"Repository Guidelines","text":"R/ holds exported R wrappers, S3 methods, roxygen docs; mirror existing files like ops.R adding API surface. src/ contains Rcpp glue MLX (mlx_bindings.cpp, mlx_ops.cpp); keep headers sync RcppExports.R. tests/testthat/ groups unit specs domain (test-math.R, test-matmul.R); add new files test-feature.R. vignettes/getting-started.Rmd introduces workflows; update adding user-facing features. configure, DESCRIPTION, NAMESPACE manage build-time detection package metadata; configure step runs automatically install.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/AGENTS.html","id":"build-test-and-development-commands","dir":"","previous_headings":"","what":"Build, Test, and Development Commands","title":"Repository Guidelines","text":"R -q -e 'Rcpp::compileAttributes()' regenerates RcppExports touching headers .cpp. R -q -e 'devtools::document()' rebuilds NAMESPACE Rd files roxygen comments. R -q -e 'devtools::build()' creates source tarball; R -q -e 'devtools::check()' runs formal package checks. R -q -e 'devtools::test()' runs testthat suite; use R -q -e 'devtools::load_all()' rapid iteration.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/AGENTS.html","id":"coding-style--naming-conventions","dir":"","previous_headings":"","what":"Coding Style & Naming Conventions","title":"Repository Guidelines","text":"Use two-space indents R C++; keep lines 100 characters match current style. Prefer snake_case R helpers (as_mlx), S3 methods Generic.class (Math.mlx). C++ helpers follow descriptive snake_case RAII patterns; include <mlx/mlx.h> via mlx_bindings.hpp. Document R functions roxygen #' blocks; let @export drive NAMESPACE entries.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/AGENTS.html","id":"testing-guidelines","dir":"","previous_headings":"","what":"Testing Guidelines","title":"Repository Guidelines","text":"Write tests testthat tests/testthat; mirror existing structure keep scenario-focused blocks within test_that. Use CPU-friendly fixtures (small matrices) GPU CPU paths run quickly. Run R -q -e 'devtools::test()' locally; conditional skips—tests allowed fail MLX absent.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/AGENTS.html","id":"commit--pull-request-guidelines","dir":"","previous_headings":"","what":"Commit & Pull Request Guidelines","title":"Repository Guidelines","text":"Follow repository’s imperative, capitalized commit style (e.g., Add rowSums helper); keep subject lines near 70 characters. PR link issues relevant, summarize API changes, note Metal/CPU devices covered. opening PR, run R -q -e 'devtools::document()', R -q -e 'devtools::test()', R -q -e 'devtools::check()'; include notable outputs screenshots performance-sensitive work.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":null,"dir":"","previous_headings":"","what":"CLAUDE.md","title":"CLAUDE.md","text":"file provides guidance Claude Code (claude.ai/code) working code repository.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"package-overview","dir":"","previous_headings":"","what":"Package Overview","title":"CLAUDE.md","text":"Rmlx R interface Apple’s MLX (Machine Learning eXchange) library GPU-accelerated array operations Apple Silicon. package provides lazy evaluation, S3 operator overloading, familiar R syntax GPU computing. Requirements: - macOS Apple Silicon (M1/M2/M3+) - MLX C/C++ library installed - Rcpp R/C++ integration","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"building-and-testing","dir":"","previous_headings":"Development Commands","what":"Building and Testing","title":"CLAUDE.md","text":"R -q -e 'Rcpp::compileAttributes()' - Generate Rcpp exports modifying C++ code (ALWAYS run first) R -q -e 'devtools::document()' - Generate documentation roxygen comments R -q -e 'devtools::load_all()' - Load package interactive development R -q -e 'devtools::build()' - Build package R -q -e 'devtools::check()' - Run R CMD check R -q -e 'devtools::test()' - Run tests","code":""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"installing","dir":"","previous_headings":"Development Commands","what":"Installing","title":"CLAUDE.md","text":"R -q -e 'devtools::install()' - Install package locally (requires MLX)","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"mlx-installation","dir":"","previous_headings":"System Requirements","what":"MLX Installation","title":"CLAUDE.md","text":"package requires MLX headers library. Configure script searches: - /opt/homebrew/include/mlx/c/mlx.h (headers) - /opt/homebrew/lib/libmlx.dylib (library) - /usr/local/include, /usr/local/lib (alternatives) Override environment variables:","code":"export MLX_INCLUDE=/path/to/mlx/include export MLX_LIB_DIR=/path/to/mlx/lib export MLX_LIBS=\"-lmlx\""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"build-process","dir":"","previous_headings":"System Requirements","what":"Build Process","title":"CLAUDE.md","text":"configure script detects MLX writes src/Makevars cleanup script removes generated src/Makevars Build fails gracefully helpful error MLX found","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"c-core-src","dir":"","previous_headings":"Architecture","what":"C++ Core (src/)","title":"CLAUDE.md","text":"mlx_bindings.hpp/cpp - RAII wrapper, array creation, conversion, evaluation mlx_ops.cpp - Unary ops, binary ops, reductions, matrix ops, slicing init.cpp - R package registration RcppExports.cpp - Auto-generated Rcpp::compileAttributes() Key design: - MlxArray class wraps mlx_array* RAII semantics - External pointers R finalizers memory management - C++ functions exported via [[Rcpp::export]]","code":""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"r-code-r","dir":"","previous_headings":"Architecture","what":"R Code (R/)","title":"CLAUDE.md","text":"class.R - S3 class, constructors, converters (as_mlx, .matrix.mlx, mlx_eval) ops.R - Operator overloading (Ops.mlx, %*%.mlx) stats.R - Reductions matrix helpers (sum, mean, colMeans, t, crossprod) utils.R - Print, indexing [.mlx, accessors (dim, length) device.R - Device management (mlx_default_device, mlx_synchronize) Rmlx-package.R - Package documentation RcppExports.R - Auto-generated Rcpp::compileAttributes()","code":""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"key-features","dir":"","previous_headings":"Architecture","what":"Key Features","title":"CLAUDE.md","text":"Lazy evaluation - Operations build computation graph; evaluate mlx_eval() .matrix() S3 dispatch - Standard R syntax: +, -, *, /, ^, %*%, t(), etc. Broadcasting - NumPy-style broadcasting binary ops GPU/CPU - Default GPU; switch mlx_default_device()","code":""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"mlx-c-api-assumptions","dir":"","previous_headings":"Architecture","what":"MLX C API Assumptions","title":"CLAUDE.md","text":"C++ code assumes MLX C API functions like: - mlx_array_from_data(), mlx_array_free(), mlx_array_eval() - mlx_array_add(), mlx_array_matmul(), mlx_array_transpose() - mlx_array_sum(), mlx_array_mean(), etc. IMPORTANT: actual MLX C API function names may differ. compilation errors occur, check MLX documentation update function names src/mlx_bindings.cpp src/mlx_ops.cpp.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"mlx-headers-not-found","dir":"","previous_headings":"Common Issues","what":"MLX headers not found","title":"CLAUDE.md","text":"Install MLX: brew install mlx (available) build source Set MLX_INCLUDE environment variable Check header path /path//include/mlx/c/mlx.h","code":""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"wrong-mlx-function-names","dir":"","previous_headings":"Common Issues","what":"Wrong MLX function names","title":"CLAUDE.md","text":"MLX C API may different naming conventions Check #include <mlx/c/mlx.h> equivalent header Update function calls src/mlx_bindings.cpp src/mlx_ops.cpp","code":""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"axis-confusion-row-major-vs-column-major","dir":"","previous_headings":"Common Issues","what":"Axis confusion (row-major vs column-major)","title":"CLAUDE.md","text":"R uses column-major order MLX uses row-major order Tests verify colMeans/rowMeans map correct axes tests fail, swap axis=0 axis=1 reductions","code":""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"testing","dir":"","previous_headings":"","what":"Testing","title":"CLAUDE.md","text":"Tests tests/testthat/: - tests skip package can’t load (MLX available) - Use tolerance = 1e-6 floating-point comparisons - Compare base R results correctness Run specific test file:","code":"R -q -e 'devtools::test_file(\"tests/testthat/test-ops.R\")'"},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"CLAUDE.md","text":"Roxygen2 comments R files Vignette vignettes/getting-started.Rmd Examples use \\dontrun{} since MLX required editing docs: possible, use usethis:: package commands things canonical way. array type doesn’t default constructor!","code":"R -q -e 'devtools::document()'"},{"path":"https://hughjonesd.github.io/Rmlx/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 Rmlx authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/articles/getting-started.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Getting Started with Rmlx","text":"Apple MLX (Machine Learning eXchange) Apple’s high-performance array machine-learning framework Apple Silicon, built top Metal GPU execution optimized CPU kernels. offers lazy evaluation, vectorized math, automatic differentiation, neural network building blocks (see official MLX documentation full details). Rmlx thin R layer MLX lets : Create MLX tensors R data (as_mlx()). Run GPU-accelerated math, linear algebra, FFTs, reductions familiar R syntax. Use automatic differentiation (mlx_grad(), mlx_value_grad()) optimization. Build simple models MLX modules update using SGD helpers. heavy computation stays MLX land; copy back base R call functions like .matrix(). ## System Requirements using Rmlx, ensure MLX installed:","code":"# Using Homebrew (if available) brew install mlx  # Or build from source git clone https://github.com/ml-explore/mlx.git cd mlx && mkdir build && cd build cmake .. && make && sudo make install"},{"path":"https://hughjonesd.github.io/Rmlx/articles/getting-started.html","id":"creating-mlx-arrays","dir":"Articles","previous_headings":"","what":"Creating MLX Arrays","title":"Getting Started with Rmlx","text":"Convert R objects MLX arrays using as_mlx(): Precision note: Numeric inputs stored single precision (float32). Requesting dtype = \"float64\" downcast input warning. Logical inputs stored MLX bool tensors (logical NA values supported). Complex inputs stored complex64 (single-precision real imaginary parts). Use base R arrays need double precision arithmetic.","code":"library(Rmlx) #>  #> Attaching package: 'Rmlx' #> The following object is masked from 'package:stats': #>  #>     fft #> The following objects are masked from 'package:base': #>  #>     colMeans, colSums, rowMeans, rowSums  # From a vector v <- as_mlx(1:10) print(v) #> mlx array [10] #>   dtype: float32 #>   device: gpu #>   values: #>  [1]  1  2  3  4  5  6  7  8  9 10  # From a matrix m <- matrix(1:12, nrow = 3, ncol = 4) x <- as_mlx(m) print(x) #> mlx array [3 x 4] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] [,4] #> [1,]    1    4    7   10 #> [2,]    2    5    8   11 #> [3,]    3    6    9   12  # Move the array to the GPU x_gpu <- as_mlx(m, device = \"gpu\")"},{"path":"https://hughjonesd.github.io/Rmlx/articles/getting-started.html","id":"lazy-evaluation","dir":"Articles","previous_headings":"","what":"Lazy Evaluation","title":"Getting Started with Rmlx","text":"MLX arrays use lazy evaluation - operations recorded computed needed:","code":"# These operations are not computed immediately x <- as_mlx(matrix(1:100, 10, 10)) y <- as_mlx(matrix(101:200, 10, 10)) z <- x + y * 2  # Force evaluation of a specific array mlx_eval(z)  # Or convert to R (automatically evaluates) as.matrix(z) #>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] #>  [1,]  203  233  263  293  323  353  383  413  443   473 #>  [2,]  206  236  266  296  326  356  386  416  446   476 #>  [3,]  209  239  269  299  329  359  389  419  449   479 #>  [4,]  212  242  272  302  332  362  392  422  452   482 #>  [5,]  215  245  275  305  335  365  395  425  455   485 #>  [6,]  218  248  278  308  338  368  398  428  458   488 #>  [7,]  221  251  281  311  341  371  401  431  461   491 #>  [8,]  224  254  284  314  344  374  404  434  464   494 #>  [9,]  227  257  287  317  347  377  407  437  467   497 #> [10,]  230  260  290  320  350  380  410  440  470   500  # Wait for all queued work on the GPU if needed mlx_synchronize(\"gpu\")"},{"path":"https://hughjonesd.github.io/Rmlx/articles/getting-started.html","id":"arithmetic-operations","dir":"Articles","previous_headings":"","what":"Arithmetic Operations","title":"Getting Started with Rmlx","text":"Rmlx supports standard arithmetic operators:","code":"x <- as_mlx(matrix(1:12, 3, 4)) y <- as_mlx(matrix(13:24, 3, 4))  # Element-wise operations sum_xy <- x + y diff_xy <- x - y prod_xy <- x * y quot_xy <- x / y pow_xy <- x ^ 2  # Convert back to R to see results as.matrix(sum_xy) #>      [,1] [,2] [,3] [,4] #> [1,]   14   20   26   32 #> [2,]   16   22   28   34 #> [3,]   18   24   30   36"},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/articles/getting-started.html","id":"matrix-multiplication","dir":"Articles","previous_headings":"Matrix Operations","what":"Matrix Multiplication","title":"Getting Started with Rmlx","text":"","code":"a <- as_mlx(matrix(1:6, 2, 3)) b <- as_mlx(matrix(1:6, 3, 2))  # Matrix multiplication c <- a %*% b as.matrix(c) #>      [,1] [,2] #> [1,]   22   49 #> [2,]   28   64"},{"path":"https://hughjonesd.github.io/Rmlx/articles/getting-started.html","id":"transpose","dir":"Articles","previous_headings":"Matrix Operations","what":"Transpose","title":"Getting Started with Rmlx","text":"","code":"x <- as_mlx(matrix(1:12, 3, 4)) x_t <- t(x) print(x_t) #> mlx array [4 x 3] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] #> [1,]    1    2    3 #> [2,]    4    5    6 #> [3,]    7    8    9 #> [4,]   10   11   12"},{"path":"https://hughjonesd.github.io/Rmlx/articles/getting-started.html","id":"cross-products","dir":"Articles","previous_headings":"Matrix Operations","what":"Cross Products","title":"Getting Started with Rmlx","text":"","code":"x <- as_mlx(matrix(rnorm(20), 5, 4)) true_w <- as_mlx(matrix(c(2, -1, 0.5, 0.25), 4, 1)) y <- x %*% true_w w <- as_mlx(matrix(0, 4, 1))  # Loss must stay entirely in MLX-land: no conversions back to base R loss <- function(theta, data_x, data_y) {   preds <- data_x %*% theta   resids <- preds - data_y   sum(resids * resids) / length(data_y) }  grads <- mlx_grad(loss, w, x, y)  # Wrong: converting to base R breaks the gradient bad_loss <- function(theta, data_x, data_y) {   preds <- as.matrix(data_x %*% theta)  # leaves MLX   resids <- preds - as.matrix(data_y)   sum(resids * resids) / nrow(resids) } try(mlx_grad(bad_loss, w, x, y)) #> Error in eval(expr, envir) :  #>   MLX autograd failed to differentiate the function: Gradient function must return an `mlx` object. Ensure your closure keeps computations in MLX or wraps the result with as_mlx(). #> Ensure all differentiable computations use MLX operations.  # A small SGD loop using the module/optimizer helpers model <- mlx_linear(4, 1, bias = FALSE)  # learns a single weight vector parameters <- mlx_parameters(model) opt <- mlx_optimizer_sgd(parameters, lr = 0.1) loss_fn <- function(mod, data_x, data_y) {   theta <- mlx_param_values(parameters)[[1]]   loss(theta, data_x, data_y) }  loss_history <- numeric(50) for (step in seq_along(loss_history)) {   step_res <- mlx_train_step(model, loss_fn, opt, x, y)   loss_history[step] <- as.vector(step_res$loss) }  # Check final loss and inspect learned parameters final_loss <- mlx_forward(model, x) residual_mse <- as.vector(mean((final_loss - y) * (final_loss - y))) residual_mse #> [1] 5.658819e-05 loss_history #>  [1] 8.308889e+00 4.272983e+00 2.288200e+00 1.283615e+00 7.582743e-01 #>  [6] 4.726674e-01 3.102017e-01 2.130744e-01 1.520021e-01 1.117421e-01 #> [11] 8.408680e-02 6.443550e-02 5.009037e-02 3.939489e-02 3.128565e-02 #> [16] 2.505323e-02 2.020860e-02 1.640565e-02 1.339452e-02 1.099170e-02 #> [21] 9.060724e-03 7.498934e-03 6.228307e-03 5.189063e-03 4.335000e-03 #> [26] 3.630075e-03 3.046037e-03 2.560509e-03 2.155664e-03 1.817213e-03 #> [31] 1.533631e-03 1.295554e-03 1.095328e-03 9.267041e-04 7.845016e-04 #> [36] 6.644622e-04 5.630297e-04 4.772589e-04 4.046760e-04 3.432218e-04 #> [41] 2.911653e-04 2.470508e-04 2.096552e-04 1.779418e-04 1.510463e-04 #> [46] 1.282235e-04 1.088608e-04 9.242821e-05 7.848036e-05 6.664058e-05  learned_w <- mlx_param_values(parameters)[[1]] as.matrix(learned_w) #>            [,1] #> [1,]  1.9941052 #> [2,] -1.0081218 #> [3,]  0.4934084 #> [4,]  0.2496413 as.matrix(true_w) #>       [,1] #> [1,]  2.00 #> [2,] -1.00 #> [3,]  0.50 #> [4,]  0.25"},{"path":"https://hughjonesd.github.io/Rmlx/articles/getting-started.html","id":"reductions","dir":"Articles","previous_headings":"","what":"Reductions","title":"Getting Started with Rmlx","text":"Compute summaries across arrays:","code":"x <- as_mlx(matrix(1:100, 10, 10))  # Overall reductions sum(x) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 5050 mean(x) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 50.5  # Column and row means colMeans(x) #> mlx array [10] #>   dtype: float32 #>   device: gpu #>   values: #>  [1]  5.5 15.5 25.5 35.5 45.5 55.5 65.5 75.5 85.5 95.5 rowMeans(x) #> mlx array [10] #>   dtype: float32 #>   device: gpu #>   values: #>  [1] 46 47 48 49 50 51 52 53 54 55  # Convert to R to see values as.matrix(colMeans(x)) #>  [1]  5.5 15.5 25.5 35.5 45.5 55.5 65.5 75.5 85.5 95.5  # Cumulative operations flatten the array in column-major order as.vector(cumsum(x)) #>   [1]    1    3    6   10   15   21   28   36   45   55   66   78   91  105  120 #>  [16]  136  153  171  190  210  231  253  276  300  325  351  378  406  435  465 #>  [31]  496  528  561  595  630  666  703  741  780  820  861  903  946  990 1035 #>  [46] 1081 1128 1176 1225 1275 1326 1378 1431 1485 1540 1596 1653 1711 1770 1830 #>  [61] 1891 1953 2016 2080 2145 2211 2278 2346 2415 2485 2556 2628 2701 2775 2850 #>  [76] 2926 3003 3081 3160 3240 3321 3403 3486 3570 3655 3741 3828 3916 4005 4095 #>  [91] 4186 4278 4371 4465 4560 4656 4753 4851 4950 5050"},{"path":"https://hughjonesd.github.io/Rmlx/articles/getting-started.html","id":"indexing","dir":"Articles","previous_headings":"","what":"Indexing","title":"Getting Started with Rmlx","text":"Subset MLX arrays similar R:","code":"x <- as_mlx(matrix(1:100, 10, 10))  # Select rows and columns x_sub <- x[1:5, 1:5]  # Select specific row row_1 <- x[1, ]  # Select specific column col_1 <- x[, 1]"},{"path":"https://hughjonesd.github.io/Rmlx/articles/getting-started.html","id":"device-management","dir":"Articles","previous_headings":"","what":"Device Management","title":"Getting Started with Rmlx","text":"Control whether computations run GPU CPU: Remember numeric computations always performed float32; CPU mode useful need compare base R debug without GPU.","code":"# Check default device mlx_default_device() #> [1] \"gpu\"  # Set to CPU for debugging mlx_default_device(\"cpu\") #> [1] \"cpu\"  # Create array on CPU x_cpu <- as_mlx(matrix(1:12, 3, 4), device = \"cpu\")  # Set back to GPU mlx_default_device(\"gpu\") #> [1] \"gpu\""},{"path":"https://hughjonesd.github.io/Rmlx/articles/getting-started.html","id":"performance-comparison","dir":"Articles","previous_headings":"","what":"Performance Comparison","title":"Getting Started with Rmlx","text":"’s simple timing comparison large matrix multiplication: Note: informal comparison, rigorous benchmark. Performance gains depend array size, operation type, hardware.","code":"n <- 1000  # R base m1 <- matrix(rnorm(n * n), n, n) m2 <- matrix(rnorm(n * n), n, n) t1 <- system.time(r_result <- m1 %*% m2)  # MLX x1 <- as_mlx(m1) x2 <- as_mlx(m2) mlx_eval(x1) mlx_eval(x2) t2 <- system.time({   mlx_result <- x1 %*% x2   mlx_eval(mlx_result)   final <- as.matrix(mlx_result) })  cat(\"Base R:\", t1[\"elapsed\"], \"seconds\\n\") #> Base R: 0.719 seconds cat(\"MLX:\", t2[\"elapsed\"], \"seconds\\n\") #> MLX: 0.009 seconds"},{"path":"https://hughjonesd.github.io/Rmlx/articles/getting-started.html","id":"best-practices","dir":"Articles","previous_headings":"","what":"Best Practices","title":"Getting Started with Rmlx","text":"Keep data GPU: Minimize transfers R MLX Use lazy evaluation: Build computation graphs evaluating Batch operations: Combine operations forcing evaluation Monitor memory: GPU memory limited; free unused arrays Start CPU: Use CPU device debugging, switch GPU","code":""},{"path":"https://hughjonesd.github.io/Rmlx/articles/getting-started.html","id":"limitations","dir":"Articles","previous_headings":"","what":"Limitations","title":"Getting Started with Rmlx","text":"Current limitations initial version: Apple Silicon (Intel Mac platforms) 2D arrays (matrices) primary focus Limited indexing operations autodiff gradient computation (planned future release)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/articles/performance.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Performance Benchmarks","text":"vignette compares runtime core operations base R Rmlx.","code":"library(Rmlx) #>  #> Attaching package: 'Rmlx' #> The following object is masked from 'package:stats': #>  #>     fft #> The following objects are masked from 'package:base': #>  #>     colMeans, colSums, rowMeans, rowSums library(bench) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(ggplot2)"},{"path":"https://hughjonesd.github.io/Rmlx/articles/performance.html","id":"matrix-addition","dir":"Articles","previous_headings":"","what":"Matrix addition","title":"Performance Benchmarks","text":"","code":"mat_sizes <- c(256, 512, 1024) add_results <- bind_rows(lapply(mat_sizes, function(n) {   A_r <- matrix(runif(n * n), n, n)   B_r <- matrix(runif(n * n), n, n)   A_mlx <- as_mlx(A_r)   B_mlx <- as_mlx(B_r)    mb <- bench::mark(     base = { A_r + B_r },     rmlx = { as.matrix(A_mlx + B_mlx) },     iterations = 5,     check = FALSE   )   mb$size <- n   mb }))  ggplot(add_results, aes(x = factor(size), y = as.numeric(median),                          fill = as.character(expression))) +   geom_col(position = \"dodge\") +   labs(     title = \"Matrix addition timing (median)\",     x = \"Matrix dimension\",     y = \"Median time\",     fill = \"Implementation\"   )"},{"path":"https://hughjonesd.github.io/Rmlx/articles/performance.html","id":"matrix-multiplication","dir":"Articles","previous_headings":"","what":"Matrix multiplication","title":"Performance Benchmarks","text":"","code":"matmul_results <- bind_rows(lapply(mat_sizes, function(n) {   A_r <- matrix(runif(n * n), n, n)   B_r <- matrix(runif(n * n), n, n)   A_mlx <- as_mlx(A_r)   B_mlx <- as_mlx(B_r)    mb <- bench::mark(     base = { A_r %*% B_r },     rmlx = { as.matrix(A_mlx %*% B_mlx) },     iterations = 3,     check = FALSE   )   mb$size <- n   mb }))  ggplot(matmul_results, aes(x = factor(size), y = as.numeric(median),                          fill = as.character(expression))) +   geom_col(position = \"dodge\") +   labs(     title = \"Matrix multiplication timing (median)\",     x = \"Matrix dimension\",     y = \"Median time\",     fill = \"Implementation\"   )"},{"path":"https://hughjonesd.github.io/Rmlx/articles/performance.html","id":"linear-system-solves","dir":"Articles","previous_headings":"","what":"Linear system solves","title":"Performance Benchmarks","text":"","code":"solve_results <- bind_rows(lapply(mat_sizes, function(n) {   A_r <- matrix(rnorm(n * n), n, n)   A_r <- crossprod(A_r) + diag(n) * 1e-3   b_r <- matrix(rnorm(n), n, 1)   A_mlx <- as_mlx(A_r)   b_mlx <- as_mlx(b_r)    mb <- bench::mark(     base = { solve(A_r, b_r) },     rmlx = { as.matrix(solve(A_mlx, b_mlx)) },     iterations = 3,     check = FALSE   )   mb$size <- n   mb }))  ggplot(solve_results, aes(x = factor(size), y = as.numeric(median),                          fill = as.character(expression))) +   geom_col(position = \"dodge\") +   labs(     title = \"Linear solve timing (median)\",     x = \"Matrix dimension\",     y = \"Median time\",     fill = \"Implementation\"   )"},{"path":"https://hughjonesd.github.io/Rmlx/articles/performance.html","id":"notes","dir":"Articles","previous_headings":"","what":"Notes","title":"Performance Benchmarks","text":"Numeric data resides single-precision (float32) stored mlx arrays; logical data uses MLX bool, complex data uses complex64. comparing timings, make sure MLX configured GPU execution consider calling mlx_synchronize(\"gpu\") reading results avoid asynchronous delays. exact speedups vary depending problem size, GPU available, whether GPU already warm.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"David Hugh-Jones. Author, maintainer.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Hugh-Jones D (2025). Rmlx: R Interface Apple's MLX Arrays (GPU-Accelerated Apple Silicon). R package version 0.0.0.9000, https://hughjonesd.github.io/Rmlx/.","code":"@Manual{,   title = {Rmlx: R Interface to Apple's MLX Arrays (GPU-Accelerated on Apple Silicon)},   author = {David Hugh-Jones},   year = {2025},   note = {R package version 0.0.0.9000},   url = {https://hughjonesd.github.io/Rmlx/}, }"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"rmlx","dir":"","previous_headings":"","what":"R Interface to Apple's MLX Arrays (GPU-Accelerated on Apple Silicon)","title":"R Interface to Apple's MLX Arrays (GPU-Accelerated on Apple Silicon)","text":"R interface Apple’s MLX (Machine Learning eXchange) library GPU-accelerated array operations Apple Silicon.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"R Interface to Apple's MLX Arrays (GPU-Accelerated on Apple Silicon)","text":"Rmlx provides R interface Apple’s MLX framework, enabling high-performance GPU computing Apple Silicon (M1, M2, M3+) using Metal backend. package implements lazy evaluation familiar R syntax S3 method dispatch. Status: Phase 1 implementation complete (arrays, operations, evaluation, tests, documentation). Phase 2 (autodiff, optimizers) yet implemented.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"requirements","dir":"","previous_headings":"","what":"Requirements","title":"R Interface to Apple's MLX Arrays (GPU-Accelerated on Apple Silicon)","text":"macOS Apple Silicon (M1/M2/M3 later) MLX C/C++ library installed R >= 4.1.0 Rcpp >= 1.0.10","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"install-mlx","dir":"","previous_headings":"Installation","what":"Install MLX","title":"R Interface to Apple's MLX Arrays (GPU-Accelerated on Apple Silicon)","text":"First, install MLX library:","code":"# Option 1: Homebrew (if available) brew install mlx  # Option 2: Build from source git clone https://github.com/ml-explore/mlx.git cd mlx mkdir build && cd build cmake .. make sudo make install"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"install-rmlx","dir":"","previous_headings":"Installation","what":"Install Rmlx","title":"R Interface to Apple's MLX Arrays (GPU-Accelerated on Apple Silicon)","text":"","code":"# Install from source devtools::install()  # Or with custom MLX paths Sys.setenv(MLX_INCLUDE = \"/path/to/mlx/include\") Sys.setenv(MLX_LIB_DIR = \"/path/to/mlx/lib\") devtools::install()"},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"lazy-evaluation","dir":"","previous_headings":"Features","what":"Lazy Evaluation","title":"R Interface to Apple's MLX Arrays (GPU-Accelerated on Apple Silicon)","text":"Operations recorded executed explicitly evaluated:","code":"library(Rmlx) #>  #> Attaching package: 'Rmlx' #> The following object is masked from 'package:stats': #>  #>     fft #> The following objects are masked from 'package:base': #>  #>     colMeans, colSums, rowMeans, rowSums  x <- as_mlx(matrix(1:100, 10, 10)) y <- as_mlx(matrix(101:200, 10, 10))  # Lazy - not computed yet z <- x + y * 2  # Force evaluation mlx_eval(z)  # Or convert to R (automatically evaluates) result <- as.matrix(z)  # Wait for queued GPU work (useful when timing) mlx_synchronize(\"gpu\")  # Simple aggregate checks sum(z) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 35150 mean(z) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 351.5"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"arithmetic-operations","dir":"","previous_headings":"Features","what":"Arithmetic Operations","title":"R Interface to Apple's MLX Arrays (GPU-Accelerated on Apple Silicon)","text":"Standard R operators work seamlessly:","code":"x <- as_mlx(matrix(1:12, 3, 4)) y <- as_mlx(matrix(13:24, 3, 4))  # Element-wise operations sum_xy <- x + y diff_xy <- x - y prod_xy <- x * y quot_xy <- x / y pow_xy <- x ^ 2  # Comparisons lt <- x < y eq <- x == y  # Bring results back to R as.matrix(sum_xy) #>      [,1] [,2] [,3] [,4] #> [1,]   14   20   26   32 #> [2,]   16   22   28   34 #> [3,]   18   24   30   36 as.matrix(lt) #>      [,1] [,2] [,3] [,4] #> [1,] TRUE TRUE TRUE TRUE #> [2,] TRUE TRUE TRUE TRUE #> [3,] TRUE TRUE TRUE TRUE"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"matrix-operations","dir":"","previous_headings":"Features","what":"Matrix Operations","title":"R Interface to Apple's MLX Arrays (GPU-Accelerated on Apple Silicon)","text":"Advanced decompositions mirror base R:","code":"a <- as_mlx(matrix(1:6, 2, 3)) b <- as_mlx(matrix(1:6, 3, 2))  # Matrix multiplication c <- a %*% b as.matrix(c) #>      [,1] [,2] #> [1,]   22   49 #> [2,]   28   64"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"random-sampling","dir":"","previous_headings":"Features","what":"Random Sampling","title":"R Interface to Apple's MLX Arrays (GPU-Accelerated on Apple Silicon)","text":"","code":"random_tensor <- mlx_rand_uniform(c(512, 512), min = -1, max = 1) random_tensor #> mlx array [512 x 512] #>   dtype: float32 #>   device: gpu #>   (262144 elements, not shown) qr_res <- qr(a) svd_res <- svd(a) chol_res <- chol(as_mlx(crossprod(matrix(1:6, 3, 2)))) fft_res <- fft(a)  # Inspect outputs qr_res$Q #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>            [,1]       [,2] #> [1,] -0.4472135 -0.8944272 #> [2,] -0.8944272  0.4472136 svd_res$d #> [1] 9.5255181 0.5143006 as.matrix(chol_res) #>          [,1]     [,2] #> [1,] 3.741657 8.552360 #> [2,] 0.000000 1.963962"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"differentiation","dir":"","previous_headings":"Features","what":"Differentiation","title":"R Interface to Apple's MLX Arrays (GPU-Accelerated on Apple Silicon)","text":"","code":"loss <- function(w, x, y) {   preds <- x %*% w   resids <- preds - y   sum(resids * resids) / length(y) }  x <- as_mlx(matrix(rnorm(20), 5, 4)) y <- as_mlx(matrix(rnorm(5), 5, 1)) w <- as_mlx(matrix(0, 4, 1))  grads <- mlx_grad(loss, w, x, y)  # Inspect gradient as.matrix(grads[[1]]) #>             [,1] #> [1,] -0.53908861 #> [2,]  0.03495799 #> [3,]  0.31788656 #> [4,]  0.08960838  # Simple SGD loop model <- mlx_linear(4, 1, bias = FALSE) opt <- mlx_optimizer_sgd(mlx_parameters(model), lr = 0.1) loss_fn <- function(mod, data_x, data_y) {   preds <- mlx_forward(mod, data_x)   resids <- preds - data_y   sum(resids * resids) / length(data_y) } for (step in 1:50) {   mlx_train_step(model, loss_fn, opt, x, y) }  # Check final loss final_loss <- mlx_forward(model, x) mean((final_loss - y) * (final_loss - y)) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 0.03953141"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"reductions","dir":"","previous_headings":"Features","what":"Reductions","title":"R Interface to Apple's MLX Arrays (GPU-Accelerated on Apple Silicon)","text":"","code":"x <- as_mlx(matrix(1:100, 10, 10))  # Overall reductions sum(x) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 5050 mean(x) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 50.5  # Column/row means colMeans(x) #> mlx array [10] #>   dtype: float32 #>   device: gpu #>   values: #>  [1]  5.5 15.5 25.5 35.5 45.5 55.5 65.5 75.5 85.5 95.5 rowMeans(x) #> mlx array [10] #>   dtype: float32 #>   device: gpu #>   values: #>  [1] 46 47 48 49 50 51 52 53 54 55  # Cumulative operations flatten column-major as.vector(cumsum(x)) #>   [1]    1    3    6   10   15   21   28   36   45   55   66   78   91  105  120 #>  [16]  136  153  171  190  210  231  253  276  300  325  351  378  406  435  465 #>  [31]  496  528  561  595  630  666  703  741  780  820  861  903  946  990 1035 #>  [46] 1081 1128 1176 1225 1275 1326 1378 1431 1485 1540 1596 1653 1711 1770 1830 #>  [61] 1891 1953 2016 2080 2145 2211 2278 2346 2415 2485 2556 2628 2701 2775 2850 #>  [76] 2926 3003 3081 3160 3240 3321 3403 3486 3570 3655 3741 3828 3916 4005 4095 #>  [91] 4186 4278 4371 4465 4560 4656 4753 4851 4950 5050"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"indexing","dir":"","previous_headings":"Features","what":"Indexing","title":"R Interface to Apple's MLX Arrays (GPU-Accelerated on Apple Silicon)","text":"","code":"x <- as_mlx(matrix(1:100, 10, 10))  # Subset x[1:5, 1:5] #> mlx array [5 x 5] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] [,4] [,5] #> [1,]    1   11   21   31   41 #> [2,]    2   12   22   32   42 #> [3,]    3   13   23   33   43 #> [4,]    4   14   24   34   44 #> [5,]    5   15   25   35   45 x[1, ] #> mlx array [10] #>   dtype: float32 #>   device: gpu #>   values: #>  [1]  1 11 21 31 41 51 61 71 81 91 x[, 1] #> mlx array [10] #>   dtype: float32 #>   device: gpu #>   values: #>  [1]  1  2  3  4  5  6  7  8  9 10"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"device-management","dir":"","previous_headings":"Features","what":"Device Management","title":"R Interface to Apple's MLX Arrays (GPU-Accelerated on Apple Silicon)","text":"Precision note: Numeric inputs stored float32. Requests dtype = \"float64\" downcast warning. Logical inputs stored MLX bool tensors (logical NA values supported). Complex inputs stored complex64 (single-precision real/imaginary parts). Use base R arrays require double precision arithmetic.","code":"# Check/set default device mlx_default_device()           # \"gpu\" #> [1] \"gpu\" mlx_default_device(\"cpu\")      # Switch to CPU #> [1] \"cpu\" mlx_default_device(\"gpu\")      # Back to GPU #> [1] \"gpu\"  # Create on specific device x_gpu <- as_mlx(matrix(1:12, 3, 4), device = \"gpu\") x_cpu <- as_mlx(matrix(1:12, 3, 4), device = \"cpu\")"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"data-types","dir":"","previous_headings":"","what":"Data Types","title":"R Interface to Apple's MLX Arrays (GPU-Accelerated on Apple Silicon)","text":"Supported dtype: float32 numeric data (default) bool logical data","code":"x_f32 <- as_mlx(matrix(1:12, 3, 4), dtype = \"float32\") logical_mat <- as_mlx(matrix(c(TRUE, FALSE, TRUE, TRUE), 2, 2))"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"R Interface to Apple's MLX Arrays (GPU-Accelerated on Apple Silicon)","text":"Package documentation: ?Rmlx Getting started vignette: vignette(\"getting-started\", package = \"Rmlx\") Function help: ?as_mlx, ?mlx_eval, etc.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"testing","dir":"","previous_headings":"","what":"Testing","title":"R Interface to Apple's MLX Arrays (GPU-Accelerated on Apple Silicon)","text":"Tests use testthat compare base R results: Tests skip gracefully MLX available package fails load.","code":"# Run all tests devtools::test()  # Run specific test file devtools::test_file(\"tests/testthat/test-ops.R\")"},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"high-level-scope-for-the-agent","dir":"","previous_headings":"","what":"High-level scope (for the agent)","title":"Project: Rmlx","text":"Language: R (+ C++ via Rcpp). OS: macOS Apple Silicon (Metal backend). Cross-platform explicitly scope now. Dependency: Apple MLX C/C++ library (present system). ’ll vendor MLX; ’ll detect link . Core object: S3 class mlx wrapping external pointer MLX array. Semantics: lazy default. .matrix.mlx() (conversions) force evaluation; otherwise, users call mlx_eval(x). Operator overloading: arithmetic, matrix algebra, comparisons; plus targeted stats helpers (colMeans.mlx, rowMeans.mlx, crossprod.mlx, tcrossprod.mlx, t.mlx, sum.mlx, mean.mlx). Phase 1: low-level arrays + ops, evaluation, conversions, basic reductions, tests, doc. (Autodiff/optimizers reserved later phase, implemented now.)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"milestones","dir":"","previous_headings":"","what":"Milestones","title":"Project: Rmlx","text":"Scaffold & toolchain C++ core: array handle, create/convert/eval Binary ops & reductions Matrix algebra & helpers R S3 class + operator overloading Indexing, printing, diagnostics Device/stream management Docs, examples, tests Build, local check, packaging milestone lists atomic tasks.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"milestone-1--scaffold--toolchain","dir":"","previous_headings":"","what":"Milestone 1 — Scaffold & toolchain","title":"Project: Rmlx","text":"T1. Create package skeleton Create standard R package layout: Acceptance: R CMD build produces tarball; R CMD check runs (expect skips missing MLX T3/T4 add detection). T2. DESCRIPTION Minimal fields: Package: Rmlx Type: Package Title: R Interface Apple's MLX Arrays (GPU-Accelerated Apple Silicon) Version: 0.0.0.9000 Authors@R: person(\"First\",\"Last\", role=c(\"aut\",\"cre\"), email=\"@example.com\") Description: S3 class 'mlx' backed Apple MLX arrays lazy GPU ops via Rcpp. License: MIT + file LICENSE Encoding: UTF-8 Depends: R (>= 4.1.0) Imports: Rcpp (>= 1.0.10) LinkingTo: Rcpp Suggests: testthat (>= 3.0.0), knitr, rmarkdown Config/testthat/edition: 3 SystemRequirements: MLX (Apple Machine Learning eXchange) C/C++ headers library; macOS Apple Silicon Acceptance: R CMD check reads DESCRIPTION cleanly. T3. NAMESPACE Start : ’ll also register %*% mlx via setMethod pattern R (see T17). T4. Build-time MLX detection (configure) Implement POSIX shell configure : Looks MLX headers & libs (probe typical locations: /opt/homebrew/include, /opt/homebrew/lib, /usr/local/include, /usr/local/lib, xcrun -sdk macosx --show-sdk-path). Allows env overrides: MLX_INCLUDE, MLX_LIB_DIR, MLX_LIBS (e.g., -lmlx -lc++) Writes src/Makevars PKG_CPPFLAGS including -... PKG_LIBS including -L... -lmlx. Add helpful error found: write small header check fail message telling user install MLX (Homebrew tap Apple docs). Acceptance: R CMD INSTALL . fails gracefully MLX missing; succeeds include+lib provided. Gotcha: keep Makevars minimal platform-guarded; hardcode Intel paths.","code":"Rmlx/   R/   src/   inst/   man/   tests/testthat/   vignettes/   DESCRIPTION   NAMESPACE   .Rbuildignore   .gitignore   configure     # POSIX shell   cleanup       # optional useDynLib(Rmlx, .registration = TRUE) importFrom(Rcpp, sourceCpp) S3method(print, mlx) S3method(as.matrix, mlx) S3method(colMeans, mlx) S3method(rowMeans, mlx) S3method(t, mlx) S3method(sum, mlx) S3method(mean, mlx) S3method(crossprod, mlx) S3method(tcrossprod, mlx) S3method(Ops, mlx) S3method(MatMult, mlx)       # custom for %*% (see T17)"},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"milestone-2--c-core-array-handle-createconverteval","dir":"","previous_headings":"","what":"Milestone 2 — C++ core: array handle, create/convert/eval","title":"Project: Rmlx","text":"T5. Define C++ wrapper class & finalizer File: src/mlx_bindings.cpp, plus header src/mlx_bindings.hpp. Create thin RAII wrapper around MLX array handle (consult MLX C API names; assume types like mlx_array*): Expose external pointer R finalizer deletes MlxArray. Acceptance: Creating garbage-collecting mlx object leak (use valgrind locally possible). T6. Create MLX array R data Rcpp-exposed functions (C++): SEXP cpp_mlx_from_numeric(SEXP x, SEXP dim, SEXP dtype, SEXP device); Inputs: x NumericVector (contiguous), dim IntegerVector, dtype string (“float32”/“float64”), device string (“gpu”/“cpu”). Create MLX array given shape copy host data. SEXP cpp_mlx_empty(SEXP dim, SEXP dtype, SEXP device); Acceptance: as_mlx(matrix(...)) returns mlx matching shape dtype. T7. Copy MLX array back R Function: SEXP cpp_mlx_to_numeric(SEXP x); Ensure evaluation first (see T8). copy NumericVector (column-major like R). Acceptance: .matrix.mlx(x) yields identical values input roundtrip. T8. Evaluation Implement: void cpp_mlx_eval(SEXP x); (force compute & sync). Design: store “needs_eval” flag inside wrapper, rely MLX’s state; call MLX eval array current graph root. R side: mlx_eval(x) calls cpp_mlx_eval. .matrix.mlx() must call mlx_eval() copying. Acceptance: Composed lazy ops compute evaluated converted.","code":"struct MlxArray {   mlx_array* ptr;   MlxArray();                       // null   explicit MlxArray(mlx_array* p);  // takes ownership   ~MlxArray();                      // calls mlx_array_free(ptr)   MlxArray(const MlxArray&) = delete;   MlxArray& operator=(const MlxArray&) = delete;   MlxArray(MlxArray&&) noexcept;   MlxArray& operator=(MlxArray&&) noexcept; };"},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"milestone-3--binary-ops--reductions","dir":"","previous_headings":"","what":"Milestone 3 — Binary ops & reductions","title":"Project: Rmlx","text":"T9. Elementwise unary ops C++ functions: neg, abs, sqrt, exp, log, sin, cos, etc. Signature pattern: SEXP cpp_mlx_unary(SEXP x, std::string op); // op ∈ {\"neg\",\"exp\",\"log\",...} Implementation maps MLX C API unary ops; output matches input dtype unless op requires float. T10. Elementwise binary ops Support: + - * / ^ comparisons < <= > >= == !=. Signature: SEXP cpp_mlx_binary(SEXP x, SEXP y, std::string op); Broadcasting rules: Follow MLX’s broadcasting (like NumPy). Validate shapes; throw R error incompatible shapes. scalar RHS/LHS, allow numeric logical scalars (wrap 0-d/1-d MLX arrays handle scalar op MLX supports). T11. Reductions Support: sum, mean (overall along axes), min, max. Signatures: SEXP cpp_mlx_reduce(SEXP x, std::string op); // full reduction -> scalar mlx SEXP cpp_mlx_reduce_axis(SEXP x, std::string op, int axis, bool keepdims); R wrappers provide sum.mlx, mean.mlx, helper colMeans.mlx / rowMeans.mlx built axis reductions. Acceptance: Numerically matches R within tolerance random small arrays.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"milestone-4--matrix-algebra--helpers","dir":"","previous_headings":"","what":"Milestone 4 — Matrix algebra & helpers","title":"Project: Rmlx","text":"T12. Transpose, reshape SEXP cpp_mlx_transpose(SEXP x); SEXP cpp_mlx_reshape(SEXP x, SEXP new_dim); T13. Matrix multiply SEXP cpp_mlx_matmul(SEXP , SEXP b); Accept shapes: (m×k) %*% (k×n) → (m×n); vectors meaningful (k)×(k) → scalar. Use MLX matmul op; ensure float32/float64 supported. T14. Crossprod & tcrossprod Implement top matmul + transpose, exploit MLX fused ops available later. R wrappers: crossprod.mlx(x, y = NULL) → t(x) %*% (y %||% x) tcrossprod.mlx(x, y = NULL) → x %*% t(y %||% x) T15. t.mlx, colMeans.mlx, rowMeans.mlx t.mlx → transpose colMeans.mlx → mean(x, axis=0) assuming R column-major (verify axis mapping; likely axis=0 == rows; explicit test). rowMeans.mlx → mean(x, axis=1) (ditto). Document axis semantics clearly.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"milestone-5--r-s3-class--operator-overloading","dir":"","previous_headings":"","what":"Milestone 5 — R S3 class + operator overloading","title":"Project: Rmlx","text":"T16. Class constructors & converters (R) File: R/class.R new_mlx <- function(ptr, dim, dtype, device) { structure(list(ptr=ptr, dim=dim, dtype=dtype, device=device), class=\"mlx\") } as_mlx <- function(x, dtype=c(\"float32\",\"float64\"), device=c(\"gpu\",\"cpu\")) Coerce matrix/array/numeric MLX via cpp_mlx_from_numeric. .matrix.mlx <- function(x, ...) { mlx_eval(x); cpp_mlx_to_numeric(x$ptr) |> structure(dim=x$dim) } mlx_eval <- function(x) { cpp_mlx_eval(x$ptr); invisible(x) } .mlx <- function(x) inherits(x, \"mlx\") T17. Operator overloading File: R/ops.R Define S3 method Ops.mlx dispatch elementwise + comparisons. Helper R wrappers call C++: .mlx_unary <- function(x, op) new_mlx(cpp_mlx_unary(x$ptr, op), x$dim, x$dtype, x$device) .mlx_binary <- function(x, y, op) new_mlx(cpp_mlx_binary(x$ptr, y$ptr, op), broadcast_dim(x,y), promote_dtype(x,y), common_device(x,y)) Matrix multiply %*% base R %*% primitive; define S3 generic shim: Register .onLoad: T18. Stats helpers File: R/stats.R sum.mlx, mean.mlx → reductions (full). colMeans.mlx, rowMeans.mlx → axis reductions + drop=TRUE return 1D mlx (dim length 1 removed) keepdims + reshape. t.mlx → transpose wrapper. crossprod.mlx, tcrossprod.mlx. T19. Class utilities File: R/utils.R print.mlx → show shape, dtype, device, lazy/evaluated flag; show small preview (e.g., 6×6) evaluating small slice (optionally evaluate fully size small). str.mlx → concise structure. Acceptance: Arithmetic, comparisons, %*%, col/row means reductions work mlx/regular R objects, producing mlx user calls .matrix() mlx_eval().","code":"Ops.mlx <- function(e1, e2 = NULL) {   op <- .Generic   if (is.null(e2)) {     # unary ops: \"+\" (no-op), \"-\" (neg)     if (op == \"+\") return(e1)     if (op == \"-\") return(.mlx_unary(e1, \"neg\"))     stop(sprintf(\"Unary op '%s' not supported for mlx\", op))   }   # Coerce scalars/matrix to mlx   if (!is.mlx(e1)) e1 <- as_mlx(e1)   if (!is.mlx(e2)) e2 <- as_mlx(e2)   if (op %in% c(\"+\",\"-\",\"*\",\"/\",\"^\")) return(.mlx_binary(e1, e2, op))   if (op %in% c(\"==\",\"!=\",\"<\",\"<=\",\">\",\">=\")) return(.mlx_binary(e1, e2, op))   stop(sprintf(\"Op '%s' not supported for mlx\", op)) } `%*%.mlx` <- function(x, y) {   if (!is.mlx(x)) x <- as_mlx(x)   if (!is.mlx(y)) y <- as_mlx(y)   new_mlx(cpp_mlx_matmul(x$ptr, y$ptr), c(x$dim[1L], y$dim[length(y$dim)]), promote_dtype(x,y), common_device(x,y)) } .onLoad <- function(...) {   # Ensure our method is visible for dispatch   # (S3 method for primitive is recognized if named `%*%.mlx`) }"},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"milestone-6--indexing-printing-diagnostics","dir":"","previous_headings":"","what":"Milestone 6 — Indexing, printing, diagnostics","title":"Project: Rmlx","text":"T20. Indexing [ ] R method: C++: SEXP cpp_mlx_slice(SEXP x, SEXP i_, SEXP j_); Support integer/real/logical vectors; negative indices throw (translate). Use MLX slicing ops (start/stop/step per axis). Acceptance: x[ ,1], x[1:5, 3:7], logical masks rows/cols (optional v1) behave; returns mlx. T21. Shape/dtype accessors R: mlx_dim <- function(x) x$dim mlx_dtype <- function(x) x$dtype dim.mlx <- function(x) x$dim (S3) length.mlx <- function(x) prod(x$dim) T22. Error messages Ensure C++ functions translate exceptions R errors actionable messages: incompatible shapes, dtype mismatch, found MLX op, etc.","code":"`[.mlx` <- function(x, i, j, ..., drop = TRUE) {   # Convert missing to full spans, build slices, call C++ slice   new_mlx(cpp_mlx_slice(x$ptr, normalize_index(i), normalize_index(j)), new_dim, x$dtype, x$device) }"},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"milestone-7--devicestream-management","dir":"","previous_headings":"","what":"Milestone 7 — Device/stream management","title":"Project: Rmlx","text":"T23. Default device R: mlx_default_device <- local({ dev <- \"gpu\"; function(value) { (!missing(value)) dev <<- match.arg(value, c(\"gpu\",\"cpu\")); dev }}) Used as_mlx() constructors device specified. C++: Keep references MLX CPU/GPU streams (e.g., MLX_GPU_STREAM, MLX_CPU_STREAM identifiers). Make small helper select stream per call. Acceptance: Users can switch default CPU debugging; ops route accordingly. T24. Synchronization R: mlx_synchronize(device=c(\"gpu\",\"cpu\")) → C++ call stream/device synchronize (MLX exposes ). Acceptance: outstanding work remains synchronize.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"milestone-8--docs-examples-tests","dir":"","previous_headings":"","what":"Milestone 8 — Docs, examples, tests","title":"Project: Rmlx","text":"T25. Roxygen2 docs Add #' docs user-facing functions: as_mlx, .matrix.mlx, mlx_eval, ops overview, %*%, colMeans.mlx, rowMeans.mlx, etc. ?mlx overview man page: explain laziness, evaluation points, device selection, unified memory concept. T26. Vignette vignettes/getting-started.Rmd Walkthrough: creating mlx arrays, arithmetic, %*%, reductions, colMeans, evaluation/convert, simple timing demo vs base R large matmul (note: formal benchmark). State Apple-requirement. T27. Tests (testthat) Skip tests MLX unavailable device GPU: Tests: Roundtrip as_mlx → .matrix equality. Elementwise ops vs base R (small sizes). %*% correctness vs base R. colMeans/rowMeans/sum/mean equality vs base R. Broadcasting cases. Indexing behavior. Tolerances: use expect_equal(..., tolerance = 1e-6).","code":"skip_if_not(mlx_available())"},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"milestone-9--build-local-check-packaging","dir":"","previous_headings":"","what":"Milestone 9 — Build, local check, packaging","title":"Project: Rmlx","text":"T28. Local build Commands: R CMD build . R CMD INSTALL Rmlx_0.0.0.9000.tar.gz R CMD check Rmlx_0.0.0.9000.tar.gz ---cran Accept: ERRORs; NOTE/WARN SystemRequirements acceptable. T29. Minimal examples Add examples function docs run fast touch small arrays avoid GPU timeouts.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"file-by-file-stubs-for-the-agent","dir":"","previous_headings":"","what":"File-by-file stubs (for the agent)","title":"Project: Rmlx","text":"R/class.R R/ops.R (skeleton shown earlier) R/stats.R src/Makevars (generated configure) src/registration.cpp src/mlx_bindings.cpp (sketch)","code":"#' Create MLX array from R object #' @export as_mlx <- function(x, dtype = c(\"float32\",\"float64\"), device = mlx_default_device()) {   dtype <- match.arg(dtype)   if (is.mlx(x)) return(x)   if (is.vector(x)) dim <- length(x) else dim <- dim(x)   stopifnot(!is.null(dim))   ptr <- cpp_mlx_from_numeric(as.numeric(x), as.integer(dim), dtype, device)   structure(list(ptr = ptr, dim = as.integer(dim), dtype = dtype, device = device), class = \"mlx\") }  #' Force evaluation #' @export mlx_eval <- function(x) { stopifnot(is.mlx(x)); cpp_mlx_eval(x$ptr); invisible(x) }  #' Convert MLX array to base matrix/array #' @export as.matrix.mlx <- function(x, ...) {   mlx_eval(x)   out <- cpp_mlx_to_numeric(x$ptr)   dim(out) <- x$dim   out }  is.mlx <- function(x) inherits(x, \"mlx\") #' @export sum.mlx  <- function(x, ...) .mlx_reduce(x, \"sum\") #' @export mean.mlx <- function(x, ...) .mlx_reduce(x, \"mean\")  #' @export colMeans.mlx <- function(x, na.rm = FALSE, dims = 1, ...) .mlx_reduce_axis(x, \"mean\", axis = 0L, keepdims = FALSE) #' @export rowMeans.mlx <- function(x, na.rm = FALSE, dims = 1, ...) .mlx_reduce_axis(x, \"mean\", axis = 1L, keepdims = FALSE)  #' @export t.mlx <- function(x) new_mlx(cpp_mlx_transpose(x$ptr), rev(x$dim), x$dtype, x$device)  #' @export crossprod.mlx <- function(x, y = NULL) { if (is.null(y)) y <- x; t(x) %*% y } #' @export tcrossprod.mlx <- function(x, y = NULL) { if (is.null(y)) y <- x; x %*% t(y) } PKG_CPPFLAGS = -I$(MLX_INCLUDE) PKG_LIBS     = -L$(MLX_LIB_DIR) -lmlx #include <Rcpp.h> using namespace Rcpp; // forward-declare C++ functions to register with R // RCPP_MODULE / R_registerRoutines as needed  extern \"C\" {   void R_init_Rmlx(DllInfo *dll) {     R_registerRoutines(dll, NULL, NULL, NULL, NULL);     R_useDynamicSymbols(dll, TRUE);   } } #include <Rcpp.h> #include \"mlx_bindings.hpp\" #include <mlx/c_api.h>  // adjust include path per installed MLX  using namespace Rcpp;  // Helpers to unwrap/wrap external pointers, set dims/dtype/device (store those in R side)  SEXP cpp_mlx_from_numeric(SEXP x_, SEXP dim_, SEXP dtype_, SEXP device_) {   NumericVector x(x_);   IntegerVector dim(dim_);   std::string dtype = as<std::string>(dtype_);   std::string device = as<std::string>(device_);    // create MLX array with given shape and dtype on device   // copy x.data() into MLX array   // return XPtr<MlxArray>(new MlxArray(ptr), true) }  SEXP cpp_mlx_to_numeric(SEXP xp_) {   // ensure evaluated   // copy MLX array data to NumericVector }  void cpp_mlx_eval(SEXP xp_) {   // call MLX eval on underlying array/graph }  // unary, binary, reduce, reduce_axis, transpose, reshape, matmul, slice..."},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"acceptance-checklist-phase-1-complete","dir":"","previous_headings":"","what":"Acceptance checklist (Phase 1 complete)","title":"Project: Rmlx","text":"Build succeeds Apple Silicon MLX installed. as_mlx(), .matrix.mlx() roundtrip correct. + - * / ^, comparisons, %*% produce correct results vs base R (small sizes). sum.mlx, mean.mlx, colMeans.mlx, rowMeans.mlx, t.mlx, crossprod.mlx, tcrossprod.mlx correct. Lazy default; .matrix.mlx() forces evaluation; mlx_eval() works. Indexing [] supports common cases. Helpful errors MLX found install, shape/dtype mismatches runtime. Vignette explains usage caveats.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"risks--notes-for-the-agent","dir":"","previous_headings":"","what":"Risks & notes for the agent","title":"Project: Rmlx","text":"MLX headers & symbols: Ensure correct include (e.g., #include <mlx/c_api.h>) link flags; actual header path & lib name may vary; keep configure flexible env overrides. Dtype: R double default; ’ll allow float32 float64. Decide default (float32 faster GPU; match R expectations, maybe default float64; document choice). Axis conventions: Confirm MLX axis numbering vs R’s column-major expectations; lock tests colMeans/rowMeans. Broadcasting: Implement consistent rules; add tests scalar + array, vector + matrix. Evaluation semantics: MLX needs explicit graph roots streams eval, store whatever handle required array (per-session singleton), make cpp_mlx_eval robust. Thread safety: Rcpp calls execute R main thread; ensure MLX usage safe context. Indexing: Logical indexing may deferred; start integer ranges : slices.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/plan.html","id":"phase-2-later-not-in-scope-for-this-handoff","dir":"","previous_headings":"","what":"Phase 2 (later, not in scope for this handoff)","title":"Project: Rmlx","text":"Autodiff: wrap MLX grad transforms; expose mlx_grad(fn, params) R closures provide graph-based differentiation APIs. Optimizers: SGD/Adam mlx parameters. linalg: solve, chol, svd, eigen (depending MLX support). Datasets/dataloaders, random seeding, fused kernels, compilation.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Math.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Math operations for MLX arrays — Math.mlx","title":"Math operations for MLX arrays — Math.mlx","text":"Math operations MLX arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Math.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Math operations for MLX arrays — Math.mlx","text":"","code":"# S3 method for class 'mlx' Math(x, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/Math.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Math operations for MLX arrays — Math.mlx","text":"x mlx object ... Additional arguments (ignored)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Math.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Math operations for MLX arrays — Math.mlx","text":"mlx object result","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Ops.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Arithmetic and comparison operators for MLX arrays — Ops.mlx","title":"Arithmetic and comparison operators for MLX arrays — Ops.mlx","text":"Arithmetic comparison operators MLX arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Ops.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Arithmetic and comparison operators for MLX arrays — Ops.mlx","text":"","code":"# S3 method for class 'mlx' Ops(e1, e2 = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/Ops.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Arithmetic and comparison operators for MLX arrays — Ops.mlx","text":"e1 First operand (mlx numeric) e2 Second operand (mlx numeric)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Ops.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Arithmetic and comparison operators for MLX arrays — Ops.mlx","text":"mlx object","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Rmlx-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Rmlx: R Interface to Apple's MLX Arrays — Rmlx-package","title":"Rmlx: R Interface to Apple's MLX Arrays — Rmlx-package","text":"package provides R interface Apple's MLX (Machine Learning eXchange) library GPU-accelerated array operations Apple Silicon.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Rmlx-package.html","id":"key-features","dir":"Reference","previous_headings":"","what":"Key Features","title":"Rmlx: R Interface to Apple's MLX Arrays — Rmlx-package","text":"Lazy evaluation: Operations computed explicitly evaluated GPU acceleration: Leverage Metal Apple Silicon Familiar syntax: S3 methods standard R operations Unified memory: Efficient data sharing CPU GPU","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Rmlx-package.html","id":"main-functions","dir":"Reference","previous_headings":"","what":"Main Functions","title":"Rmlx: R Interface to Apple's MLX Arrays — Rmlx-package","text":"as_mlx(): Convert R objects MLX arrays .matrix.mlx(): Convert MLX arrays back R mlx_eval(): Force evaluation lazy operations Arithmetic: +, -, *, /, ^ Matrix ops: %*%, t, crossprod, tcrossprod Reductions: sum, mean, colMeans, rowMeans","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Rmlx-package.html","id":"lazy-evaluation","dir":"Reference","previous_headings":"","what":"Lazy Evaluation","title":"Rmlx: R Interface to Apple's MLX Arrays — Rmlx-package","text":"MLX arrays use lazy evaluation default. Operations recorded executed : call mlx_eval(x) convert R .matrix(x) result needed another computation","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Rmlx-package.html","id":"device-management","dir":"Reference","previous_headings":"","what":"Device Management","title":"Rmlx: R Interface to Apple's MLX Arrays — Rmlx-package","text":"Use mlx_default_device() control whether arrays created GPU (default) CPU. mlx arrays stored float32 regardless device. Use base R arrays require float64 math.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/Rmlx-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Rmlx: R Interface to Apple's MLX Arrays — Rmlx-package","text":"Maintainer: David Hugh-Jones david@hughjones.com","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.array.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert MLX array to R array — as.array.mlx","title":"Convert MLX array to R array — as.array.mlx","text":"Convert MLX array R array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.array.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert MLX array to R array — as.array.mlx","text":"","code":"# S3 method for class 'mlx' as.array(x, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.array.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert MLX array to R array — as.array.mlx","text":"x mlx object ... Additional arguments (ignored)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.array.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert MLX array to R array — as.array.mlx","text":"numeric array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.matrix.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert MLX array to R matrix/array — as.matrix.mlx","title":"Convert MLX array to R matrix/array — as.matrix.mlx","text":"Convert MLX array R matrix/array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.matrix.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert MLX array to R matrix/array — as.matrix.mlx","text":"","code":"# S3 method for class 'mlx' as.matrix(x, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.matrix.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert MLX array to R matrix/array — as.matrix.mlx","text":"x mlx object ... Additional arguments (ignored)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.matrix.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert MLX array to R matrix/array — as.matrix.mlx","text":"matrix array (numeric logical depending dtype)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.vector.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert MLX array to R vector — as.vector.mlx","title":"Convert MLX array to R vector — as.vector.mlx","text":"Convert MLX array R vector","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.vector.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert MLX array to R vector — as.vector.mlx","text":"","code":"# S3 method for class 'mlx' as.vector(x, mode = \"any\")"},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.vector.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert MLX array to R vector — as.vector.mlx","text":"x mlx object mode Character string specifying mode (ignored)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.vector.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert MLX array to R vector — as.vector.mlx","text":"numeric vector","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as_mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Create MLX array from R object — as_mlx","title":"Create MLX array from R object — as_mlx","text":"Create MLX array R object","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as_mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create MLX array from R object — as_mlx","text":"","code":"as_mlx(   x,   dtype = c(\"float32\", \"float64\", \"bool\", \"complex64\"),   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/as_mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create MLX array from R object — as_mlx","text":"x Numeric, logical, complex vector, matrix, array convert dtype Ignored. Present backward compatibility. Numeric arrays stored float32; logical arrays use MLX bool; complex arrays use MLX complex64. device Device: \"gpu\" (default) \"cpu\"","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as_mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create MLX array from R object — as_mlx","text":"object class mlx","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as_mlx.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create MLX array from R object — as_mlx","text":"Apple MLX executes single precision. Numeric inputs stored float32 regardless requested dtype. Logical inputs mapped MLX boolean tensors. Complex inputs stored complex64 (float32 real imaginary parts). Asking dtype = \"float64\" emits warning input downcast float32. require double precision arithmetic, use base R arrays instead mlx objects.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as_mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create MLX array from R object — as_mlx","text":"","code":"if (FALSE) { # \\dontrun{ x <- as_mlx(matrix(1:12, 3, 4)) } # }"},{"path":"https://hughjonesd.github.io/Rmlx/reference/colMeans.html","id":null,"dir":"Reference","previous_headings":"","what":"Column means for MLX tensors — colMeans","title":"Column means for MLX tensors — colMeans","text":"Column means MLX tensors","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/colMeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Column means for MLX tensors — colMeans","text":"","code":"colMeans(x, na.rm = FALSE, dims = 1, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/colMeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Column means for MLX tensors — colMeans","text":"x array mlx tensor. na.rm Logical; currently ignored mlx tensors. dims Dimensions passed base implementation x mlx tensor. ... Additional arguments forwarded base implementation.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/colMeans.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Column means for MLX tensors — colMeans","text":"mlx tensor x mlx, otherwise numeric vector.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/colSums.html","id":null,"dir":"Reference","previous_headings":"","what":"Column sums for MLX tensors — colSums","title":"Column sums for MLX tensors — colSums","text":"Column sums MLX tensors","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/colSums.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Column sums for MLX tensors — colSums","text":"","code":"colSums(x, na.rm = FALSE, dims = 1, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/colSums.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Column sums for MLX tensors — colSums","text":"x array mlx tensor. na.rm Logical; currently ignored mlx tensors. dims Dimensions passed base implementation x mlx tensor. ... Additional arguments forwarded base implementation.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/colSums.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Column sums for MLX tensors — colSums","text":"mlx tensor x mlx, otherwise numeric vector.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/crossprod.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross product — crossprod.mlx","title":"Cross product — crossprod.mlx","text":"Cross product","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/crossprod.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross product — crossprod.mlx","text":"","code":"# S3 method for class 'mlx' crossprod(x, y = NULL, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/crossprod.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross product — crossprod.mlx","text":"x mlx matrix y mlx matrix (default: NULL, uses x) ... Additional arguments passed base::crossprod.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/crossprod.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross product — crossprod.mlx","text":"t(x) %*% y mlx object","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/dim.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Get dimensions of MLX array — dim.mlx","title":"Get dimensions of MLX array — dim.mlx","text":"Get dimensions MLX array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/dim.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get dimensions of MLX array — dim.mlx","text":"","code":"# S3 method for class 'mlx' dim(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/dim.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get dimensions of MLX array — dim.mlx","text":"x mlx object","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/dim.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get dimensions of MLX array — dim.mlx","text":"Integer vector dimensions","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/fft.html","id":null,"dir":"Reference","previous_headings":"","what":"Fast Fourier Transform — fft","title":"Fast Fourier Transform — fft","text":"Extends stats::fft() work mlx objects delegating standard R implementation inputs.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/fft.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fast Fourier Transform — fft","text":"","code":"fft(z, inverse = FALSE, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/fft.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fast Fourier Transform — fft","text":"z Input transform. May numeric, complex, mlx object. inverse Logical flag; TRUE compute inverse transform. ... Passed default method.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/fft.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fast Fourier Transform — fft","text":"mlx inputs, mlx object containing complex frequency coefficients; otherwise base R result.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/grapes-times-grapes-.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Matrix multiplication for MLX arrays — %*%.mlx","title":"Matrix multiplication for MLX arrays — %*%.mlx","text":"Matrix multiplication MLX arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/grapes-times-grapes-.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matrix multiplication for MLX arrays — %*%.mlx","text":"","code":"# S3 method for class 'mlx' x %*% y"},{"path":"https://hughjonesd.github.io/Rmlx/reference/grapes-times-grapes-.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matrix multiplication for MLX arrays — %*%.mlx","text":"x, y numeric complex matrices vectors.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/grapes-times-grapes-.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Matrix multiplication for MLX arrays — %*%.mlx","text":"mlx object","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/is.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Test if object is an MLX array — is.mlx","title":"Test if object is an MLX array — is.mlx","text":"Test object MLX array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/is.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test if object is an MLX array — is.mlx","text":"","code":"is.mlx(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/is.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test if object is an MLX array — is.mlx","text":"x Object test","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/is.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test if object is an MLX array — is.mlx","text":"Logical","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/length.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Get length of MLX array — length.mlx","title":"Get length of MLX array — length.mlx","text":"Get length MLX array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/length.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get length of MLX array — length.mlx","text":"","code":"# S3 method for class 'mlx' length(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/length.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get length of MLX array — length.mlx","text":"x mlx object","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/length.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get length of MLX array — length.mlx","text":"Total number elements","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mean.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean of MLX array elements — mean.mlx","title":"Mean of MLX array elements — mean.mlx","text":"Mean MLX array elements","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mean.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean of MLX array elements — mean.mlx","text":"","code":"# S3 method for class 'mlx' mean(x, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mean.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean of MLX array elements — mean.mlx","text":"x mlx object ... Additional arguments (ignored)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mean.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean of MLX array elements — mean.mlx","text":"mlx scalar","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_default_device.html","id":null,"dir":"Reference","previous_headings":"","what":"Get or set default MLX device — mlx_default_device","title":"Get or set default MLX device — mlx_default_device","text":"Get set default MLX device","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_default_device.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get or set default MLX device — mlx_default_device","text":"","code":"mlx_default_device(value)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_default_device.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get or set default MLX device — mlx_default_device","text":"value New default device (\"gpu\" \"cpu\"). missing, returns current default.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_default_device.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get or set default MLX device — mlx_default_device","text":"Current default device (character)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_default_device.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get or set default MLX device — mlx_default_device","text":"","code":"if (FALSE) { # \\dontrun{ mlx_default_device()  # Get current default mlx_default_device(\"cpu\")  # Set to CPU mlx_default_device(\"gpu\")  # Set back to GPU } # }"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dim.html","id":null,"dir":"Reference","previous_headings":"","what":"Get dimensions helper — mlx_dim","title":"Get dimensions helper — mlx_dim","text":"Get dimensions helper","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get dimensions helper — mlx_dim","text":"","code":"mlx_dim(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get dimensions helper — mlx_dim","text":"x mlx object","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get dimensions helper — mlx_dim","text":"Dimensions","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dtype.html","id":null,"dir":"Reference","previous_headings":"","what":"Get data type helper — mlx_dtype","title":"Get data type helper — mlx_dtype","text":"Get data type helper","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dtype.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get data type helper — mlx_dtype","text":"","code":"mlx_dtype(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dtype.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get data type helper — mlx_dtype","text":"x mlx object","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dtype.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get data type helper — mlx_dtype","text":"Data type string","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eval.html","id":null,"dir":"Reference","previous_headings":"","what":"Force evaluation of lazy MLX operations — mlx_eval","title":"Force evaluation of lazy MLX operations — mlx_eval","text":"Force evaluation lazy MLX operations","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Force evaluation of lazy MLX operations — mlx_eval","text":"","code":"mlx_eval(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Force evaluation of lazy MLX operations — mlx_eval","text":"x mlx object","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Force evaluation of lazy MLX operations — mlx_eval","text":"input object (invisibly)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_forward.html","id":null,"dir":"Reference","previous_headings":"","what":"Forward pass utility — mlx_forward","title":"Forward pass utility — mlx_forward","text":"Forward pass utility","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_forward.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forward pass utility — mlx_forward","text":"","code":"mlx_forward(module, x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_forward.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forward pass utility — mlx_forward","text":"module mlx_module. x Input tensor.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_forward.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forward pass utility — mlx_forward","text":"Output tensor.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_grad.html","id":null,"dir":"Reference","previous_headings":"","what":"Automatic differentiation for MLX functions — mlx_grad","title":"Automatic differentiation for MLX functions — mlx_grad","text":"mlx_grad() computes gradients R function operates mlx tensors. function must keep differentiable computations MLX (e.g., via as_mlx() MLX operators) return mlx object.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_grad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Automatic differentiation for MLX functions — mlx_grad","text":"","code":"mlx_grad(f, ..., argnums = NULL, value = FALSE)  mlx_value_grad(f, ..., argnums = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_grad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Automatic differentiation for MLX functions — mlx_grad","text":"f R function. arguments mlx objects, return value must mlx tensor (typically scalar loss). ... Arguments pass f. coerced mlx needed. argnums Indices (1-based) identifying arguments differentiate respect . Defaults arguments. value function value returned alongside gradients? Set TRUE receive list components value grads.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_grad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Automatic differentiation for MLX functions — mlx_grad","text":"value = FALSE (default), list mlx tensors containing gradients order argnums. value = TRUE, list elements value (function output mlx) grads.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_grad.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Automatic differentiation for MLX functions — mlx_grad","text":"Keep differentiated closure inside MLX operations. Coercing tensors back base R objects (.matrix(), .numeric(), [[ extraction) breaks gradient tape results error.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_grad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Automatic differentiation for MLX functions — mlx_grad","text":"","code":"if (FALSE) { # \\dontrun{ loss <- function(w, x, y) {   preds <- x %*% w   resids <- preds - y   sum(resids * resids) / length(y) } x <- as_mlx(matrix(rnorm(20), 5, 4)) y <- as_mlx(matrix(rnorm(5), 5, 1)) w <- as_mlx(matrix(0, 4, 1)) grad_w <- mlx_grad(loss, w, x, y)[[1]] } # }"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_linear.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a learnable linear transformation — mlx_linear","title":"Create a learnable linear transformation — mlx_linear","text":"Create learnable linear transformation","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_linear.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a learnable linear transformation — mlx_linear","text":"","code":"mlx_linear(   in_features,   out_features,   bias = TRUE,   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_linear.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a learnable linear transformation — mlx_linear","text":"in_features Number input features. out_features Number output features. bias bias term included? device Device parameters.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_linear.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a learnable linear transformation — mlx_linear","text":"object class mlx_module.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_optimizer_sgd.html","id":null,"dir":"Reference","previous_headings":"","what":"Stochastic gradient descent optimizer — mlx_optimizer_sgd","title":"Stochastic gradient descent optimizer — mlx_optimizer_sgd","text":"Stochastic gradient descent optimizer","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_optimizer_sgd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stochastic gradient descent optimizer — mlx_optimizer_sgd","text":"","code":"mlx_optimizer_sgd(params, lr = 0.01)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_optimizer_sgd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stochastic gradient descent optimizer — mlx_optimizer_sgd","text":"params List parameters (mlx_parameters()). lr Learning rate.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_optimizer_sgd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stochastic gradient descent optimizer — mlx_optimizer_sgd","text":"optimizer object step() method.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_param_set_values.html","id":null,"dir":"Reference","previous_headings":"","what":"Assign tensors back to parameters — mlx_param_set_values","title":"Assign tensors back to parameters — mlx_param_set_values","text":"Assign tensors back parameters","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_param_set_values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assign tensors back to parameters — mlx_param_set_values","text":"","code":"mlx_param_set_values(params, values)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_param_set_values.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assign tensors back to parameters — mlx_param_set_values","text":"params list mlx_param. values list tensors.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_param_values.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve parameter tensors — mlx_param_values","title":"Retrieve parameter tensors — mlx_param_values","text":"Retrieve parameter tensors","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_param_values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve parameter tensors — mlx_param_values","text":"","code":"mlx_param_values(params)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_param_values.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve parameter tensors — mlx_param_values","text":"params list mlx_param.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_param_values.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve parameter tensors — mlx_param_values","text":"List mlx tensors.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Collect parameters from modules — mlx_parameters","title":"Collect parameters from modules — mlx_parameters","text":"Collect parameters modules","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Collect parameters from modules — mlx_parameters","text":"","code":"mlx_parameters(module)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Collect parameters from modules — mlx_parameters","text":"module mlx_module list modules.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Collect parameters from modules — mlx_parameters","text":"list mlx_param objects.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_bernoulli.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample Bernoulli random variables on MLX tensors — mlx_rand_bernoulli","title":"Sample Bernoulli random variables on MLX tensors — mlx_rand_bernoulli","text":"Sample Bernoulli random variables MLX tensors","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_bernoulli.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample Bernoulli random variables on MLX tensors — mlx_rand_bernoulli","text":"","code":"mlx_rand_bernoulli(dim, prob = 0.5, device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_bernoulli.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample Bernoulli random variables on MLX tensors — mlx_rand_bernoulli","text":"dim Integer vector giving tensor shape. prob Probability one. device Target device (\"gpu\" \"cpu\").","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_bernoulli.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample Bernoulli random variables on MLX tensors — mlx_rand_bernoulli","text":"mlx boolean tensor.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_normal.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from a normal distribution on MLX tensors — mlx_rand_normal","title":"Sample from a normal distribution on MLX tensors — mlx_rand_normal","text":"Sample normal distribution MLX tensors","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_normal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from a normal distribution on MLX tensors — mlx_rand_normal","text":"","code":"mlx_rand_normal(   dim,   mean = 0,   sd = 1,   dtype = c(\"float32\", \"float64\"),   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_normal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from a normal distribution on MLX tensors — mlx_rand_normal","text":"dim Integer vector giving tensor shape. mean Mean normal distribution. sd Standard deviation normal distribution. dtype Desired MLX dtype (\"float32\" \"float64\"). device Target device (\"gpu\" \"cpu\").","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_normal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from a normal distribution on MLX tensors — mlx_rand_normal","text":"mlx tensor normally distributed entries.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_uniform.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from a uniform distribution on MLX tensors — mlx_rand_uniform","title":"Sample from a uniform distribution on MLX tensors — mlx_rand_uniform","text":"Sample uniform distribution MLX tensors","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_uniform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from a uniform distribution on MLX tensors — mlx_rand_uniform","text":"","code":"mlx_rand_uniform(   dim,   min = 0,   max = 1,   dtype = c(\"float32\", \"float64\"),   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_uniform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from a uniform distribution on MLX tensors — mlx_rand_uniform","text":"dim Integer vector giving tensor shape. min Lower bound uniform distribution. max Upper bound uniform distribution. dtype Desired MLX dtype (\"float32\" \"float64\"). device Target device (\"gpu\" \"cpu\").","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_uniform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from a uniform distribution on MLX tensors — mlx_rand_uniform","text":"mlx tensor whose entries sampled uniformly.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_reduction_base.html","id":null,"dir":"Reference","previous_headings":"","what":"Shared arguments for MLX/base reduction helpers. — mlx_reduction_base","title":"Shared arguments for MLX/base reduction helpers. — mlx_reduction_base","text":"Shared arguments MLX/base reduction helpers.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_reduction_base.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shared arguments for MLX/base reduction helpers. — mlx_reduction_base","text":"x array mlx tensor. na.rm Logical; currently ignored mlx tensors. dims Dimensions passed base implementation x mlx tensor. ... Additional arguments forwarded base implementation.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_relu.html","id":null,"dir":"Reference","previous_headings":"","what":"Rectified linear activation module — mlx_relu","title":"Rectified linear activation module — mlx_relu","text":"Rectified linear activation module","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_relu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rectified linear activation module — mlx_relu","text":"","code":"mlx_relu()"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_relu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rectified linear activation module — mlx_relu","text":"mlx_module applying ReLU.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sequential.html","id":null,"dir":"Reference","previous_headings":"","what":"Compose modules sequentially — mlx_sequential","title":"Compose modules sequentially — mlx_sequential","text":"Compose modules sequentially","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sequential.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compose modules sequentially — mlx_sequential","text":"","code":"mlx_sequential(...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sequential.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compose modules sequentially — mlx_sequential","text":"... Modules compose.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sequential.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compose modules sequentially — mlx_sequential","text":"mlx_module.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_stop_gradient.html","id":null,"dir":"Reference","previous_headings":"","what":"Stop gradient propagation through an MLX tensor — mlx_stop_gradient","title":"Stop gradient propagation through an MLX tensor — mlx_stop_gradient","text":"Stop gradient propagation MLX tensor","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_stop_gradient.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stop gradient propagation through an MLX tensor — mlx_stop_gradient","text":"","code":"mlx_stop_gradient(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_stop_gradient.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stop gradient propagation through an MLX tensor — mlx_stop_gradient","text":"x mlx tensor.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_stop_gradient.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stop gradient propagation through an MLX tensor — mlx_stop_gradient","text":"new mlx tensor identical values zero gradient.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_synchronize.html","id":null,"dir":"Reference","previous_headings":"","what":"Synchronize MLX device — mlx_synchronize","title":"Synchronize MLX device — mlx_synchronize","text":"Waits outstanding operations specified device complete.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_synchronize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Synchronize MLX device — mlx_synchronize","text":"","code":"mlx_synchronize(device = c(\"gpu\", \"cpu\"))"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_synchronize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Synchronize MLX device — mlx_synchronize","text":"device Device synchronize (\"gpu\" \"cpu\").","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_train_step.html","id":null,"dir":"Reference","previous_headings":"","what":"Single training step helper — mlx_train_step","title":"Single training step helper — mlx_train_step","text":"Single training step helper","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_train_step.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Single training step helper — mlx_train_step","text":"","code":"mlx_train_step(module, loss_fn, optimizer, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_train_step.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Single training step helper — mlx_train_step","text":"module mlx_module. loss_fn Function module data returning mlx scalar. optimizer Optimizer object mlx_optimizer_sgd(). ... Additional data passed loss_fn.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_train_step.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Single training step helper — mlx_train_step","text":"list current loss.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/new_mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal constructor for mlx objects — new_mlx","title":"Internal constructor for mlx objects — new_mlx","text":"Internal constructor mlx objects","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/new_mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal constructor for mlx objects — new_mlx","text":"","code":"new_mlx(ptr, dim, dtype, device)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/new_mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal constructor for mlx objects — new_mlx","text":"ptr External pointer MLX array dim Dimensions dtype Data type device Device","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/pinv.html","id":null,"dir":"Reference","previous_headings":"","what":"Moore-Penrose pseudoinverse for MLX arrays — pinv","title":"Moore-Penrose pseudoinverse for MLX arrays — pinv","text":"Moore-Penrose pseudoinverse MLX arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/pinv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Moore-Penrose pseudoinverse for MLX arrays — pinv","text":"","code":"pinv(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/pinv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Moore-Penrose pseudoinverse for MLX arrays — pinv","text":"x mlx object coercible matrix.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/pinv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Moore-Penrose pseudoinverse for MLX arrays — pinv","text":"mlx object containing pseudoinverse.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/print.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Print MLX array — print.mlx","title":"Print MLX array — print.mlx","text":"Print MLX array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/print.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print MLX array — print.mlx","text":"","code":"# S3 method for class 'mlx' print(x, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/print.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print MLX array — print.mlx","text":"x mlx object ... Additional arguments (ignored)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/rowMeans.html","id":null,"dir":"Reference","previous_headings":"","what":"Row means for MLX tensors — rowMeans","title":"Row means for MLX tensors — rowMeans","text":"Row means MLX tensors","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/rowMeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Row means for MLX tensors — rowMeans","text":"","code":"rowMeans(x, na.rm = FALSE, dims = 1, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/rowMeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Row means for MLX tensors — rowMeans","text":"x array mlx tensor. na.rm Logical; currently ignored mlx tensors. dims Dimensions passed base implementation x mlx tensor. ... Additional arguments forwarded base implementation.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/rowMeans.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Row means for MLX tensors — rowMeans","text":"mlx tensor x mlx, otherwise numeric vector.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/rowSums.html","id":null,"dir":"Reference","previous_headings":"","what":"Row sums for MLX tensors — rowSums","title":"Row sums for MLX tensors — rowSums","text":"Row sums MLX tensors","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/rowSums.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Row sums for MLX tensors — rowSums","text":"","code":"rowSums(x, na.rm = FALSE, dims = 1, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/rowSums.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Row sums for MLX tensors — rowSums","text":"x array mlx tensor. na.rm Logical; currently ignored mlx tensors. dims Dimensions passed base implementation x mlx tensor. ... Additional arguments forwarded base implementation.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/rowSums.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Row sums for MLX tensors — rowSums","text":"mlx tensor x mlx, otherwise numeric vector.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/solve.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Solve a system of linear equations — solve.mlx","title":"Solve a system of linear equations — solve.mlx","text":"Solve system linear equations","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/solve.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solve a system of linear equations — solve.mlx","text":"","code":"# S3 method for class 'mlx' solve(a, b = NULL, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/solve.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solve a system of linear equations — solve.mlx","text":"mlx matrix (coefficient matrix) b mlx vector matrix (right-hand side). omitted, computes matrix inverse. ... Additional arguments (compatibility base::solve)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/solve.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solve a system of linear equations — solve.mlx","text":"mlx object containing solution","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/str.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Object structure for MLX array — str.mlx","title":"Object structure for MLX array — str.mlx","text":"Object structure MLX array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/str.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Object structure for MLX array — str.mlx","text":"","code":"# S3 method for class 'mlx' str(object, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/str.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Object structure for MLX array — str.mlx","text":"object mlx object ... Additional arguments (ignored)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/sub-.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Subset MLX array — [.mlx","title":"Subset MLX array — [.mlx","text":"Subset MLX array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/sub-.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subset MLX array — [.mlx","text":"","code":"# S3 method for class 'mlx' x[i, j, ..., drop = TRUE]"},{"path":"https://hughjonesd.github.io/Rmlx/reference/sub-.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subset MLX array — [.mlx","text":"x mlx object Row indices j Column indices (matrices) ... Additional indices drop dimensions dropped? (default: TRUE)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/sub-.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subset MLX array — [.mlx","text":"Subsetted mlx object","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/sum.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Sum of MLX array elements — sum.mlx","title":"Sum of MLX array elements — sum.mlx","text":"Sum MLX array elements","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/sum.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sum of MLX array elements — sum.mlx","text":"","code":"# S3 method for class 'mlx' sum(x, ..., na.rm = FALSE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/sum.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sum of MLX array elements — sum.mlx","text":"x mlx object ... Additional arguments (ignored) na.rm Ignored (compatibility)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/sum.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sum of MLX array elements — sum.mlx","text":"mlx scalar","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/t.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Transpose of MLX matrix — t.mlx","title":"Transpose of MLX matrix — t.mlx","text":"Transpose MLX matrix","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/t.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transpose of MLX matrix — t.mlx","text":"","code":"# S3 method for class 'mlx' t(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/t.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transpose of MLX matrix — t.mlx","text":"x mlx matrix","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/t.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transpose of MLX matrix — t.mlx","text":"Transposed mlx matrix","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/tcrossprod.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Transposed cross product — tcrossprod.mlx","title":"Transposed cross product — tcrossprod.mlx","text":"Transposed cross product","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/tcrossprod.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transposed cross product — tcrossprod.mlx","text":"","code":"# S3 method for class 'mlx' tcrossprod(x, y = NULL, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/tcrossprod.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transposed cross product — tcrossprod.mlx","text":"x mlx matrix y mlx matrix (default: NULL, uses x) ... Additional arguments passed base::tcrossprod.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/tcrossprod.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transposed cross product — tcrossprod.mlx","text":"x %*% t(y) mlx object","code":""}]
