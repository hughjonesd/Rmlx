[{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/AGENTS.html","id":"project-structure--module-organization","dir":"","previous_headings":"","what":"Project Structure & Module Organization","title":"Repository Guidelines","text":"R/ holds exported R wrappers, S3 methods, roxygen docs; mirror existing files like ops.R adding API surface. src/ contains Rcpp glue MLX (mlx_bindings.cpp, mlx_ops.cpp); keep headers sync RcppExports.R. tests/testthat/ groups unit specs domain (test-math.R, test-matmul.R); add new files test-feature.R. vignettes/getting-started.Rmd introduces workflows; update adding user-facing features. configure, DESCRIPTION, NAMESPACE manage build-time detection package metadata; configure step runs automatically install.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/AGENTS.html","id":"build-test-and-development-commands","dir":"","previous_headings":"","what":"Build, Test, and Development Commands","title":"Repository Guidelines","text":"R -q -e 'Rcpp::compileAttributes()' regenerates RcppExports touching headers .cpp. R -q -e 'devtools::document()' rebuilds NAMESPACE Rd files roxygen comments. R -q -e 'devtools::build()' creates source tarball; R -q -e 'devtools::check()' runs formal package checks. R -q -e 'devtools::test()' runs testthat suite; use R -q -e 'devtools::load_all()' rapid iteration.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/AGENTS.html","id":"coding-style--naming-conventions","dir":"","previous_headings":"","what":"Coding Style & Naming Conventions","title":"Repository Guidelines","text":"Use two-space indents R C++; keep lines 100 characters match current style. Prefer snake_case R helpers (as_mlx), S3 methods Generic.class (Math.mlx). C++ helpers follow descriptive snake_case RAII patterns; include <mlx/mlx.h> via mlx_bindings.hpp. Document R functions roxygen #' blocks; let @export drive NAMESPACE entries.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/AGENTS.html","id":"testing-guidelines","dir":"","previous_headings":"","what":"Testing Guidelines","title":"Repository Guidelines","text":"Write tests testthat tests/testthat; mirror existing structure keep scenario-focused blocks within test_that. Use CPU-friendly fixtures (small matrices) GPU CPU paths run quickly. Run R -q -e 'devtools::test()' locally; conditional skips—tests allowed fail MLX absent.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/AGENTS.html","id":"issue-tracking","dir":"","previous_headings":"","what":"Issue Tracking","title":"Repository Guidelines","text":"File tasks straight GitHub via gh issue create rather maintaining local scratchpads. Reference issue numbers downstream docs/PRs.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/AGENTS.html","id":"commit--pull-request-guidelines","dir":"","previous_headings":"","what":"Commit & Pull Request Guidelines","title":"Repository Guidelines","text":"Follow repository’s imperative, capitalized commit style (e.g., Add rowSums helper); keep subject lines near 70 characters. PR link issues relevant, summarize API changes, note Metal/CPU devices covered. opening PR, run R -q -e 'devtools::document()', R -q -e 'devtools::test()', R -q -e 'devtools::check()'; include notable outputs screenshots performance-sensitive work.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/AGENTS.html","id":"current-agent-notes-2025-10-22","dir":"","previous_headings":"","what":"Current Agent Notes (2025-10-22)","title":"Repository Guidelines","text":"MLX tensor creation Metal-backed work (e.g., as_mlx(), GPU tests) succeed session runs danger-full-access; restricted sandboxes block Metal device initialisation processx/callr’s kqueue() calls. restricted modes can still build via R CMD build/INSTALL roxygen2::roxygenise(load_code = roxygen2::load_source), expect MLX runtime calls bail c++ exception (unknown reason). danger-full-access, full devtools workflow (document(), test(), check()) works end--end. devtools::check() currently reports single NOTE bashism configure line 33; everything else clean. Keep workspace tidy checks: remove Rmlx_0.0.0.9000.tar.gz, temporary Rmlx.Rcheck/, local library/ installs create . Tests now pass, rely MLX availability. Avoid adding conditional skips—failures acceptable MLX absent.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/AGENTS.html","id":"mlx-integration-reminders","dir":"","previous_headings":"Additional Guidance","what":"MLX Integration Reminders","title":"Repository Guidelines","text":"MLX may rename C API entry points; confirm function names <mlx/c/mlx.h> wiring Rcpp wrappers. Update src/mlx_bindings.cpp src/mlx_ops.cpp whenever upstream changes occur. R arrays column-major MLX tensors row-major. reduction tests misbehave, double-check axis ordering (swapping axis 0/1 often fixes ).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/AGENTS.html","id":"testing-notes","dir":"","previous_headings":"Additional Guidance","what":"Testing Notes","title":"Repository Guidelines","text":"testthat specs live tests/testthat/; skip MLX fails load. Prefer tolerance = 1e-6 asserting floating point equality. Use base R results oracle comparisons. Run single file via R -q -e 'devtools::test_file(\"tests/testthat/test-ops.R\")' iterating.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/AGENTS.html","id":"documentation-workflow","dir":"","previous_headings":"Additional Guidance","what":"Documentation Workflow","title":"Repository Guidelines","text":"Roxygen comments power man/ docs; vignette vignettes/getting-started.Rmd. doc edits, regenerate R -q -e 'devtools::document()'. Favor markdown lists/tables roxygen \\item. Add @seealso links relevant MLX online docs new exports. adding features, update pkgdown reference index. GitHub Actions builds pkgdown production; local pkgdown::build_reference() runs smoke testing (need commit rendered HTML). Benchmarks: reuse helpers inst/benchmarks/bench_helpers.R (dev CLI sources file). Run Rscript dev/benchmarks/run_benchmarks_cli.R > dev/benchmarks/bench_results.tsv (pre-commit hook githooks/ , prints table, stages TSV git config core.hooksPath githooks). Diff TSV across commits track perf trends.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/AGENTS.html","id":"handy-tips","dir":"","previous_headings":"Additional Guidance","what":"Handy Tips","title":"Repository Guidelines","text":"usethis:: helpers provide canonical workflows package chores—prefer possible. MLX array types lack default constructor; always supply shape/dtype explicitly C++. Discover exports via library(help = \"Rmlx\"); inspect functions ls(envir = asNamespace(\"Rmlx\"), .names = TRUE). Search upstream docs https://ml-explore.github.io/mlx/build/html/search.html?q=<term>. Never edit NAMESPACE R/RcppExports.R hand—regenerate devtools::document() / Rcpp::compileAttributes() updating roxygen C++ signatures. user-facing APIs docs, prefer term array tensor match R conventions. Add concise internal documentation (comments helper docstrings) non-obvious internal helpers; keep codebase self-explanatory.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/AGENTS.html","id":"mlx-core-capabilities","dir":"","previous_headings":"Additional Guidance","what":"MLX Core Capabilities","title":"Repository Guidelines","text":"Integer array indexing: MLX supports indexing integer arrays via [.mlx. R vectors mlx arrays work indices. Example: sorted_x[indices_mlx] indices_mlx mlx array integers extracts values positions. Sorting: mlx_sort() mlx_argsort() available. Note mlx_argsort() returns 1-based indices following R conventions. Arithmetic interpolation: Linear interpolation straightforward mlx arrays: result <- (1 - weight) * lower + weight * upper values mlx arrays. leverages lazy evaluation build computation graph efficiently.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":null,"dir":"","previous_headings":"","what":"CLAUDE.md","title":"CLAUDE.md","text":"file provides guidance Claude Code (claude.ai/code) working code repository.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"package-overview","dir":"","previous_headings":"","what":"Package Overview","title":"CLAUDE.md","text":"Rmlx R interface Apple’s MLX (Machine Learning eXchange) library GPU-accelerated array operations Apple Silicon. package provides lazy evaluation, S3 operator overloading, familiar R syntax GPU computing. Requirements: - macOS Apple Silicon (M1/M2/M3+) - MLX C/C++ library installed - Rcpp R/C++ integration","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"building-and-testing","dir":"","previous_headings":"Development Commands","what":"Building and Testing","title":"CLAUDE.md","text":"R -q -e 'Rcpp::compileAttributes()' - Generate Rcpp exports modifying C++ code (ALWAYS run first) R -q -e 'devtools::document()' - Generate documentation roxygen comments R -q -e 'devtools::load_all()' - Load package interactive development R -q -e 'devtools::build()' - Build package R -q -e 'devtools::check()' - Run R CMD check R -q -e 'devtools::test()' - Run tests","code":""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"installing","dir":"","previous_headings":"Development Commands","what":"Installing","title":"CLAUDE.md","text":"R -q -e 'devtools::install()' - Install package locally (requires MLX)","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"mlx-installation","dir":"","previous_headings":"System Requirements","what":"MLX Installation","title":"CLAUDE.md","text":"package requires MLX headers library. Configure script searches: - /opt/homebrew/include/mlx/c/mlx.h (headers) - /opt/homebrew/lib/libmlx.dylib (library) - /usr/local/include, /usr/local/lib (alternatives) Override environment variables:","code":"export MLX_INCLUDE=/path/to/mlx/include export MLX_LIB_DIR=/path/to/mlx/lib export MLX_LIBS=\"-lmlx\""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"build-process","dir":"","previous_headings":"System Requirements","what":"Build Process","title":"CLAUDE.md","text":"configure script detects MLX writes src/Makevars cleanup script removes generated src/Makevars Build fails gracefully helpful error MLX found","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"c-core-src","dir":"","previous_headings":"Architecture","what":"C++ Core (src/)","title":"CLAUDE.md","text":"mlx_bindings.hpp/cpp - RAII wrapper, array creation, conversion, evaluation mlx_ops.cpp - Unary ops, binary ops, reductions, matrix ops, slicing init.cpp - R package registration RcppExports.cpp - Auto-generated Rcpp::compileAttributes() Key design: - MlxArray class wraps mlx_array* RAII semantics - External pointers R finalizers memory management - C++ functions exported via [[Rcpp::export]]","code":""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"r-code-r","dir":"","previous_headings":"Architecture","what":"R Code (R/)","title":"CLAUDE.md","text":"class.R - S3 class, constructors, converters (as_mlx, .matrix.mlx, mlx_eval) ops.R - Operator overloading (Ops.mlx, %*%.mlx) stats.R - Reductions matrix helpers (sum, mean, colMeans, t, crossprod) utils.R - Print, indexing [.mlx, accessors (dim, length) device.R - Device management (mlx_default_device, mlx_synchronize) Rmlx-package.R - Package documentation RcppExports.R - Auto-generated Rcpp::compileAttributes()","code":""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"key-features","dir":"","previous_headings":"Architecture","what":"Key Features","title":"CLAUDE.md","text":"Lazy evaluation - Operations build computation graph; evaluate mlx_eval() .matrix() S3 dispatch - Standard R syntax: +, -, *, /, ^, %*%, t(), etc. Broadcasting - NumPy-style broadcasting binary ops GPU/CPU - Default GPU; switch mlx_default_device()","code":""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"mlx-c-api-assumptions","dir":"","previous_headings":"Architecture","what":"MLX C API Assumptions","title":"CLAUDE.md","text":"C++ code assumes MLX C API functions like: - mlx_array_from_data(), mlx_array_free(), mlx_array_eval() - mlx_array_add(), mlx_array_matmul(), mlx_array_transpose() - mlx_array_sum(), mlx_array_mean(), etc. IMPORTANT: actual MLX C API function names may differ. compilation errors occur, check MLX documentation update function names src/mlx_bindings.cpp src/mlx_ops.cpp.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"mlx-headers-not-found","dir":"","previous_headings":"Common Issues","what":"MLX headers not found","title":"CLAUDE.md","text":"Install MLX: brew install mlx (available) build source Set MLX_INCLUDE environment variable Check header path /path//include/mlx/c/mlx.h","code":""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"wrong-mlx-function-names","dir":"","previous_headings":"Common Issues","what":"Wrong MLX function names","title":"CLAUDE.md","text":"MLX C API may different naming conventions Check #include <mlx/c/mlx.h> equivalent header Update function calls src/mlx_bindings.cpp src/mlx_ops.cpp","code":""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"axis-confusion-row-major-vs-column-major","dir":"","previous_headings":"Common Issues","what":"Axis confusion (row-major vs column-major)","title":"CLAUDE.md","text":"R uses column-major order MLX uses row-major order Tests verify colMeans/rowMeans map correct axes tests fail, swap axis=0 axis=1 reductions","code":""},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"testing","dir":"","previous_headings":"","what":"Testing","title":"CLAUDE.md","text":"Tests tests/testthat/: - tests skip package can’t load (MLX available) - Use tolerance = 1e-6 floating-point comparisons - Compare base R results correctness Run specific test file:","code":"R -q -e 'devtools::test_file(\"tests/testthat/test-ops.R\")'"},{"path":"https://hughjonesd.github.io/Rmlx/CLAUDE.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"CLAUDE.md","text":"Roxygen2 comments R files Vignette vignettes/getting-started.Rmd editing docs: possible, use usethis:: package commands things canonical way. array type doesn’t default constructor! add function, update pkgdown reference index. add new function, include @seealso link online mlx documentation, appropriate. can use library(help = “Rmlx”) find exported R functions package, descriptions . can use ls(envir = asNamespace(“Rmlx”), .names = TRUE) find functions including unexported ones. url https://ml-explore.github.io/mlx/build/html/search.html?q=foobar search documentation foobar Always use markdown roxygen possible (e.g. markdown lists rather ). Always default using mlx data-related variables. drop R e.g. .numeric(), think hard avoid , ask user advice.","code":"R -q -e 'devtools::document()'"},{"path":"https://hughjonesd.github.io/Rmlx/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 Rmlx authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/articles/benchmarks.html","id":"distribution-functions","dir":"Articles","previous_headings":"","what":"Distribution Functions","title":"MLX Benchmarks","text":"Distribution functions operate vectors rather matrices, benchmark larger sizes: 1,000, 100,000, 10,000,000 elements.","code":"dist_sizes <- c(small = 1000L, medium = 100000L, large = 10000000L) dist_inputs <- build_distribution_inputs(dist_sizes) dist_operations <- distribution_operations()  dist_results <- run_benchmarks(dist_operations, dist_inputs)  dist_results$size <- factor(   dist_results$size,   levels = names(dist_sizes),   labels = format(dist_sizes, scientific = FALSE, big.mark = \",\") ) dist_results$implementation <- factor(   dist_results$implementation,   levels = c(\"base\", \"mlx\"),   labels = c(\"base R\", \"mlx\") ) dist_results$operation <- factor(   dist_results$operation,   levels = vapply(dist_operations, `[[`, character(1), \"label\") ) ggplot(   dist_results,   aes(x = size, y = median_seconds, colour = implementation, group = implementation) ) +   geom_line() +   geom_point(size = 2) +   scale_colour_manual(values = c(\"base R\" = \"#4A4A4A\", \"mlx\" = \"#D63230\")) +   facet_wrap(~ operation, scales = \"free_y\") +   labs(     title = \"Distribution function benchmarks\",     subtitle = \"Time taken (less is better)\",     x = \"Vector length\",     y = \"Median time (seconds)\",     colour = \"\"   ) +   theme_minimal(base_size = 11) +   theme(legend.position = \"bottom\")"},{"path":"https://hughjonesd.github.io/Rmlx/articles/linear-regression.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Linear Regression with MLX","text":"vignette demonstrates linear regression using Rmlx, based MLX linear regression example. ’ll train linear model using automatic differentiation stochastic gradient descent (SGD) GPU-accelerated arrays.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/articles/linear-regression.html","id":"problem-setup","dir":"Articles","previous_headings":"","what":"Problem Setup","title":"Linear Regression with MLX","text":"’ll create synthetic data linear regression high dimensionality: - random “true” weight vector w_star dimension 100 - random design matrix X 10,000 cases × 100 features - Noisy labels y = X @ w_star + small_noise","code":"library(Rmlx) #>  #> Attaching package: 'Rmlx' #> The following object is masked from 'package:stats': #>  #>     fft #> The following objects are masked from 'package:base': #>  #>     asplit, backsolve, chol2inv, col, colMeans, colSums, diag, drop, #>     outer, row, rowMeans, rowSums, svd  # Problem metadata num_features <- 100 num_cases <- 10000 num_iters <- 1200          # iterations of SGD learning_rate <- 0.01      # learning rate for SGD  # Set seed for reproducibility set.seed(42)  # True parameters (what we're trying to learn) w_star <- mlx_rand_normal(c(num_features, 1))  # Input examples (design matrix) X <- mlx_rand_normal(c(num_cases, num_features))  # Noisy labels eps <- 1e-2 * mlx_rand_normal(c(num_cases, 1)) y <- X %*% w_star + eps"},{"path":"https://hughjonesd.github.io/Rmlx/articles/linear-regression.html","id":"define-the-loss-function","dir":"Articles","previous_headings":"","what":"Define the Loss Function","title":"Linear Regression with MLX","text":"mean squared error loss standard choice regression: loss measures well parameters w predict labels. Lower loss means better predictions.","code":"# Define loss function loss_fn <- function(w) {   preds <- X %*% w   residuals <- preds - y   0.5 * mean(residuals * residuals) }"},{"path":"https://hughjonesd.github.io/Rmlx/articles/linear-regression.html","id":"automatic-differentiation","dir":"Articles","previous_headings":"","what":"Automatic Differentiation","title":"Linear Regression with MLX","text":"Rmlx provides mlx_grad() compute gradients via automatic differentiation. computes gradient loss respect parameters:","code":"# Get the gradient function grad_fn <- function(w) {   mlx_grad(loss_fn, w)[[1]] }  train_sgd <- function(steps = num_iters, step_size = learning_rate, verbose = TRUE) {   w <- 1e-2 * mlx_rand_normal(c(num_features, 1))   for (i in seq_len(steps)) {     grad <- grad_fn(w)     w <- w - step_size * grad     mlx_eval(w)     if (verbose && i %% 1000 == 0) {       cat(\"Iteration\", i, \"- Loss:\", as.vector(loss_fn(w)), \"\\n\")     }   }   w }"},{"path":"https://hughjonesd.github.io/Rmlx/articles/linear-regression.html","id":"training-loop-with-sgd","dir":"Articles","previous_headings":"","what":"Training Loop with SGD","title":"Linear Regression with MLX","text":"train repeatedly computing gradients updating parameters. iteration, : Compute gradient loss respect w Update parameters using gradient step Force evaluation prevent computation graph growing unbounded Monitor progress printing loss every 1000 iterations","code":"w_sgd <- train_sgd() #> Iteration 1000 - Loss: 5.0589e-05"},{"path":"https://hughjonesd.github.io/Rmlx/articles/linear-regression.html","id":"method-2-closed-form-regression-via-matrix-algebra","dir":"Articles","previous_headings":"","what":"Method 2: Closed-form Regression via Matrix Algebra","title":"Linear Regression with MLX","text":"Gradient descent flexible, linear regression also closed-form solution can obtained via QR decomposition. Rather forming X⊤XX^\\top X explicitly, factor X=QRX = QR Q⊤Q=IQ^\\top Q = solve triangular system Rw=Q⊤yRw = Q^\\top y:","code":"mlx_normal_eq <- function(X, y) {   qr_res <- qr(X)   q <- qr_res$Q   r <- qr_res$R   q_ty <- crossprod(q, y)   mlx_solve_triangular(r, q_ty, upper = TRUE) }  w_closed <- mlx_normal_eq(X, y) mlx_eval(w_closed)  closed_error <- w_closed - w_star closed_error_norm <- sqrt(sum(closed_error * closed_error)) cat(\"Closed-form ||w - w*|| =\", as.vector(closed_error_norm), \"\\n\") #> Closed-form ||w - w*|| = 0.0009406764"},{"path":"https://hughjonesd.github.io/Rmlx/articles/linear-regression.html","id":"accelerating-the-closed-form-solution-with-mlx_compile","dir":"Articles","previous_headings":"","what":"Accelerating the Closed-form Solution with mlx_compile()","title":"Linear Regression with MLX","text":"closed-form function mixes several MLX primitives. can trace fuse operations mlx_compile(). first call incurs tracing cost; subsequent calls reuse compiled graph.","code":"compiled_normal_eq <- mlx_compile(mlx_normal_eq)  # Warm-up call performs tracing and compilation mlx_eval(compiled_normal_eq(X, y))  # Re-use the compiled function w_compiled <- compiled_normal_eq(X, y) mlx_eval(w_compiled)  compiled_error <- w_compiled - w_star compiled_error_norm <- sqrt(sum(compiled_error * compiled_error)) cat(\"Compiled closed-form ||w - w*|| =\", as.vector(compiled_error_norm), \"\\n\") #> Compiled closed-form ||w - w*|| = 0.0009406764"},{"path":"https://hughjonesd.github.io/Rmlx/articles/linear-regression.html","id":"accuracy-and-performance-comparison","dir":"Articles","previous_headings":"","what":"Accuracy and Performance Comparison","title":"Linear Regression with MLX","text":"compare approaches measure elapsed time several repetitions resulting distance estimate true coefficients. also add base R’s normal-equation implementation reference.","code":"library(bench)  # Fit models once for accuracy measurements w_sgd <- train_sgd(verbose = FALSE) w_closed <- mlx_normal_eq(X, y) compiled_normal_eq <- mlx_compile(mlx_normal_eq) mlx_eval(compiled_normal_eq(X, y)) w_compiled <- compiled_normal_eq(X, y) X_r <- as.matrix(X) y_r <- as.matrix(y) w_base <- matrix(lm.fit(X_r, y_r[, 1])$coefficients, ncol = 1)  # Accuracy comparisons to_norm <- function(w_hat) {   diff <- w_hat - as.matrix(w_star)   sqrt(sum(diff * diff)) }  # Benchmark timings (compiled solution already warm) timings <- bench::mark(   sgd = {     res <- train_sgd(verbose = FALSE)     mlx_eval(res)   },   mlx_closed = {     res <- mlx_normal_eq(X, y)     mlx_eval(res)   },   mlx_closed_compiled = {     res <- compiled_normal_eq(X, y)     mlx_eval(res)   },   base_R = {     lm.fit(X_r, y_r[, 1])$coefficients   },   iterations = 3,   check = FALSE ) |>   as.data.frame() #> Warning: Some expressions had a GC in every iteration; so filtering is #> disabled.  results <- data.frame(   method = c(\"SGD\", \"MLX closed form\", \"MLX closed form (compiled)\", \"Base R\"),   median_time = timings$median,   parameter_error = c(     to_norm(as.matrix(w_sgd)),     to_norm(as.matrix(w_closed)),     to_norm(as.matrix(w_compiled)),     to_norm(w_base)   ) ) knitr::kable(results, digits = 4)"},{"path":"https://hughjonesd.github.io/Rmlx/articles/linear-regression.html","id":"device-selection","dir":"Articles","previous_headings":"","what":"Device Selection","title":"Linear Regression with MLX","text":"default, computations run GPU speed. Switch CPU needed:","code":"# Use CPU (useful for debugging) mlx_default_device(\"cpu\") #> [1] \"cpu\"  # Or back to GPU mlx_default_device(\"gpu\") #> [1] \"gpu\""},{"path":"https://hughjonesd.github.io/Rmlx/articles/neural-networks.html","id":"building-a-neural-network","dir":"Articles","previous_headings":"","what":"Building a Neural Network","title":"Neural Networks with Rmlx","text":"Rmlx provides modular neural network components can combined using mlx_sequential(). ’s simple multi-layer perceptron (MLP) binary classification:","code":"library(Rmlx) #>  #> Attaching package: 'Rmlx' #> The following object is masked from 'package:stats': #>  #>     fft #> The following objects are masked from 'package:base': #>  #>     asplit, backsolve, chol2inv, col, colMeans, colSums, diag, drop, #>     outer, row, rowMeans, rowSums, svd  # Create a 3-layer MLP mlp <- mlx_sequential(   mlx_linear(2, 32),    # Input: 2 features   mlx_relu(),   mlx_dropout(p = 0.2),   mlx_linear(32, 16),   mlx_relu(),   mlx_linear(16, 1),    # Output: 1 logit   mlx_sigmoid()         # Probability output )"},{"path":"https://hughjonesd.github.io/Rmlx/articles/neural-networks.html","id":"generating-training-data","dir":"Articles","previous_headings":"","what":"Generating Training Data","title":"Neural Networks with Rmlx","text":"Let’s create simple binary classification dataset:","code":"set.seed(42)  # Generate spiral dataset n_samples <- 2000 noise <- 0.1  # Class 0: first spiral starting at angle 0 theta0 <- runif(n_samples/2, 0, 4*pi) r0 <- theta0 / (4*pi) + rnorm(n_samples/2, 0, noise) x0 <- cbind(r0 * cos(theta0), r0 * sin(theta0)) y0 <- rep(0, n_samples/2)  # Class 1: second spiral starting at angle pi (interleaved) theta1 <- runif(n_samples/2, 0, 4*pi) r1 <- theta1 / (4*pi) + rnorm(n_samples/2, 0, noise) x1 <- cbind(r1 * cos(theta1 + pi), r1 * sin(theta1 + pi)) y1 <- rep(1, n_samples/2)  # Combine x_train <- rbind(x0, x1) y_train <- c(y0, y1)  # Convert to MLX tensors x_mlx <- as_mlx(x_train) y_mlx <- as_mlx(matrix(y_train, ncol = 1)) # Visualize the training data plot(x_train[, 1], x_train[, 2],      col = ifelse(y_train == 0, \"blue\", \"red\"),      pch = 19, cex = 0.8,      main = \"Training Data\",      xlab = \"Feature 1\", ylab = \"Feature 2\")"},{"path":"https://hughjonesd.github.io/Rmlx/articles/neural-networks.html","id":"training-loop","dir":"Articles","previous_headings":"","what":"Training Loop","title":"Neural Networks with Rmlx","text":"Define loss function train using gradient descent:","code":"# Loss function operating on the module loss_fn <- function(module, x, y) {   preds <- mlx_forward(module, x)   mlx_binary_cross_entropy(preds, y) }  # Training parameters learning_rate <- 0.05 n_epochs <- 600  # Optimizer and training mode optimizer <- mlx_optimizer_sgd(mlx_parameters(mlp), lr = learning_rate) mlx_set_training(mlp, TRUE)  for (epoch in seq_len(n_epochs)) {   step <- mlx_train_step(mlp, loss_fn, optimizer, x_mlx, y_mlx)    if (epoch %% 100 == 0) {     loss_value <- as.numeric(as.matrix(step$loss))     cat(sprintf(\"Epoch %d, Loss: %.4f\\n\", epoch, loss_value))   } } #> Epoch 100, Loss: 0.6702 #> Epoch 200, Loss: 0.6622 #> Epoch 300, Loss: 0.6577 #> Epoch 400, Loss: 0.6585 #> Epoch 500, Loss: 0.6551 #> Epoch 600, Loss: 0.6554  mlx_set_training(mlp, FALSE)"},{"path":"https://hughjonesd.github.io/Rmlx/articles/neural-networks.html","id":"evaluating-model-performance","dir":"Articles","previous_headings":"","what":"Evaluating Model Performance","title":"Neural Networks with Rmlx","text":"Let’s evaluate model’s predictions:","code":"# Make predictions on all training points predictions <- mlx_forward(mlp, x_mlx) pred_probs <- as.matrix(predictions) pred_classes <- ifelse(pred_probs > 0.5, 1, 0)  # Confusion matrix confusion <- table(Actual = y_train, Predicted = pred_classes) print(confusion) #>       Predicted #> Actual   0   1 #>      0 772 228 #>      1 543 457  # Calculate accuracy accuracy <- sum(diag(confusion)) / sum(confusion) cat(sprintf(\"\\nAccuracy: %.2f%%\\n\", accuracy * 100)) #>  #> Accuracy: 61.45% # Plot predicted classes plot(x_train[, 1], x_train[, 2],      col = ifelse(pred_classes == 0, \"blue\", \"red\"),      pch = 19, cex = 0.8,      main = \"Predicted Classes\",      xlab = \"Feature 1\", ylab = \"Feature 2\")"},{"path":"https://hughjonesd.github.io/Rmlx/articles/neural-networks.html","id":"using-different-architectures","dir":"Articles","previous_headings":"","what":"Using Different Architectures","title":"Neural Networks with Rmlx","text":"Rmlx provides various layer types different architectures:","code":""},{"path":"https://hughjonesd.github.io/Rmlx/articles/neural-networks.html","id":"convolutional-features","dir":"Articles","previous_headings":"Using Different Architectures","what":"Convolutional Features","title":"Neural Networks with Rmlx","text":"full convolution layers require C++ implementation, can combine linear layers reshape operations:","code":"# Classifier with normalization classifier <- mlx_sequential(   mlx_linear(10, 64),   mlx_layer_norm(64),   mlx_relu(),   mlx_dropout(p = 0.5),   mlx_linear(64, 32),   mlx_batch_norm(32),   mlx_relu(),   mlx_linear(32, 3),   mlx_softmax_layer()  # Multi-class output )"},{"path":"https://hughjonesd.github.io/Rmlx/articles/neural-networks.html","id":"embeddings-for-categorical-data","dir":"Articles","previous_headings":"Using Different Architectures","what":"Embeddings for Categorical Data","title":"Neural Networks with Rmlx","text":"Use mlx_embedding() categorical inputs:","code":"# Text/token embeddings vocab_size <- 10000 embed_dim <- 128  embedding_net <- mlx_sequential(   mlx_embedding(vocab_size, embed_dim),   mlx_linear(embed_dim, 64),   mlx_relu(),   mlx_linear(64, 1) )  # Input: token indices (1-indexed) tokens <- as_mlx(c(42, 17, 99)) output <- mlx_forward(embedding_net, tokens)"},{"path":"https://hughjonesd.github.io/Rmlx/articles/neural-networks.html","id":"available-loss-functions","dir":"Articles","previous_headings":"","what":"Available Loss Functions","title":"Neural Networks with Rmlx","text":"Rmlx implements common loss functions: mlx_mse_loss(): Mean squared error (regression) mlx_l1_loss(): Mean absolute error (robust regression) mlx_binary_cross_entropy(): Binary classification mlx_cross_entropy(): Multi-class classification supports reduction = \"mean\", \"sum\", \"none\".","code":""},{"path":"https://hughjonesd.github.io/Rmlx/articles/neural-networks.html","id":"available-activation-functions","dir":"Articles","previous_headings":"","what":"Available Activation Functions","title":"Neural Networks with Rmlx","text":"mlx_relu(): Rectified Linear Unit mlx_gelu(): Gaussian Error Linear Unit mlx_sigmoid(): Logistic sigmoid mlx_tanh(): Hyperbolic tangent mlx_silu(): Sigmoid Linear Unit (Swish) mlx_leaky_relu(): Leaky ReLU configurable slope mlx_softmax_layer(): Softmax normalization","code":""},{"path":"https://hughjonesd.github.io/Rmlx/articles/neural-networks.html","id":"regularization-and-normalization","dir":"Articles","previous_headings":"","what":"Regularization and Normalization","title":"Neural Networks with Rmlx","text":"mlx_dropout(): Dropout regularization mlx_layer_norm(): Layer normalization mlx_batch_norm(): Batch normalization Remember set training mode appropriately:","code":"model <- mlx_sequential(   mlx_linear(2, 4),   mlx_dropout(0.5) )  # Training mlx_set_training(model, TRUE)  # Evaluation mlx_set_training(model, FALSE)"},{"path":"https://hughjonesd.github.io/Rmlx/articles/neural-networks.html","id":"best-practices","dir":"Articles","previous_headings":"","what":"Best Practices","title":"Neural Networks with Rmlx","text":"Always evaluate: Call mlx_eval() parameter updates trigger computation Training mode: Set models training mode training, evaluation mode inference Gradient computation: Use argnums mlx_grad() specify arguments differentiate Device management: Ensure tensors device (GPU/CPU)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/articles/neural-networks.html","id":"further-reading","dir":"Articles","previous_headings":"","what":"Further Reading","title":"Neural Networks with Rmlx","text":"See vignette(\"linear-regression\") simpler optimization example Check ?mlx_grad automatic differentiation details Refer MLX Python documentation advanced patterns","code":""},{"path":"https://hughjonesd.github.io/Rmlx/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"David Hugh-Jones. Author, maintainer.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Hugh-Jones D (2025). Rmlx: R Interface Apple's MLX library GPU-accelerated arrays. R package version 0.1.0.9000, https://hughjonesd.github.io/Rmlx/.","code":"@Manual{,   title = {Rmlx: R Interface to Apple's MLX library for GPU-accelerated arrays},   author = {David Hugh-Jones},   year = {2025},   note = {R package version 0.1.0.9000},   url = {https://hughjonesd.github.io/Rmlx/}, }"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"rmlx","dir":"","previous_headings":"","what":"R Interface to Apple's MLX library for GPU-accelerated arrays","title":"R Interface to Apple's MLX library for GPU-accelerated arrays","text":"Rmlx provides R interface Apple’s MLX framework, enabling high-performance GPU computing Apple Silicon. Modern Macs GPU, great performing matrix operations. Statistics uses lot matrix operations. now, way R Mac use GPU. Rmlx exists fill gap. early stage largely vibe-coded Claude/OpenAI Codex. Obviously, use risk! Contributions welcome. particular great implement function import/export, neural network components, etc. companion library hughjonesd/RmlxStats, focuses implementing common statistical methods GPU. C++ functions implemented via R functions mlx_ prefix. addition, package defines mlx-specific methods many R matrix operations, including arithmetic, subsetting matrix algebra.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"requirements","dir":"","previous_headings":"","what":"Requirements","title":"R Interface to Apple's MLX library for GPU-accelerated arrays","text":"MacOS Apple Silicon Linux CUDA MacOS/Linux CPU-build.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"R Interface to Apple's MLX library for GPU-accelerated arrays","text":"brew install mlx Linux equivalent. just install package normal: Alternatively, can build mlx source.","code":"remotes::install(\"hughjonesd/Rmlx\")"},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"fast-gpu-operations","dir":"","previous_headings":"Features","what":"Fast GPU Operations","title":"R Interface to Apple's MLX library for GPU-accelerated arrays","text":"","code":"library(Rmlx) #>  #> Attaching package: 'Rmlx' #> The following object is masked from 'package:stats': #>  #>     fft #> The following objects are masked from 'package:base': #>  #>     asplit, backsolve, chol2inv, col, colMeans, colSums, diag, drop, #>     outer, row, rowMeans, rowSums, svd  A <- matrix(rnorm(1e6), 1e3, 1e3) A_mlx <- as_mlx(A) system.time(solve(A)) #>    user  system elapsed  #>   0.378   0.005   0.555 system.time(mlx_eval(solve(A_mlx)))  #>    user  system elapsed  #>   0.008   0.006   0.015"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"lazy-evaluation","dir":"","previous_headings":"Features","what":"Lazy Evaluation","title":"R Interface to Apple's MLX library for GPU-accelerated arrays","text":"Operations recorded executed explicitly evaluated:","code":"x <- as_mlx(matrix(1:25, 5, 5)) y <- as_mlx(matrix(101:125, 5, 5))  # Lazy - not computed yet z <- x + y * 2  # Force evaluation mlx_eval(z)  # Or convert to R (automatically evaluates) as.matrix(z) #>      [,1] [,2] [,3] [,4] [,5] #> [1,]  203  218  233  248  263 #> [2,]  206  221  236  251  266 #> [3,]  209  224  239  254  269 #> [4,]  212  227  242  257  272 #> [5,]  215  230  245  260  275"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"device-management","dir":"","previous_headings":"Features","what":"Device Management","title":"R Interface to Apple's MLX library for GPU-accelerated arrays","text":"M series chips shared memory CPU GPU, switching devices costless.","code":"# Check/set default device dev <- mlx_default_device()            mlx_default_device(\"cpu\")    # Switch to CPU mlx_default_device(dev)      # Back to GPU  # Create on specific device x_gpu <- as_mlx(matrix(1:12, 3, 4), device = \"gpu\") x_cpu <- as_mlx(matrix(1:12, 3, 4), device = \"cpu\")"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"subsetting","dir":"","previous_headings":"Features","what":"Subsetting","title":"R Interface to Apple's MLX library for GPU-accelerated arrays","text":"Subsetting works like base R:","code":"x <- as_mlx(matrix(1:9, 3, 3)) x[1:2, 1:2] #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]    1    4 #> [2,]    2    5  # drop = FALSE by default x[1, ] #> mlx array [1 x 3] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] #> [1,]    1    4    7  logical_mask <- c(TRUE, FALSE, TRUE) x[logical_mask, ] #> mlx array [2 x 3] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] #> [1,]    1    4    7 #> [2,]    3    6    9  # subset assignment  x[, 2] <- c(0, 0, 0) x #> mlx array [3 x 3] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] #> [1,]    1    0    7 #> [2,]    2    0    8 #> [3,]    3    0    9"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"arithmetic","dir":"","previous_headings":"Features","what":"Arithmetic","title":"R Interface to Apple's MLX library for GPU-accelerated arrays","text":"","code":"x <- as_mlx(matrix(1:12, 3, 4)) y <- as_mlx(matrix(13:24, 3, 4))  # Element-wise operations sum_xy <- x + y diff_xy <- x - y prod_xy <- x * y quot_xy <- x / y pow_xy <- x ^ 2  # Comparisons lt <- x < y eq <- x == y  # Bring results back to R as.matrix(sum_xy) #>      [,1] [,2] [,3] [,4] #> [1,]   14   20   26   32 #> [2,]   16   22   28   34 #> [3,]   18   24   30   36 as.matrix(lt) #>      [,1] [,2] [,3] [,4] #> [1,] TRUE TRUE TRUE TRUE #> [2,] TRUE TRUE TRUE TRUE #> [3,] TRUE TRUE TRUE TRUE"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"matrix-operations","dir":"","previous_headings":"Features","what":"Matrix Operations","title":"R Interface to Apple's MLX library for GPU-accelerated arrays","text":"Many base R matrix functions mlx-specific methods:","code":"a <- as_mlx(matrix(1:6, 2, 3)) b <- as_mlx(matrix(1:6, 3, 2))  # rbind, cbind, transpose rbind(a, t(b)) #> mlx array [4 x 3] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] #> [1,]    1    3    5 #> [2,]    2    4    6 #> [3,]    1    2    3 #> [4,]    4    5    6 cbind(a, t(b)) #> mlx array [2 x 6] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] [,4] [,5] [,6] #> [1,]    1    3    5    1    2    3 #> [2,]    2    4    6    4    5    6  # Matrix algebra a %*% b #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]   22   49 #> [2,]   28   64  # Reductions sum(a) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 21 colMeans(a) #> mlx array [3] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 1.5 3.5 5.5  # Cumulative operations flatten column-major cumsum(a) #> mlx array [6] #>   dtype: float32 #>   device: gpu #>   values: #> [1]  1  3  6 10 15 21  qr_res <- qr(a) svd_res <- svd(a) chol_res <- chol(a[, 1:2]) fft_res <- fft(a) crossprod_res <- crossprod(a, b[1:2, ]) solve_res <- solve(a[, 1:2], b[1:2, ])"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"automatic-differentiation","dir":"","previous_headings":"Features","what":"Automatic Differentiation","title":"R Interface to Apple's MLX library for GPU-accelerated arrays","text":"","code":"loss <- function(w, x, y) {   preds <- x %*% w   resids <- preds - y   sum(resids * resids) / length(y) }  x <- as_mlx(matrix(rnorm(20), 5, 4)) y <- as_mlx(matrix(rnorm(5), 5, 1)) w <- as_mlx(matrix(0, 4, 1))  grads <- mlx_grad(loss, w, x, y)  # Inspect gradient as.matrix(grads[[1]]) #>           [,1] #> [1,] 0.9005783 #> [2,] 0.2985840 #> [3,] 0.6431852 #> [4,] 0.7269748  # Simple SGD loop model <- mlx_linear(4, 1, bias = FALSE) opt <- mlx_optimizer_sgd(mlx_parameters(model), lr = 0.1) loss_fn <- function(mod, data_x, data_y) {   preds <- mlx_forward(mod, data_x)   resids <- preds - data_y   sum(resids * resids) / length(data_y) } for (step in 1:50) {   mlx_train_step(model, loss_fn, opt, x, y) }  # Check final loss ypred <- mlx_forward(model, x) mean((ypred - y) * (ypred - y)) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 0.1833142"},{"path":"https://hughjonesd.github.io/Rmlx/index.html","id":"learning-more","dir":"","previous_headings":"","what":"Learning more","title":"R Interface to Apple's MLX library for GPU-accelerated arrays","text":"Package website Apple MLX documentation Package help Function reference","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Math.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Math operations for MLX arrays — Math.mlx","title":"Math operations for MLX arrays — Math.mlx","text":"Math operations MLX arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Math.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Math operations for MLX arrays — Math.mlx","text":"","code":"# S3 method for class 'mlx' Math(x, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/Math.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Math operations for MLX arrays — Math.mlx","text":"x mlx array. ... Additional arguments (ignored)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Math.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Math operations for MLX arrays — Math.mlx","text":"mlx object result","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/Math.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Math operations for MLX arrays — Math.mlx","text":"","code":"x <- as_mlx(matrix(c(-1, 0, 1), 3, 1)) sin(x) #> mlx array [3 x 1] #>   dtype: float32 #>   device: gpu #>   values: #>           [,1] #> [1,] -0.841471 #> [2,]  0.000000 #> [3,]  0.841471 round(x + 0.4) #> mlx array [3 x 1] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] #> [1,]   -1 #> [2,]    0 #> [3,]    1"},{"path":"https://hughjonesd.github.io/Rmlx/reference/Ops.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Arithmetic and comparison operators for MLX arrays — Ops.mlx","title":"Arithmetic and comparison operators for MLX arrays — Ops.mlx","text":"Arithmetic comparison operators MLX arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Ops.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Arithmetic and comparison operators for MLX arrays — Ops.mlx","text":"","code":"# S3 method for class 'mlx' Ops(e1, e2 = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/Ops.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Arithmetic and comparison operators for MLX arrays — Ops.mlx","text":"e1 First operand (mlx numeric) e2 Second operand (mlx numeric)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Ops.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Arithmetic and comparison operators for MLX arrays — Ops.mlx","text":"mlx object","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/Ops.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Arithmetic and comparison operators for MLX arrays — Ops.mlx","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) y <- as_mlx(matrix(5:8, 2, 2)) x + y #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]    6   10 #> [2,]    8   12 x < y #> mlx array [2 x 2] #>   dtype: bool #>   device: gpu #>   values: #>      [,1] [,2] #> [1,] TRUE TRUE #> [2,] TRUE TRUE"},{"path":"https://hughjonesd.github.io/Rmlx/reference/Rmlx-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Rmlx: R Interface to Apple's MLX Arrays — Rmlx-package","title":"Rmlx: R Interface to Apple's MLX Arrays — Rmlx-package","text":"package provides R interface Apple's MLX (Machine Learning eXchange) library GPU-accelerated array operations Apple Silicon.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Rmlx-package.html","id":"key-features","dir":"Reference","previous_headings":"","what":"Key Features","title":"Rmlx: R Interface to Apple's MLX Arrays — Rmlx-package","text":"Lazy evaluation: Operations computed explicitly evaluated GPU acceleration: Leverage Metal Apple Silicon Familiar syntax: S3 methods standard R operations Unified memory: Efficient data sharing CPU GPU","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Rmlx-package.html","id":"lazy-evaluation","dir":"Reference","previous_headings":"","what":"Lazy Evaluation","title":"Rmlx: R Interface to Apple's MLX Arrays — Rmlx-package","text":"MLX arrays use lazy evaluation default. Operations recorded executed : call mlx_eval() convert R .matrix() .vector() result needed another computation package implements C++ API via calls mlx_ prefix, also ships S3 methods many base generics, common R matrix operations continue work MLX arrays. R conventions used throughout: example, indexing 1-based.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/Rmlx-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Rmlx: R Interface to Apple's MLX Arrays — Rmlx-package","text":"Maintainer: David Hugh-Jones david@hughjones.com","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Summary.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary operations for MLX arrays — Summary.mlx","title":"Summary operations for MLX arrays — Summary.mlx","text":"S3 group generic summary functions including sum(), prod(), min(), max(), (), ().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Summary.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary operations for MLX arrays — Summary.mlx","text":"","code":"# S3 method for class 'mlx' Summary(x, ..., na.rm = FALSE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/Summary.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary operations for MLX arrays — Summary.mlx","text":"x mlx array object coercible mlx ... Additional mlx arrays (reducing multiple arrays), named arguments axes (legacy axis) drop na.rm Logical; currently ignored mlx arrays (generates warning TRUE)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/Summary.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary operations for MLX arrays — Summary.mlx","text":"mlx array summary result","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/Summary.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary operations for MLX arrays — Summary.mlx","text":"","code":"x <- as_mlx(matrix(1:6, 2, 3)) sum(x) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 21 any(x > 3) #> [1] TRUE all(x > 0) #> [1] TRUE"},{"path":"https://hughjonesd.github.io/Rmlx/reference/abind.html","id":null,"dir":"Reference","previous_headings":"","what":"Bind mlx arrays along an axis — abind","title":"Bind mlx arrays along an axis — abind","text":"Bind mlx arrays along axis","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/abind.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bind mlx arrays along an axis — abind","text":"","code":"abind(..., along = 1L)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/abind.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bind mlx arrays along an axis — abind","text":"... One mlx arrays (single list arrays) combine. along Positive integer giving existing axis (1-indexed) along bind inputs.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/abind.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bind mlx arrays along an axis — abind","text":"mlx array formed concatenating inputs along along.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/abind.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bind mlx arrays along an axis — abind","text":"MLX-backed alternative abind::abind(). inputs must share shape non-bound axes. along axis must already exist; create new axis use mlx_stack().","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/abind.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bind mlx arrays along an axis — abind","text":"","code":"x <- as_mlx(array(1:12, c(2, 3, 2))) y <- as_mlx(array(13:24, c(2, 3, 2))) z <- abind(x, y, along = 3) dim(z) #> [1] 2 3 4"},{"path":"https://hughjonesd.github.io/Rmlx/reference/all.equal.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Test if two MLX arrays are (nearly) equal — all.equal.mlx","title":"Test if two MLX arrays are (nearly) equal — all.equal.mlx","text":"S3 method .equal following R semantics. Returns TRUE arrays close, character vector describing differences .","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/all.equal.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test if two MLX arrays are (nearly) equal — all.equal.mlx","text":"","code":"# S3 method for class 'mlx' all.equal(target, current, tolerance = sqrt(.Machine$double.eps), ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/all.equal.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test if two MLX arrays are (nearly) equal — all.equal.mlx","text":"target, current MLX arrays compare tolerance Numeric tolerance comparison (default: sqrt(.Machine$double.eps)) ... Additional arguments (currently ignored)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/all.equal.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test if two MLX arrays are (nearly) equal — all.equal.mlx","text":"Either TRUE character vector describing differences","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/all.equal.mlx.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Test if two MLX arrays are (nearly) equal — all.equal.mlx","text":"method follows R's .equal() semantics: Returns TRUE arrays close within tolerance Returns character vector describing differences otherwise Checks dimensions/shapes comparing values tolerance converted MLX's rtol atol parameters: rtol = tolerance atol = tolerance","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/all.equal.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test if two MLX arrays are (nearly) equal — all.equal.mlx","text":"","code":"a <- as_mlx(c(1.0, 2.0, 3.0)) b <- as_mlx(c(1.0 + 1e-6, 2.0 + 1e-6, 3.0 + 1e-6)) all.equal(a, b)  # TRUE #> [1] \"Arrays are not all close within tolerance\"  c <- as_mlx(c(1.0, 2.0, 10.0)) all.equal(a, c)  # Character vector describing difference #> [1] \"Arrays are not all close within tolerance\""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.array.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert MLX array to R array — as.array.mlx","title":"Convert MLX array to R array — as.array.mlx","text":"Convert MLX array R array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.array.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert MLX array to R array — as.array.mlx","text":"","code":"# S3 method for class 'mlx' as.array(x, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.array.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert MLX array to R array — as.array.mlx","text":"x mlx array. ... Additional arguments (ignored)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.array.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert MLX array to R array — as.array.mlx","text":"numeric array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.array.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert MLX array to R array — as.array.mlx","text":"","code":"x <- as_mlx(matrix(1:8, 2, 4)) as.array(x) #>      [,1] [,2] [,3] [,4] #> [1,]    1    3    5    7 #> [2,]    2    4    6    8"},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.double.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert MLX array to numeric vector — as.double.mlx","title":"Convert MLX array to numeric vector — as.double.mlx","text":"Converts MLX array numeric (double) vector, dropping dimensions coercing types needed. Integers booleans converted doubles.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.double.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert MLX array to numeric vector — as.double.mlx","text":"","code":"# S3 method for class 'mlx' as.double(x, ...)  # S3 method for class 'mlx' as.numeric(x, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.double.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert MLX array to numeric vector — as.double.mlx","text":"x mlx array. ... Additional arguments (currently unused).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.double.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert MLX array to numeric vector — as.double.mlx","text":"numeric vector.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.double.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert MLX array to numeric vector — as.double.mlx","text":"","code":"x_int <- as_mlx(c(1L, 2L, 3L), dtype = \"int32\") as.numeric(x_int)  # Returns c(1.0, 2.0, 3.0) #> [1] 1 2 3  x_bool <- as_mlx(c(TRUE, FALSE, TRUE)) as.numeric(x_bool)  # Returns c(1.0, 0.0, 1.0) #> [1] 1 0 1"},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.logical.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert MLX array to logical vector — as.logical.mlx","title":"Convert MLX array to logical vector — as.logical.mlx","text":"Convert MLX array logical vector","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.logical.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert MLX array to logical vector — as.logical.mlx","text":"","code":"# S3 method for class 'mlx' as.logical(x, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.logical.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert MLX array to logical vector — as.logical.mlx","text":"x mlx array. ... Additional arguments passed base::.vector().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.logical.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert MLX array to logical vector — as.logical.mlx","text":"logical vector.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.logical.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert MLX array to logical vector — as.logical.mlx","text":"","code":"x <- as_mlx(c(1, 0, 2)) as.logical(x) #> [1]  TRUE FALSE  TRUE"},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.matrix.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert MLX array to R matrix/array — as.matrix.mlx","title":"Convert MLX array to R matrix/array — as.matrix.mlx","text":"MLX arrays without dimension returned R vectors.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.matrix.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert MLX array to R matrix/array — as.matrix.mlx","text":"","code":"# S3 method for class 'mlx' as.matrix(x, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.matrix.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert MLX array to R matrix/array — as.matrix.mlx","text":"x mlx array. ... Additional arguments (ignored)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.matrix.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert MLX array to R matrix/array — as.matrix.mlx","text":"vector, matrix array (numeric logical depending dtype)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.matrix.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert MLX array to R matrix/array — as.matrix.mlx","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) as.matrix(x) #>      [,1] [,2] #> [1,]    1    3 #> [2,]    2    4"},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.vector.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert MLX array to R vector — as.vector.mlx","title":"Convert MLX array to R vector — as.vector.mlx","text":"Converts MLX array R vector. multi-dimensional arrays (2+ dimensions), array flattened column-major order (R's default).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.vector.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert MLX array to R vector — as.vector.mlx","text":"","code":"# S3 method for class 'mlx' as.vector(x, mode = \"any\")"},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.vector.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert MLX array to R vector — as.vector.mlx","text":"x mlx array. mode Character string specifying type vector return (passed base::.vector())","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.vector.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert MLX array to R vector — as.vector.mlx","text":"vector specified mode","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as.vector.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert MLX array to R vector — as.vector.mlx","text":"","code":"x <- as_mlx(1:5) as.vector(x) #> [1] 1 2 3 4 5  # Multi-dimensional arrays are flattened m <- as_mlx(matrix(1:6, 2, 3)) v <- as.vector(m)  # Flattened in column-major order"},{"path":"https://hughjonesd.github.io/Rmlx/reference/as_mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Create MLX array from R object — as_mlx","title":"Create MLX array from R object — as_mlx","text":"Create MLX array R object","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as_mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create MLX array from R object — as_mlx","text":"","code":"as_mlx(   x,   dtype = c(\"float32\", \"float64\", \"bool\", \"complex64\", \"int8\", \"int16\", \"int32\", \"int64\",     \"uint8\", \"uint16\", \"uint32\", \"uint64\"),   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/as_mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create MLX array from R object — as_mlx","text":"x Numeric, logical, complex vector, matrix, array convert dtype Data type MLX array. One : Floating point: \"float32\", \"float64\" Integer signed: \"int8\", \"int16\", \"int32\", \"int64\" Integer unsigned: \"uint8\", \"uint16\", \"uint32\", \"uint64\" : \"bool\", \"complex64\" specified, defaults \"float32\" numeric, \"bool\" logical, \"complex64\" complex inputs. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as_mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create MLX array from R object — as_mlx","text":"object class mlx","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/as_mlx.html","id":"default-type-behavior","dir":"Reference","previous_headings":"","what":"Default type behavior","title":"Create MLX array from R object — as_mlx","text":"dtype specified: Numeric vectors/arrays (including R integers 1:10) → float32 Logical vectors/arrays → bool Complex vectors/arrays → complex64","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as_mlx.html","id":"integer-types-require-explicit-dtype","dir":"Reference","previous_headings":"","what":"Integer types require explicit dtype","title":"Create MLX array from R object — as_mlx","text":"Important: R integer vectors (like 1:10) convert float32 default. create integer MLX arrays, must explicitly specify dtype:   design avoids unintentional integer promotion, since R creates integers many contexts floating-point intended.","code":"x <- as_mlx(1:10, dtype = \"int32\")  # Creates int32 array x <- as_mlx(1:10)                    # Creates float32 array"},{"path":"https://hughjonesd.github.io/Rmlx/reference/as_mlx.html","id":"supported-integer-types","dir":"Reference","previous_headings":"","what":"Supported integer types","title":"Create MLX array from R object — as_mlx","text":"Signed: int8 (-128 127), int16, int32, int64 Unsigned: uint8 (0 255), uint16, uint32, uint64","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as_mlx.html","id":"type-precision-notes","dir":"Reference","previous_headings":"","what":"Type precision notes","title":"Create MLX array from R object — as_mlx","text":"float64 supported emits warning downcasts float32 Integer arithmetic may promote types (e.g., int32 + int32 might → int64) Mixed integer/float operations promote float","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/as_mlx.html","id":"missing-values","dir":"Reference","previous_headings":"","what":"Missing values","title":"Create MLX array from R object — as_mlx","text":"MLX NA sentinel. pass numeric NA values R, stored NaN inside MLX returned R NaN. Use .nan() MLX arrays (method provided) need detect .","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/as_mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create MLX array from R object — as_mlx","text":"","code":"# Default float32 for numeric x <- as_mlx(c(1.5, 2.5, 3.5)) mlx_dtype(x)  # \"float32\" #> [1] \"float32\"  # R integers also default to float32 x <- as_mlx(1:10) mlx_dtype(x)  # \"float32\" #> [1] \"float32\"  # Explicit integer types x_int <- as_mlx(1:10, dtype = \"int32\") mlx_dtype(x_int)  # \"int32\" #> [1] \"int32\"  # Unsigned integers x_uint <- as_mlx(c(0, 128, 255), dtype = \"uint8\")  # Logical → bool mask <- as_mlx(c(TRUE, FALSE, TRUE)) mlx_dtype(mask)  # \"bool\" #> [1] \"bool\""},{"path":"https://hughjonesd.github.io/Rmlx/reference/asplit.html","id":null,"dir":"Reference","previous_headings":"","what":"Split mlx arrays along a margin — asplit","title":"Split mlx arrays along a margin — asplit","text":"asplit() extends base asplit() work mlx arrays delegating mlx_split(). x mlx result list mlx arrays; otherwise, base implementation used.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/asplit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split mlx arrays along a margin — asplit","text":"","code":"asplit(x, MARGIN, drop = FALSE)  # Default S3 method asplit(x, MARGIN, drop = FALSE)  # S3 method for class 'mlx' asplit(x, MARGIN, drop = FALSE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/asplit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split mlx arrays along a margin — asplit","text":"x array, including matrix. MARGIN vector giving margins split .     E.g., matrix 1 indicates rows, 2 indicates     columns, c(1, 2) indicates rows columns.     x named dimnames, can character vector     selecting dimension names. drop logical indicating whether splits drop     dimensions dimnames.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/asplit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split mlx arrays along a margin — asplit","text":"mlx inputs, list mlx arrays; otherwise matches base::asplit().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/asplit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Split mlx arrays along a margin — asplit","text":"Currently single MARGIN value supported mlx arrays.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/cbind.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Column-bind mlx arrays — cbind.mlx","title":"Column-bind mlx arrays — cbind.mlx","text":"Column-bind mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/cbind.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Column-bind mlx arrays — cbind.mlx","text":"","code":"# S3 method for class 'mlx' cbind(..., deparse.level = 1)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/cbind.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Column-bind mlx arrays — cbind.mlx","text":"... Objects bind. mlx arrays kept MLX; inputs coerced via as_mlx(). deparse.level Compatibility argument accepted S3 dispatch; ignored.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/cbind.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Column-bind mlx arrays — cbind.mlx","text":"mlx array stacked along second axis.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/cbind.mlx.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Column-bind mlx arrays — cbind.mlx","text":"Unlike base R's cbind(), function supports arrays 2 dimensions preserves dimensions except second (summed across inputs). Base R's cbind() flattens higher-dimensional arrays matrices binding.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/cbind.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Column-bind mlx arrays — cbind.mlx","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) y <- as_mlx(matrix(5:8, 2, 2)) cbind(x, y) #> mlx array [2 x 4] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] [,4] #> [1,]    1    3    5    7 #> [2,]    2    4    6    8"},{"path":"https://hughjonesd.github.io/Rmlx/reference/chol.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Cholesky decomposition for mlx arrays — chol.mlx","title":"Cholesky decomposition for mlx arrays — chol.mlx","text":"x symmetric positive semi-definite, \"behaviour undefined\" according MLX documentation.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/chol.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cholesky decomposition for mlx arrays — chol.mlx","text":"","code":"# S3 method for class 'mlx' chol(x, pivot = FALSE, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/chol.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cholesky decomposition for mlx arrays — chol.mlx","text":"x mlx matrix (2-dimensional array). pivot Ignored; pivoted decomposition supported. ... Additional arguments (unused).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/chol.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cholesky decomposition for mlx arrays — chol.mlx","text":"Upper-triangular Cholesky factor mlx matrix.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/chol.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cholesky decomposition for mlx arrays — chol.mlx","text":"","code":"x <- as_mlx(matrix(c(4, 1, 1, 3), 2, 2)) chol(x) #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1]     [,2] #> [1,]    2 0.500000 #> [2,]    0 1.658312"},{"path":"https://hughjonesd.github.io/Rmlx/reference/chol2inv.html","id":null,"dir":"Reference","previous_headings":"","what":"Inverse from Cholesky decomposition — chol2inv","title":"Inverse from Cholesky decomposition — chol2inv","text":"Compute inverse symmetric, positive definite matrix Cholesky decomposition. input x upper triangular matrix chol().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/chol2inv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inverse from Cholesky decomposition — chol2inv","text":"","code":"chol2inv(x, size = NCOL(x), ...)  # Default S3 method chol2inv(x, size = NCOL(x), ...)  # S3 method for class 'mlx' chol2inv(x, size = NCOL(x), ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/chol2inv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inverse from Cholesky decomposition — chol2inv","text":"x mlx matrix (2-dimensional array). size Ignored; included compatibility base R. ... Additional arguments (unused).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/chol2inv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inverse from Cholesky decomposition — chol2inv","text":"inverse original matrix (Cholesky decomposition).","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/chol2inv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inverse from Cholesky decomposition — chol2inv","text":"","code":"A <- as_mlx(matrix(c(4, 1, 1, 3), 2, 2)) U <- chol(A) A_inv <- chol2inv(U) # Verify: A %*% A_inv should be identity as.matrix(A %*% A_inv) #>      [,1] [,2] #> [1,]    1    0 #> [2,]    0    1"},{"path":"https://hughjonesd.github.io/Rmlx/reference/colMeans.html","id":null,"dir":"Reference","previous_headings":"","what":"Column means for mlx arrays — colMeans","title":"Column means for mlx arrays — colMeans","text":"Column means mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/colMeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Column means for mlx arrays — colMeans","text":"","code":"colMeans(x, ...)  # Default S3 method colMeans(x, na.rm = FALSE, dims = 1, ...)  # S3 method for class 'mlx' colMeans(x, na.rm = FALSE, dims = 1, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/colMeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Column means for mlx arrays — colMeans","text":"x array mlx array. ... Additional arguments forwarded base implementation. na.rm Logical; currently ignored mlx arrays. dims Dimensions passed base implementation x mlx array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/colMeans.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Column means for mlx arrays — colMeans","text":"mlx array x mlx, otherwise numeric vector.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/colMeans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Column means for mlx arrays — colMeans","text":"","code":"x <- as_mlx(matrix(1:6, 3, 2)) colMeans(x) #> mlx array [2] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 2 5"},{"path":"https://hughjonesd.github.io/Rmlx/reference/colSums.html","id":null,"dir":"Reference","previous_headings":"","what":"Column sums for mlx arrays — colSums","title":"Column sums for mlx arrays — colSums","text":"Column sums mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/colSums.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Column sums for mlx arrays — colSums","text":"","code":"colSums(x, ...)  # Default S3 method colSums(x, na.rm = FALSE, dims = 1, ...)  # S3 method for class 'mlx' colSums(x, na.rm = FALSE, dims = 1, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/colSums.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Column sums for mlx arrays — colSums","text":"x array mlx array. ... Additional arguments forwarded base implementation. na.rm Logical; currently ignored mlx arrays. dims Dimensions passed base implementation x mlx array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/colSums.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Column sums for mlx arrays — colSums","text":"mlx array x mlx, otherwise numeric vector.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/colSums.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Column sums for mlx arrays — colSums","text":"","code":"x <- as_mlx(matrix(1:6, 3, 2)) colSums(x) #> mlx array [2] #>   dtype: float32 #>   device: gpu #>   values: #> [1]  6 15"},{"path":"https://hughjonesd.github.io/Rmlx/reference/common_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Common Parameter Documentation — common_params","title":"Common Parameter Documentation — common_params","text":"Common Parameter Documentation","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/common_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Common Parameter Documentation — common_params","text":"device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream). dtype Data type string. Supported types include: Floating point: \"float32\", \"float64\" Integer: \"int8\", \"int16\", \"int32\", \"int64\", \"uint8\", \"uint16\", \"uint32\", \"uint64\" : \"bool\", \"complex64\" functions support types. See individual function documentation. axis Single axis (1-indexed). Supply positive integer 1 array rank. Use NULL helper interprets \"axes\" (see individual docs). axes Integer vector axes (1-indexed). Supply positive integers 1 array rank. Many helpers interpret NULL mean \"axes\"—see function details specifics. drop TRUE (default), drop dimensions length 1. FALSE, retain dimensions. Equivalent keepdims = TRUE underlying mlx functions. dim Integer vector specifying array dimensions (shape). x mlx array, R array/matrix/vector converted via as_mlx().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/conv_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Common Convolution Parameters — conv_params","title":"Common Convolution Parameters — conv_params","text":"Common Convolution Parameters","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/conv_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Common Convolution Parameters — conv_params","text":"input Input mlx array. Shape depends dimensionality (see individual functions). weight Weight array. Shape depends dimensionality (see individual functions). stride Stride convolution. Can scalar vector (length depends dimensionality). Default: 1 1D, c(1,1) 2D, c(1,1,1) 3D. padding Amount zero padding. Can scalar vector (length depends dimensionality). Default: 0 1D, c(0,0) 2D, c(0,0,0) 3D. dilation Spacing kernel elements. Can scalar vector (length depends dimensionality). Default: 1 1D, c(1,1) 2D, c(1,1,1) 3D. groups Number blocked connections input output channels. Default: 1.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/crossprod.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross product — crossprod.mlx","title":"Cross product — crossprod.mlx","text":"Cross product","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/crossprod.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross product — crossprod.mlx","text":"","code":"# S3 method for class 'mlx' crossprod(x, y = NULL, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/crossprod.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross product — crossprod.mlx","text":"x mlx matrix (2-dimensional array). y mlx matrix (default: NULL, uses x) ... Additional arguments passed base::crossprod.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/crossprod.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross product — crossprod.mlx","text":"t(x) %*% y mlx object","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/crossprod.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross product — crossprod.mlx","text":"","code":"x <- as_mlx(matrix(1:6, 2, 3)) crossprod(x) #> mlx array [3 x 3] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] #> [1,]    5   11   17 #> [2,]   11   25   39 #> [3,]   17   39   61"},{"path":"https://hughjonesd.github.io/Rmlx/reference/diag.html","id":null,"dir":"Reference","previous_headings":"","what":"Diagonal matrix extraction and construction — diag","title":"Diagonal matrix extraction and construction — diag","text":"Generic function extracting/constructing diagonal matrices.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/diag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Diagonal matrix extraction and construction — diag","text":"","code":"diag(x = 1, nrow, ncol, names = TRUE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/diag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Diagonal matrix extraction and construction — diag","text":"x object. nrow, ncol Optional dimensions matrix construction. names Logical indicating whether use names.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/dim-set-.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Set dimensions of MLX array — dim<-.mlx","title":"Set dimensions of MLX array — dim<-.mlx","text":"Reshapes MLX array specified dimensions. total number elements must remain .","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/dim-set-.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set dimensions of MLX array — dim<-.mlx","text":"","code":"# S3 method for class 'mlx' dim(x) <- value"},{"path":"https://hughjonesd.github.io/Rmlx/reference/dim-set-.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set dimensions of MLX array — dim<-.mlx","text":"x mlx array, R array/matrix/vector converted via as_mlx(). value Integer vector new dimensions","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/dim-set-.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set dimensions of MLX array — dim<-.mlx","text":"Reshaped mlx object","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/dim-set-.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set dimensions of MLX array — dim<-.mlx","text":"","code":"x <- as_mlx(1:12) dim(x) <- c(3, 4) dim(x) #> [1] 3 4"},{"path":"https://hughjonesd.github.io/Rmlx/reference/dim.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Get dimensions of MLX array — dim.mlx","title":"Get dimensions of MLX array — dim.mlx","text":"Get dimensions MLX array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/dim.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get dimensions of MLX array — dim.mlx","text":"","code":"# S3 method for class 'mlx' dim(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/dim.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get dimensions of MLX array — dim.mlx","text":"x mlx array, R array/matrix/vector converted via as_mlx().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/dim.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get dimensions of MLX array — dim.mlx","text":"Integer vector dimensions","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/dim.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get dimensions of MLX array — dim.mlx","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) dim(x) #> [1] 2 2"},{"path":"https://hughjonesd.github.io/Rmlx/reference/drop.html","id":null,"dir":"Reference","previous_headings":"","what":"Drop singleton dimensions — drop","title":"Drop singleton dimensions — drop","text":"drop() removes axes length one. base R objects dispatches base::drop(), drop.mlx() delegates mlx_squeeze() mlx arrays remain device.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/drop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Drop singleton dimensions — drop","text":"","code":"drop(x)  # Default S3 method drop(x)  # S3 method for class 'mlx' drop(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/drop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Drop singleton dimensions — drop","text":"x Object drop dimensions .","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/drop.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Drop singleton dimensions — drop","text":"object singleton dimensions removed. mlx inputs result another mlx array.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/fft.html","id":null,"dir":"Reference","previous_headings":"","what":"Fast Fourier Transform — fft","title":"Fast Fourier Transform — fft","text":"Extends stats::fft() work mlx objects delegating standard R implementation inputs.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/fft.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fast Fourier Transform — fft","text":"","code":"fft(z, inverse = FALSE, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/fft.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fast Fourier Transform — fft","text":"z Input transform. May numeric, complex, mlx object. inverse Logical flag; TRUE compute inverse transform. ... Passed default method.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/fft.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fast Fourier Transform — fft","text":"mlx inputs, mlx object containing complex frequency coefficients; otherwise base R result.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/fft.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fast Fourier Transform — fft","text":"","code":"z <- as_mlx(c(1, 2, 3, 4)) fft(z) #> mlx array [4] #>   dtype: complex64 #>   device: gpu #>   values: #> [1] 10+0i -2+2i -2+0i -2-2i fft(z, inverse = TRUE) #> mlx array [4] #>   dtype: complex64 #>   device: gpu #>   values: #> [1] 10+0i -2-2i -2+0i -2+2i"},{"path":"https://hughjonesd.github.io/Rmlx/reference/grapes-times-grapes-.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Matrix multiplication for MLX arrays — %*%.mlx","title":"Matrix multiplication for MLX arrays — %*%.mlx","text":"Matrix multiplication MLX arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/grapes-times-grapes-.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matrix multiplication for MLX arrays — %*%.mlx","text":"","code":"# S3 method for class 'mlx' x %*% y"},{"path":"https://hughjonesd.github.io/Rmlx/reference/grapes-times-grapes-.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matrix multiplication for MLX arrays — %*%.mlx","text":"x, y numeric complex matrices vectors.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/grapes-times-grapes-.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Matrix multiplication for MLX arrays — %*%.mlx","text":"mlx object","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/grapes-times-grapes-.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Matrix multiplication for MLX arrays — %*%.mlx","text":"","code":"x <- as_mlx(matrix(1:6, 2, 3)) y <- as_mlx(matrix(1:6, 3, 2)) x %*% y #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]   22   49 #> [2,]   28   64"},{"path":"https://hughjonesd.github.io/Rmlx/reference/is.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Test if object is an MLX array — is.mlx","title":"Test if object is an MLX array — is.mlx","text":"Test object MLX array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/is.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test if object is an MLX array — is.mlx","text":"","code":"is.mlx(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/is.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test if object is an MLX array — is.mlx","text":"x Object test","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/is.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test if object is an MLX array — is.mlx","text":"Logical","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/is.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test if object is an MLX array — is.mlx","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) is.mlx(x) #> [1] TRUE"},{"path":"https://hughjonesd.github.io/Rmlx/reference/kronecker.html","id":null,"dir":"Reference","previous_headings":"","what":"Kronecker product dispatcher — kronecker","title":"Kronecker product dispatcher — kronecker","text":"Wrapper around base::kronecker() enables S3 dispatch mlx arrays delegating base R inputs. Ensures base kronecker() generic can dispatch S3 mlx objects S4 dispatch unavailable.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/kronecker.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kronecker product dispatcher — kronecker","text":"","code":"kronecker(X, Y, FUN = \"*\", make.dimnames = FALSE, ...)  kronecker.default(X, Y, FUN = \"*\", make.dimnames = FALSE, ...)  # S4 method for class 'mlx,mlx' kronecker(X, Y, FUN = \"*\", make.dimnames = FALSE, ...)  # S4 method for class 'mlx,ANY' kronecker(X, Y, FUN = \"*\", make.dimnames = FALSE, ...)  # S4 method for class 'ANY,mlx' kronecker(X, Y, FUN = \"*\", make.dimnames = FALSE, ...)  # S3 method for class 'mlx' kronecker(X, Y, FUN = \"*\", ..., make.dimnames = FALSE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/kronecker.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kronecker product dispatcher — kronecker","text":"X vector array. Y vector array. FUN Must '*' (functions unsupported MLX tensors). make.dimnames logical: provide dimnames product    dimnames X Y. ... Passed maintain signature compatibility base kronecker().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/kronecker.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Kronecker product dispatcher — kronecker","text":"mlx array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/length.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Get length of MLX array — length.mlx","title":"Get length of MLX array — length.mlx","text":"Get length MLX array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/length.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get length of MLX array — length.mlx","text":"","code":"# S3 method for class 'mlx' length(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/length.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get length of MLX array — length.mlx","text":"x mlx array, R array/matrix/vector converted via as_mlx().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/length.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get length of MLX array — length.mlx","text":"Total number elements","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/length.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get length of MLX array — length.mlx","text":"","code":"x <- as_mlx(matrix(1:6, 2, 3)) length(x) #> [1] 6"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mean.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean of MLX array elements — mean.mlx","title":"Mean of MLX array elements — mean.mlx","text":"Mean MLX array elements","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mean.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean of MLX array elements — mean.mlx","text":"","code":"# S3 method for class 'mlx' mean(x, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mean.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean of MLX array elements — mean.mlx","text":"x mlx array. ... Additional arguments (ignored)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mean.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean of MLX array elements — mean.mlx","text":"mlx scalar","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mean.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mean of MLX array elements — mean.mlx","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) mean(x) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 2.5"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Base R generics with mlx methods — mlx-methods","title":"Base R generics with mlx methods — mlx-methods","text":"Rmlx provides S3 methods number base R generics common operations keep working converting objects as_mlx(). main entry points :","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx-methods.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Base R generics with mlx methods — mlx-methods","text":"%*% matrix multiplication [ [<- extraction assignment Ops Math elementwise arithmetic math Summary reductions sum() max(); also mean(), length() .equal(). diag(), dim() dim<- .matrix(), .array(), .vector() conversion back base R row() col() index helpers play nicely mlx arrays cbind() rbind() binding arrays along rows columns; also abind() function modelled abind::abind(). rowMeans(), colMeans(), rowSums(), colSums() axis-wise summaries aperm(), t(), dim<- shape manipulation kronecker(), outer(), crossprod(), tcrossprod() linear algebra helpers fft(), chol(), chol2inv(), backsolve(), solve() numerical routines scale() column-wise centring scaling stays MLX backend asplit() slice arrays along margin staying MLX backend .finite(), .infinite() .nan() methods return mlx objects. One exception () () return standard R TRUE FALSE used mlx objects.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_addmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Fused matrix multiply and add for MLX arrays — mlx_addmm","title":"Fused matrix multiply and add for MLX arrays — mlx_addmm","text":"Computes beta * input + alpha * (mat1 %*% mat2) single MLX kernel. operands promoted common dtype/device prior evaluation.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_addmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fused matrix multiply and add for MLX arrays — mlx_addmm","text":"","code":"mlx_addmm(input, mat1, mat2, alpha = 1, beta = 1)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_addmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fused matrix multiply and add for MLX arrays — mlx_addmm","text":"input Matrix-like object providing additive term. mat1 Left matrix operand. mat2 Right matrix operand. alpha, beta Numeric scalars controlling fused linear combination.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_addmm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fused matrix multiply and add for MLX arrays — mlx_addmm","text":"mlx matrix shape input.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_addmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fused matrix multiply and add for MLX arrays — mlx_addmm","text":"","code":"input <- as_mlx(diag(3)) mat1 <- as_mlx(matrix(rnorm(9), 3, 3)) mat2 <- as_mlx(matrix(rnorm(9), 3, 3)) mlx_addmm(input, mat1, mat2, alpha = 0.5, beta = 2) #> mlx array [3 x 3] #>   dtype: float32 #>   device: gpu #>   values: #>           [,1]      [,2]      [,3] #> [1,]  1.881381 0.2373658 0.2563887 #> [2,] -0.183827 2.4977331 0.4444461 #> [3,] -1.614122 0.7220473 1.6599751"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_allclose.html","id":null,"dir":"Reference","previous_headings":"","what":"Test if all elements of two arrays are close — mlx_allclose","title":"Test if all elements of two arrays are close — mlx_allclose","text":"Returns boolean scalar indicating whether elements two arrays close within specified tolerances.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_allclose.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test if all elements of two arrays are close — mlx_allclose","text":"","code":"mlx_allclose(   a,   b,   rtol = 1e-05,   atol = 1e-08,   equal_nan = FALSE,   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_allclose.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test if all elements of two arrays are close — mlx_allclose","text":", b MLX arrays objects coercible MLX arrays rtol Relative tolerance (default: 1e-5) atol Absolute tolerance (default: 1e-8) equal_nan TRUE, NaN values considered equal (default: FALSE) device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_allclose.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test if all elements of two arrays are close — mlx_allclose","text":"mlx array containing single boolean value","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_allclose.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Test if all elements of two arrays are close — mlx_allclose","text":"Two values considered close : abs(- b) <= (atol + rtol * abs(b)) function returns TRUE elements close. Supports NumPy-style broadcasting.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_allclose.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test if all elements of two arrays are close — mlx_allclose","text":"","code":"a <- as_mlx(c(1.0, 2.0, 3.0)) b <- as_mlx(c(1.0 + 1e-6, 2.0 + 1e-6, 3.0 + 1e-6)) as.logical(as.matrix(mlx_allclose(a, b)))  # TRUE #> [1] TRUE"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_arange.html","id":null,"dir":"Reference","previous_headings":"","what":"Numerical ranges on MLX devices — mlx_arange","title":"Numerical ranges on MLX devices — mlx_arange","text":"mlx_arange() mirrors base::seq() mlx arrays: creates evenly spaced values starting start (default 0), stepping step (default 1), stopping stop.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_arange.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Numerical ranges on MLX devices — mlx_arange","text":"","code":"mlx_arange(   stop,   start = NULL,   step = NULL,   dtype = c(\"float32\", \"float64\", \"int8\", \"int16\", \"int32\", \"int64\", \"uint8\", \"uint16\",     \"uint32\", \"uint64\"),   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_arange.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Numerical ranges on MLX devices — mlx_arange","text":"stop Exclusive upper bound. start Optional starting value (defaults 0). step Optional step size (defaults 1). dtype MLX dtype (\"float32\" \"float64\"). device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_arange.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Numerical ranges on MLX devices — mlx_arange","text":"1D mlx array.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_arange.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Numerical ranges on MLX devices — mlx_arange","text":"","code":"mlx_arange(5)                    # 0, 1, 2, 3, 4 #> mlx array [5] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 0 1 2 3 4 mlx_arange(5, start = 1, step = 2) # 1, 3 #> mlx array [2] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 1 3"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_argmax.html","id":null,"dir":"Reference","previous_headings":"","what":"Argmax and argmin on mlx arrays — mlx_argmax","title":"Argmax and argmin on mlx arrays — mlx_argmax","text":"Argmax argmin mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_argmax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Argmax and argmin on mlx arrays — mlx_argmax","text":"","code":"mlx_argmax(x, axis = NULL, drop = TRUE)  mlx_argmin(x, axis = NULL, drop = TRUE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_argmax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Argmax and argmin on mlx arrays — mlx_argmax","text":"x mlx array, R array/matrix/vector converted via as_mlx(). axis Single axis (1-indexed). Supply positive integer 1 array rank. Use NULL helper interprets \"axes\" (see individual docs). drop TRUE (default), drop dimensions length 1. FALSE, retain dimensions. Equivalent keepdims = TRUE underlying mlx functions.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_argmax.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Argmax and argmin on mlx arrays — mlx_argmax","text":"mlx array indices. Indices 1-based match R's conventions.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_argmax.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Argmax and argmin on mlx arrays — mlx_argmax","text":"axis = NULL, array flattened computing extrema. Setting drop = FALSE retains reduced axis length one returned indices.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_argmax.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Argmax and argmin on mlx arrays — mlx_argmax","text":"","code":"x <- as_mlx(matrix(c(1, 5, 3, 2), 2, 2)) mlx_argmax(x) #> mlx array [] #>   dtype: int64 #>   device: gpu #>   values: #> [1] 3 mlx_argmax(x, axis = 1) #> mlx array [2] #>   dtype: int64 #>   device: gpu #>   values: #> [1] 2 1 mlx_argmin(x) #> mlx array [] #>   dtype: int64 #>   device: gpu #>   values: #> [1] 1"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_array.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct an MLX array from R data — mlx_array","title":"Construct an MLX array from R data — mlx_array","text":"mlx_array() low-level constructor skips as_mlx()'s type inference dimension guessing. Supply raw payload vector plus explicit shape pipes data straight MLX.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_array.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct an MLX array from R data — mlx_array","text":"","code":"mlx_array(   data,   dim,   dtype = NULL,   device = mlx_default_device(),   allow_scalar = FALSE )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_array.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct an MLX array from R data — mlx_array","text":"data Numeric, logical, complex vector supplying payload. dimension attributes ignored; pass dim explicitly. dim Integer vector array dimensions (product must equal length(data)). dtype Optional MLX dtype. Defaults \"float32\" numeric input, \"bool\" logical, \"complex64\" complex. device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device(). allow_scalar Logical; set TRUE permit dim = integer(0) scalar payloads can represented. enabled, data must length 1 resulting array dimensionless.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_array.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct an MLX array from R data — mlx_array","text":"mlx array requested shape.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_array.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct an MLX array from R data — mlx_array","text":"","code":"payload <- runif(6) arr <- mlx_array(payload, dim = c(2, 3)) as.matrix(arr) #>           [,1]      [,2]       [,3] #> [1,] 0.7182697 0.5470434 0.02795603 #> [2,] 0.2413140 0.8348018 0.46938431"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_array_required.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters for Functions Requiring MLX Arrays — mlx_array_required","title":"Parameters for Functions Requiring MLX Arrays — mlx_array_required","text":"Parameters Functions Requiring MLX Arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_array_required.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters for Functions Requiring MLX Arrays — mlx_array_required","text":"x mlx array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_batch_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"Batch normalization — mlx_batch_norm","title":"Batch normalization — mlx_batch_norm","text":"Normalizes inputs across batch dimension.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_batch_norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Batch normalization — mlx_batch_norm","text":"","code":"mlx_batch_norm(   num_features,   eps = 1e-05,   momentum = 0.1,   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_batch_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Batch normalization — mlx_batch_norm","text":"num_features Number feature channels. eps Small constant numerical stability (default: 1e-5). momentum Momentum running statistics (default: 0.1). device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_batch_norm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Batch normalization — mlx_batch_norm","text":"mlx_module applying batch normalization.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_batch_norm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Batch normalization — mlx_batch_norm","text":"","code":"set.seed(1) bn <- mlx_batch_norm(4) x <- as_mlx(matrix(rnorm(12), 3, 4)) mlx_forward(bn, x) #> mlx array [3 x 4] #>   dtype: float32 #>   device: gpu #>   values: #>            [,1]        [,2]       [,3]       [,4] #> [1,] -0.4556868  1.24383128 -1.0877743 -1.1186367 #> [2,]  1.3872330 -0.03912285  1.3256620  1.3086261 #> [3,] -0.9315463 -1.20470834 -0.2378886 -0.1899893"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_binary_cross_entropy.html","id":null,"dir":"Reference","previous_headings":"","what":"Binary cross-entropy loss — mlx_binary_cross_entropy","title":"Binary cross-entropy loss — mlx_binary_cross_entropy","text":"Computes binary cross-entropy loss predictions binary targets.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_binary_cross_entropy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binary cross-entropy loss — mlx_binary_cross_entropy","text":"","code":"mlx_binary_cross_entropy(   predictions,   targets,   reduction = c(\"mean\", \"sum\", \"none\") )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_binary_cross_entropy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Binary cross-entropy loss — mlx_binary_cross_entropy","text":"predictions Predicted probabilities mlx array (values [0,1]). targets Binary target values mlx array (0 1). reduction Type reduction: \"mean\" (default), \"sum\", \"none\".","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_binary_cross_entropy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Binary cross-entropy loss — mlx_binary_cross_entropy","text":"mlx array containing loss.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_binary_cross_entropy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Binary cross-entropy loss — mlx_binary_cross_entropy","text":"","code":"preds <- as_mlx(matrix(c(0.9, 0.2, 0.8), 3, 1)) targets <- as_mlx(matrix(c(1, 0, 1), 3, 1)) mlx_binary_cross_entropy(preds, targets) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 0.1838825"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_broadcast_arrays.html","id":null,"dir":"Reference","previous_headings":"","what":"Broadcast multiple arrays to a shared shape — mlx_broadcast_arrays","title":"Broadcast multiple arrays to a shared shape — mlx_broadcast_arrays","text":"mlx_broadcast_arrays() mirrors mlx.core.broadcast_arrays(), returning list inputs expanded common shape.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_broadcast_arrays.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Broadcast multiple arrays to a shared shape — mlx_broadcast_arrays","text":"","code":"mlx_broadcast_arrays(..., device = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_broadcast_arrays.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Broadcast multiple arrays to a shared shape — mlx_broadcast_arrays","text":"... One arrays (single list) convertible via as_mlx(). device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_broadcast_arrays.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Broadcast multiple arrays to a shared shape — mlx_broadcast_arrays","text":"list broadcast mlx arrays.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_broadcast_arrays.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Broadcast multiple arrays to a shared shape — mlx_broadcast_arrays","text":"","code":"a <- as_mlx(matrix(1:3, nrow = 1)) b <- as_mlx(matrix(1:3, ncol = 1)) outs <- mlx_broadcast_arrays(a, b) lapply(outs, dim) #> [[1]] #> [1] 3 3 #>  #> [[2]] #> [1] 3 3 #>"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_broadcast_to.html","id":null,"dir":"Reference","previous_headings":"","what":"Broadcast an array to a new shape — mlx_broadcast_to","title":"Broadcast an array to a new shape — mlx_broadcast_to","text":"mlx_broadcast_to() mirrors mlx.core.broadcast_to(), repeating singleton dimensions without copying data.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_broadcast_to.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Broadcast an array to a new shape — mlx_broadcast_to","text":"","code":"mlx_broadcast_to(x, shape, device = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_broadcast_to.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Broadcast an array to a new shape — mlx_broadcast_to","text":"x mlx array. shape Integer vector describing broadcasted shape. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_broadcast_to.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Broadcast an array to a new shape — mlx_broadcast_to","text":"mlx array requested dimensions.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_broadcast_to.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Broadcast an array to a new shape — mlx_broadcast_to","text":"","code":"x <- as_mlx(matrix(1:3, nrow = 1)) broadcast <- mlx_broadcast_to(x, c(5, 3)) dim(broadcast) #> [1] 5 3"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cholesky_inv.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute matrix inverse via Cholesky decomposition — mlx_cholesky_inv","title":"Compute matrix inverse via Cholesky decomposition — mlx_cholesky_inv","text":"Computes inverse positive definite matrix Cholesky factor. Note: x Cholesky factor (L U), original matrix.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cholesky_inv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute matrix inverse via Cholesky decomposition — mlx_cholesky_inv","text":"","code":"mlx_cholesky_inv(x, upper = FALSE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cholesky_inv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute matrix inverse via Cholesky decomposition — mlx_cholesky_inv","text":"x mlx array. upper Logical; TRUE, x upper triangular, otherwise lower triangular.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cholesky_inv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute matrix inverse via Cholesky decomposition — mlx_cholesky_inv","text":"inverse original matrix (^-1 = LL' = U'U).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cholesky_inv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute matrix inverse via Cholesky decomposition — mlx_cholesky_inv","text":"R-like interface, see chol2inv().","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cholesky_inv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute matrix inverse via Cholesky decomposition — mlx_cholesky_inv","text":"","code":"# Create a positive definite matrix A <- matrix(rnorm(9), 3, 3) A <- t(A) %*% A # Compute Cholesky factor L <- chol(A, pivot = FALSE, upper = FALSE) # Get inverse from Cholesky factor A_inv <- mlx_cholesky_inv(as_mlx(L))"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_clip.html","id":null,"dir":"Reference","previous_headings":"","what":"Clip mlx array values into a range — mlx_clip","title":"Clip mlx array values into a range — mlx_clip","text":"Clip mlx array values range","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_clip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clip mlx array values into a range — mlx_clip","text":"","code":"mlx_clip(x, min = NULL, max = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_clip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clip mlx array values into a range — mlx_clip","text":"x mlx array, R array/matrix/vector converted via as_mlx(). min, max Scalar bounds. Use NULL leave bound open.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_clip.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clip mlx array values into a range — mlx_clip","text":"mlx array values clipped [min, max].","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_clip.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Clip mlx array values into a range — mlx_clip","text":"","code":"x <- as_mlx(rnorm(4)) mlx_clip(x, min = -1, max = 1) #> mlx array [4] #>   dtype: float32 #>   device: gpu #>   values: #> [1] -0.1557955 -1.0000000 -0.4781501  0.4179416"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_compile.html","id":null,"dir":"Reference","previous_headings":"","what":"Compile an MLX Function for Optimized Execution — mlx_compile","title":"Compile an MLX Function for Optimized Execution — mlx_compile","text":"Returns compiled version function traces optimizes computation graph first call, reuses compiled graph subsequent calls matching input shapes types.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_compile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compile an MLX Function for Optimized Execution — mlx_compile","text":"","code":"mlx_compile(f, shapeless = FALSE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_compile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compile an MLX Function for Optimized Execution — mlx_compile","text":"f R function takes MLX arrays arguments returns MLX array(s). function must pure (side effects) use MLX operations. shapeless Logical. TRUE, compiled function recompile input shapes change. However, changing input dtypes number dimensions still triggers recompilation. Default: FALSE","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_compile.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compile an MLX Function for Optimized Execution — mlx_compile","text":"compiled function signature f. first call slow (tracing compilation), subsequent calls much faster.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_compile.html","id":"how-compilation-works","dir":"Reference","previous_headings":"","what":"How Compilation Works","title":"Compile an MLX Function for Optimized Execution — mlx_compile","text":"call mlx_compile(f), returns new function immediately without tracing. actual compilation happens first call compiled function: First call: MLX traces function placeholder inputs, builds computation graph, optimizes (fusing operations, eliminating redundancy), caches result. slow. Subsequent calls: inputs shapes dtypes, MLX reuses cached compiled graph. fast. Recompilation: Occurs input shapes change (unless shapeless = TRUE), input dtypes change, number arguments changes.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_compile.html","id":"requirements-for-compiled-functions","dir":"Reference","previous_headings":"","what":"Requirements for Compiled Functions","title":"Compile an MLX Function for Optimized Execution — mlx_compile","text":"function must: Accept MLX arrays arguments Return MLX array(s) - either single mlx object list mlx objects Use MLX operations (conversion R) pure (side effects, external state modification) function : Print evaluate arrays execution (print(), .matrix(), .numeric(), [[ extraction, etc.) Use control flow based array values ((x > 0) x array) Modify external variables side effects Return non-MLX values","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_compile.html","id":"performance-benefits","dir":"Reference","previous_headings":"","what":"Performance Benefits","title":"Compile an MLX Function for Optimized Execution — mlx_compile","text":"Operation fusion: Combines multiple operations optimized kernels Memory reduction: Eliminates intermediate allocations Overhead reduction: Bypasses R/C++ call overhead fused operations Typical speedups range 2-10x operation-heavy functions.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_compile.html","id":"shapeless-compilation","dir":"Reference","previous_headings":"","what":"Shapeless Compilation","title":"Compile an MLX Function for Optimized Execution — mlx_compile","text":"Setting shapeless = TRUE allows compiled function handle varying input shapes without recompilation:   Shapeless mode sacrifices optimization opportunities avoids recompilation costs. Use processing variable-sized batches.","code":"# Regular compilation - recompiles for each new shape fast_fn <- mlx_compile(matmul_fn) fast_fn(mlx_zeros(c(10, 64)), weights)  # Compiles for shape (10, 64) fast_fn(mlx_zeros(c(20, 64)), weights)  # Recompiles for shape (20, 64)  # Shapeless compilation - compiles once fast_fn <- mlx_compile(matmul_fn, shapeless = TRUE) fast_fn(mlx_zeros(c(10, 64)), weights)  # Compiles once fast_fn(mlx_zeros(c(20, 64)), weights)  # No recompilation!"},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_compile.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compile an MLX Function for Optimized Execution — mlx_compile","text":"","code":"# Simple example matmul_add <- function(x, w, b) {   (x %*% w) + b }  # Compile it (returns immediately, no tracing yet) fast_fn <- mlx_compile(matmul_add)  # First call: slow (traces and compiles) x <- mlx_rand_normal(c(32, 128)) w <- mlx_rand_normal(c(128, 256)) b <- mlx_rand_normal(c(256)) result <- fast_fn(x, w, b)  # Compiles during this call  # Subsequent calls: fast (uses cached graph) batches <- replicate(10, mlx_rand_normal(c(32, 128)), simplify = FALSE) for (bat in batches) {   result <- fast_fn(bat, w, b)  # Uses cached graph }  # Multiple returns forward_and_norm <- function(x, w) {   y <- x %*% w   norm <- sqrt(sum(y * y))   list(y, norm)  # Return list of mlx objects }  compiled_fn <- mlx_compile(forward_and_norm) results <- compiled_fn(x, w)  # Returns list(y, norm)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_compile_control.html","id":null,"dir":"Reference","previous_headings":"","what":"Control Global Compilation Behavior — mlx_disable_compile","title":"Control Global Compilation Behavior — mlx_disable_compile","text":"mlx_disable_compile() prevents compilation globally. Compiled functions execute without optimization. mlx_enable_compile() enables compilation (overrides MLX_DISABLE_COMPILE environment variable).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_compile_control.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Control Global Compilation Behavior — mlx_disable_compile","text":"","code":"mlx_disable_compile()  mlx_enable_compile()"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_compile_control.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Control Global Compilation Behavior — mlx_disable_compile","text":"Invisibly returns NULL.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_compile_control.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Control Global Compilation Behavior — mlx_disable_compile","text":"functions control whether MLX compilation enabled globally. useful debugging (check compilation causing issues) benchmarking (measure compilation overhead vs speedup). can also disable compilation setting MLX_DISABLE_COMPILE environment variable loading package.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_compile_control.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Control Global Compilation Behavior — mlx_disable_compile","text":"","code":"demo_fn <- mlx_compile(function(x) x + 1) x <- mlx_rand_normal(c(4, 4))  # Disable compilation for debugging mlx_disable_compile() demo_fn(x)  # Runs without optimization #> mlx array [4 x 4] #>   dtype: float32 #>   device: gpu #>   values: #>            [,1]       [,2]      [,3]       [,4] #> [1,]  0.6885960 -0.2165980 0.2565813 2.12118530 #> [2,]  1.7389933  2.8602319 2.6256876 0.04484504 #> [3,] -0.3415704  0.6531709 1.4265676 2.15548325 #> [4,]  1.7810299  0.9662346 0.8734691 0.88092554  # Re-enable compilation mlx_enable_compile() demo_fn(x)  # Runs with optimization #> mlx array [4 x 4] #>   dtype: float32 #>   device: gpu #>   values: #>            [,1]       [,2]      [,3]       [,4] #> [1,]  0.6885960 -0.2165980 0.2565813 2.12118530 #> [2,]  1.7389933  2.8602319 2.6256876 0.04484504 #> [3,] -0.3415704  0.6531709 1.4265676 2.15548325 #> [4,]  1.7810299  0.9662346 0.8734691 0.88092554"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_contiguous.html","id":null,"dir":"Reference","previous_headings":"","what":"Ensure contiguous memory layout — mlx_contiguous","title":"Ensure contiguous memory layout — mlx_contiguous","text":"Returns copy x contiguous strides requested device stream.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_contiguous.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ensure contiguous memory layout — mlx_contiguous","text":"","code":"mlx_contiguous(x, device = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_contiguous.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ensure contiguous memory layout — mlx_contiguous","text":"x mlx array. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_contiguous.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ensure contiguous memory layout — mlx_contiguous","text":"mlx array backed contiguous storage specified device.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_contiguous.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ensure contiguous memory layout — mlx_contiguous","text":"","code":"x <- mlx_swapaxes(as_mlx(matrix(1:4, 2, 2)), axis1 = 1, axis2 = 2) y <- mlx_contiguous(x) identical(as.array(x), as.array(y)) #> [1] TRUE"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv1d.html","id":null,"dir":"Reference","previous_headings":"","what":"1D Convolution — mlx_conv1d","title":"1D Convolution — mlx_conv1d","text":"Applies 1D convolution input signal.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"1D Convolution — mlx_conv1d","text":"","code":"mlx_conv1d(   input,   weight,   stride = 1L,   padding = 0L,   dilation = 1L,   groups = 1L,   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"1D Convolution — mlx_conv1d","text":"input Input mlx array. Shape depends dimensionality (see individual functions). weight Weight array. Shape depends dimensionality (see individual functions). stride Stride convolution. Can scalar vector (length depends dimensionality). Default: 1 1D, c(1,1) 2D, c(1,1,1) 3D. padding Amount zero padding. Can scalar vector (length depends dimensionality). Default: 0 1D, c(0,0) 2D, c(0,0,0) 3D. dilation Spacing kernel elements. Can scalar vector (length depends dimensionality). Default: 1 1D, c(1,1) 2D, c(1,1,1) 3D. groups Number blocked connections input output channels. Default: 1. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv1d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"1D Convolution — mlx_conv1d","text":"Convolved output array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv1d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"1D Convolution — mlx_conv1d","text":"Input shape (N, L, C_in) N batch size, L sequence length, C_in number input channels. Weight shape (C_out, kernel_size, C_in).","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv2d.html","id":null,"dir":"Reference","previous_headings":"","what":"2D Convolution — mlx_conv2d","title":"2D Convolution — mlx_conv2d","text":"Applies 2D convolution input image.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"2D Convolution — mlx_conv2d","text":"","code":"mlx_conv2d(   input,   weight,   stride = c(1L, 1L),   padding = c(0L, 0L),   dilation = c(1L, 1L),   groups = 1L,   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"2D Convolution — mlx_conv2d","text":"input Input mlx array. Shape depends dimensionality (see individual functions). weight Weight array. Shape depends dimensionality (see individual functions). stride Stride convolution. Can scalar vector (length depends dimensionality). Default: 1 1D, c(1,1) 2D, c(1,1,1) 3D. padding Amount zero padding. Can scalar vector (length depends dimensionality). Default: 0 1D, c(0,0) 2D, c(0,0,0) 3D. dilation Spacing kernel elements. Can scalar vector (length depends dimensionality). Default: 1 1D, c(1,1) 2D, c(1,1,1) 3D. groups Number blocked connections input output channels. Default: 1. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv2d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"2D Convolution — mlx_conv2d","text":"Convolved output array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv2d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"2D Convolution — mlx_conv2d","text":"Input shape (N, H, W, C_in) N batch size, H W height width, C_in number input channels. Weight shape (C_out, kernel_h, kernel_w, C_in).","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv2d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"2D Convolution — mlx_conv2d","text":"","code":"# Create a simple 2D convolution input <- as_mlx(array(rnorm(1*28*28*3), dim = c(1, 28, 28, 3)))  # Batch of 1 RGB image weight <- as_mlx(array(rnorm(16*3*3*3), dim = c(16, 3, 3, 3)))  # 16 filters, 3x3 kernel output <- mlx_conv2d(input, weight, stride = c(1, 1), padding = c(1, 1))"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv3d.html","id":null,"dir":"Reference","previous_headings":"","what":"3D Convolution — mlx_conv3d","title":"3D Convolution — mlx_conv3d","text":"Applies 3D convolution input volume.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"3D Convolution — mlx_conv3d","text":"","code":"mlx_conv3d(   input,   weight,   stride = c(1L, 1L, 1L),   padding = c(0L, 0L, 0L),   dilation = c(1L, 1L, 1L),   groups = 1L,   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"3D Convolution — mlx_conv3d","text":"input Input mlx array. Shape depends dimensionality (see individual functions). weight Weight array. Shape depends dimensionality (see individual functions). stride Stride convolution. Can scalar vector (length depends dimensionality). Default: 1 1D, c(1,1) 2D, c(1,1,1) 3D. padding Amount zero padding. Can scalar vector (length depends dimensionality). Default: 0 1D, c(0,0) 2D, c(0,0,0) 3D. dilation Spacing kernel elements. Can scalar vector (length depends dimensionality). Default: 1 1D, c(1,1) 2D, c(1,1,1) 3D. groups Number blocked connections input output channels. Default: 1. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv3d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"3D Convolution — mlx_conv3d","text":"Convolved output array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv3d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"3D Convolution — mlx_conv3d","text":"Input shape (N, D, H, W, C_in) N batch size, D, H, W depth, height width, C_in number input channels. Weight shape (C_out, kernel_d, kernel_h, kernel_w, C_in).","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose1d.html","id":null,"dir":"Reference","previous_headings":"","what":"1D Transposed Convolution — mlx_conv_transpose1d","title":"1D Transposed Convolution — mlx_conv_transpose1d","text":"Applies 1D transposed convolution (also called deconvolution) input signal. Transposed convolutions used upsample spatial dimensions input.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"1D Transposed Convolution — mlx_conv_transpose1d","text":"","code":"mlx_conv_transpose1d(   input,   weight,   stride = 1L,   padding = 0L,   dilation = 1L,   output_padding = 0L,   groups = 1L,   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"1D Transposed Convolution — mlx_conv_transpose1d","text":"input Input mlx array. Shape depends dimensionality (see individual functions). weight Weight array. Shape depends dimensionality (see individual functions). stride Stride convolution. Can scalar vector (length depends dimensionality). Default: 1 1D, c(1,1) 2D, c(1,1,1) 3D. padding Amount zero padding. Can scalar vector (length depends dimensionality). Default: 0 1D, c(0,0) 2D, c(0,0,0) 3D. dilation Spacing kernel elements. Can scalar vector (length depends dimensionality). Default: 1 1D, c(1,1) 2D, c(1,1,1) 3D. output_padding Additional size added output shape. Default: 0 groups Number blocked connections input output channels. Default: 1. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose1d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"1D Transposed Convolution — mlx_conv_transpose1d","text":"mlx array transposed convolution result","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose1d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"1D Transposed Convolution — mlx_conv_transpose1d","text":"Input shape (batch, length, in_channels) 'NWC' layout. Weight shape (out_channels, kernel_size, in_channels).","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose2d.html","id":null,"dir":"Reference","previous_headings":"","what":"2D Transposed Convolution — mlx_conv_transpose2d","title":"2D Transposed Convolution — mlx_conv_transpose2d","text":"Applies 2D transposed convolution (also called deconvolution) input signal. Transposed convolutions commonly used image generation upsampling tasks.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"2D Transposed Convolution — mlx_conv_transpose2d","text":"","code":"mlx_conv_transpose2d(   input,   weight,   stride = c(1L, 1L),   padding = c(0L, 0L),   dilation = c(1L, 1L),   output_padding = c(0L, 0L),   groups = 1L,   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"2D Transposed Convolution — mlx_conv_transpose2d","text":"input Input mlx array. Shape depends dimensionality (see individual functions). weight Weight array. Shape depends dimensionality (see individual functions). stride Stride convolution. Can scalar vector (length depends dimensionality). Default: 1 1D, c(1,1) 2D, c(1,1,1) 3D. padding Amount zero padding. Can scalar vector (length depends dimensionality). Default: 0 1D, c(0,0) 2D, c(0,0,0) 3D. dilation Spacing kernel elements. Can scalar vector (length depends dimensionality). Default: 1 1D, c(1,1) 2D, c(1,1,1) 3D. output_padding Additional size added output shape. Can scalar length-2 vector. Default: c(0, 0) groups Number blocked connections input output channels. Default: 1. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose2d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"2D Transposed Convolution — mlx_conv_transpose2d","text":"mlx array transposed convolution result","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose2d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"2D Transposed Convolution — mlx_conv_transpose2d","text":"Input shape (batch, height, width, in_channels) 'NHWC' layout. Weight shape (out_channels, kernel_h, kernel_w, in_channels).","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose3d.html","id":null,"dir":"Reference","previous_headings":"","what":"3D Transposed Convolution — mlx_conv_transpose3d","title":"3D Transposed Convolution — mlx_conv_transpose3d","text":"Applies 3D transposed convolution (also called deconvolution) input signal. Useful 3D volumetric data upsampling, medical imaging video generation.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"3D Transposed Convolution — mlx_conv_transpose3d","text":"","code":"mlx_conv_transpose3d(   input,   weight,   stride = c(1L, 1L, 1L),   padding = c(0L, 0L, 0L),   dilation = c(1L, 1L, 1L),   output_padding = c(0L, 0L, 0L),   groups = 1L,   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"3D Transposed Convolution — mlx_conv_transpose3d","text":"input Input mlx array. Shape depends dimensionality (see individual functions). weight Weight array. Shape depends dimensionality (see individual functions). stride Stride convolution. Can scalar vector (length depends dimensionality). Default: 1 1D, c(1,1) 2D, c(1,1,1) 3D. padding Amount zero padding. Can scalar vector (length depends dimensionality). Default: 0 1D, c(0,0) 2D, c(0,0,0) 3D. dilation Spacing kernel elements. Can scalar vector (length depends dimensionality). Default: 1 1D, c(1,1) 2D, c(1,1,1) 3D. output_padding Additional size added output shape. Can scalar length-3 vector. Default: c(0, 0, 0) groups Number blocked connections input output channels. Default: 1. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose3d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"3D Transposed Convolution — mlx_conv_transpose3d","text":"mlx array transposed convolution result","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_conv_transpose3d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"3D Transposed Convolution — mlx_conv_transpose3d","text":"Input shape (batch, depth, height, width, in_channels) 'NDHWC' layout. Weight shape (out_channels, kernel_d, kernel_h, kernel_w, in_channels).","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_coordinate_descent.html","id":null,"dir":"Reference","previous_headings":"","what":"Coordinate Descent with L1 Regularization — mlx_coordinate_descent","title":"Coordinate Descent with L1 Regularization — mlx_coordinate_descent","text":"Minimizes f(beta) + lambda * ||beta||_1 using coordinate descent, f smooth differentiable loss function.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_coordinate_descent.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coordinate Descent with L1 Regularization — mlx_coordinate_descent","text":"","code":"mlx_coordinate_descent(   loss_fn,   beta_init,   lambda = 0,   ridge_penalty = 0,   grad_fn = NULL,   lipschitz = NULL,   max_iter = 1000,   tol = 1e-06,   block_size = 1,   grad_cache = NULL )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_coordinate_descent.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coordinate Descent with L1 Regularization — mlx_coordinate_descent","text":"loss_fn Function(beta) -> scalar loss (MLX tensor). Must smooth differentiable. beta_init Initial parameter vector (p x 1 MLX tensor). lambda L1 penalty parameter (scalar, default 0). ridge_penalty Optional ridge (L2) penalty term applied per-coordinate computing gradients. Can scalar, numeric vector length p, mlx array shape compatible beta_init. grad_fn Optional gradient function. NULL, computed via mlx_grad(loss_fn). lipschitz Optional Lipschitz constants coordinate (length p vector). NULL, uses simple constant estimates. max_iter Maximum number iterations (default 1000). tol Convergence tolerance (default 1e-6). block_size Number coordinates update recomputing gradient. Set 1 strict coordinate descent; larger values trade accuracy speed. grad_cache Optional environment supplying cached gradient components. Supported fields type = \"gaussian\" entries x, residual, n_obs, optional ridge_penalty; type = \"binomial\" entries x, eta, mu, residual, y, n_obs, optional ridge_penalty.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_coordinate_descent.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coordinate Descent with L1 Regularization — mlx_coordinate_descent","text":"List : beta: Optimized parameter vector (MLX tensor) n_iter: Number iterations performed converged: Whether convergence criterion met","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_coordinate_descent.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Coordinate Descent with L1 Regularization — mlx_coordinate_descent","text":"function implements proximal gradient descent problems form: min_beta f(beta) + lambda * ||beta||_1 f smooth. iteration, coordinates updated via: z = beta - (1/L) * grad_f(beta) beta = soft_threshold(z, lambda/L) L Lipschitz constants coordinate.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_coordinate_descent.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coordinate Descent with L1 Regularization — mlx_coordinate_descent","text":"","code":"# Lasso regression: min 0.5*||y - X*beta||^2 + lambda*||beta||_1 n <- 100 p <- 50 X <- as_mlx(matrix(rnorm(n*p), n, p)) y <- as_mlx(matrix(rnorm(n), ncol=1)) beta_init <- mlx_zeros(c(p, 1))  loss_fn <- function(beta) {   residual <- y - X %*% beta   sum(residual^2) / (2*n) }  result <- mlx_coordinate_descent(   loss_fn = loss_fn,   beta_init = beta_init,   lambda = 0.1,   block_size = 8 )  # Reuse cached residuals for a Gaussian problem grad_cache <- new.env(parent = emptyenv()) grad_cache$type <- \"gaussian\" grad_cache$x <- X grad_cache$n_obs <- n grad_cache$residual <- y - X %*% beta_init cached <- mlx_coordinate_descent(   loss_fn = loss_fn,   beta_init = beta_init,   lambda = 0.1,   grad_cache = grad_cache )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_creation_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Common parameters for MLX array creation — mlx_creation_params","title":"Common parameters for MLX array creation — mlx_creation_params","text":"Common parameters MLX array creation","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_creation_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Common parameters for MLX array creation — mlx_creation_params","text":"dim Integer vector specifying array shape/dimensions. dtype Character string specifying MLX data type. Common options: Floating point: \"float32\", \"float64\" Integer: \"int8\", \"int16\", \"int32\", \"int64\", \"uint8\", \"uint16\", \"uint32\", \"uint64\" : \"bool\", \"complex64\" Supported types vary function; see individual function documentation. device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cross.html","id":null,"dir":"Reference","previous_headings":"","what":"Vector cross product with mlx arrays — mlx_cross","title":"Vector cross product with mlx arrays — mlx_cross","text":"Vector cross product mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cross.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Vector cross product with mlx arrays — mlx_cross","text":"","code":"mlx_cross(a, b, axis = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cross.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Vector cross product with mlx arrays — mlx_cross","text":", b Input mlx arrays containing 3D vectors. axis Axis along compute cross product (1-indexed). Omit argument use trailing dimension.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cross.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Vector cross product with mlx arrays — mlx_cross","text":"mlx array cross products.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cross.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Vector cross product with mlx arrays — mlx_cross","text":"","code":"u <- as_mlx(c(1, 0, 0)) v <- as_mlx(c(0, 1, 0)) mlx_cross(u, v) #> mlx array [3] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 0 0 1"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cross_entropy.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-entropy loss — mlx_cross_entropy","title":"Cross-entropy loss — mlx_cross_entropy","text":"Computes cross-entropy loss multi-class classification.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cross_entropy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-entropy loss — mlx_cross_entropy","text":"","code":"mlx_cross_entropy(logits, targets, reduction = c(\"mean\", \"sum\", \"none\"))"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cross_entropy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-entropy loss — mlx_cross_entropy","text":"logits Unnormalized predictions (logits) mlx array. targets Target class indices mlx array integer vector. reduction Type reduction: \"mean\" (default), \"sum\", \"none\".","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cross_entropy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-entropy loss — mlx_cross_entropy","text":"mlx array containing loss.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cross_entropy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-entropy loss — mlx_cross_entropy","text":"","code":"# Logits for 3 samples, 4 classes logits <- as_mlx(matrix(rnorm(12), 3, 4)) targets <- as_mlx(c(1, 3, 2)) mlx_cross_entropy(logits, targets) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 1.331489"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cumsum.html","id":null,"dir":"Reference","previous_headings":"","what":"Cumulative sum and product — mlx_cumsum","title":"Cumulative sum and product — mlx_cumsum","text":"Compute cumulative sums products along axis.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cumsum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cumulative sum and product — mlx_cumsum","text":"","code":"mlx_cumsum(x, axis = NULL, reverse = FALSE, inclusive = TRUE)  mlx_cumprod(x, axis = NULL, reverse = FALSE, inclusive = TRUE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cumsum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cumulative sum and product — mlx_cumsum","text":"x mlx array, R array/matrix/vector converted via as_mlx(). axis Single axis (1-indexed). Supply positive integer 1 array rank. Use NULL helper interprets \"axes\" (see individual docs). reverse TRUE, compute reverse order. inclusive TRUE (default), include current element cumulative operation. FALSE, cumulative operation exclusive (starts identity element).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cumsum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cumulative sum and product — mlx_cumsum","text":"mlx array cumulative sums products.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cumsum.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cumulative sum and product — mlx_cumsum","text":"axis NULL (default), array flattened computing cumulative result.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_cumsum.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cumulative sum and product — mlx_cumsum","text":"","code":"x <- as_mlx(1:5) mlx_cumsum(x)  # [1, 3, 6, 10, 15] #> mlx array [5] #>   dtype: float32 #>   device: gpu #>   values: #> [1]  1  3  6 10 15  mat <- as_mlx(matrix(1:12, 3, 4)) mlx_cumsum(mat, axis = 1)  # cumsum down rows #> mlx array [3 x 4] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] [,4] #> [1,]    1    4    7   10 #> [2,]    3    9   15   21 #> [3,]    6   15   24   33"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_default_device.html","id":null,"dir":"Reference","previous_headings":"","what":"Get or set default MLX device — mlx_default_device","title":"Get or set default MLX device — mlx_default_device","text":"Get set default MLX device","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_default_device.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get or set default MLX device — mlx_default_device","text":"","code":"mlx_default_device(value)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_default_device.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get or set default MLX device — mlx_default_device","text":"value New default device (\"gpu\" \"cpu\"). missing, returns current default.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_default_device.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get or set default MLX device — mlx_default_device","text":"Current default device (character)","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_default_device.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get or set default MLX device — mlx_default_device","text":"","code":"mlx_default_device()  # Get current default #> [1] \"gpu\" mlx_default_device(\"cpu\")  # Set to CPU #> [1] \"cpu\" mlx_default_device(\"gpu\")  # Set back to GPU #> [1] \"gpu\" mlx_default_device() #> [1] \"gpu\""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_degrees.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert between radians and degrees — mlx_degrees","title":"Convert between radians and degrees — mlx_degrees","text":"mlx_degrees() mlx_radians() mirror mlx.core.degrees() mlx.core.radians(), converting angular values elementwise using MLX kernels.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_degrees.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert between radians and degrees — mlx_degrees","text":"","code":"mlx_degrees(x)  mlx_radians(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_degrees.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert between radians and degrees — mlx_degrees","text":"x mlx array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_degrees.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert between radians and degrees — mlx_degrees","text":"mlx array transformed angular units.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_degrees.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert between radians and degrees — mlx_degrees","text":"","code":"x <- as_mlx(pi / 2) as.matrix(mlx_degrees(x))  # 90 #> [1] 90 angles <- mlx_radians(as_mlx(c(0, 90, 180))) as.matrix(angles) #> [1] 0.000000 1.570796 3.141593"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dequantize.html","id":null,"dir":"Reference","previous_headings":"","what":"Dequantize a Matrix — mlx_dequantize","title":"Dequantize a Matrix — mlx_dequantize","text":"Reconstructs approximate floating-point matrix quantized representation produced mlx_quantize().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dequantize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dequantize a Matrix — mlx_dequantize","text":"","code":"mlx_dequantize(   w,   scales,   biases = NULL,   group_size = 64L,   bits = 4L,   mode = \"affine\",   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dequantize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dequantize a Matrix — mlx_dequantize","text":"w mlx array (quantized weight matrix) scales mlx array (quantization scales) biases optional mlx array (quantization biases affine mode). Default: NULL group_size group size used quantization. Default: 64 bits number bits used quantization. Default: 4 mode quantization mode used: \"affine\" \"mxfp4\". Default: \"affine\" device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dequantize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Dequantize a Matrix — mlx_dequantize","text":"mlx array dequantized (approximate) floating-point weights","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dequantize.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Dequantize a Matrix — mlx_dequantize","text":"Dequantization unpacks low-precision quantized weights applies scales (biases) reconstruct approximate floating-point values. Note precision lost quantization recovered.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dequantize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dequantize a Matrix — mlx_dequantize","text":"","code":"w <- mlx_rand_normal(c(64, 32)) quant <- mlx_quantize(w, group_size = 32) w_reconstructed <- mlx_dequantize(quant$w_q, quant$scales, quant$biases, group_size = 32)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dexp.html","id":null,"dir":"Reference","previous_headings":"","what":"Exponential distribution functions — mlx_dexp","title":"Exponential distribution functions — mlx_dexp","text":"Compute density (mlx_dexp), cumulative distribution (mlx_pexp), quantile (mlx_qexp) functions exponential distribution using MLX.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dexp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Exponential distribution functions — mlx_dexp","text":"","code":"mlx_dexp(x, rate = 1, log = FALSE, device = mlx_default_device())  mlx_pexp(x, rate = 1, device = mlx_default_device())  mlx_qexp(p, rate = 1, device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dexp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Exponential distribution functions — mlx_dexp","text":"x Vector quantiles (mlx array coercible mlx) rate Rate parameter (default: 1) log TRUE, return log density mlx_dexp (default: FALSE) device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream). p Vector probabilities (mlx array coercible mlx)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dexp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Exponential distribution functions — mlx_dexp","text":"mlx array computed values","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dexp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Exponential distribution functions — mlx_dexp","text":"","code":"x <- as_mlx(seq(0, 5, by = 0.5)) as.matrix(mlx_dexp(x)) #>  [1] 1.000000000 0.606530666 0.367879450 0.223130152 0.135335281 0.082084998 #>  [7] 0.049787071 0.030197384 0.018315639 0.011108996 0.006737947 as.matrix(mlx_pexp(x)) #>  [1] 0.0000000 0.3934693 0.6321205 0.7768698 0.8646647 0.9179150 0.9502130 #>  [8] 0.9698026 0.9816844 0.9888910 0.9932621  p <- as_mlx(c(0.25, 0.5, 0.75)) as.matrix(mlx_qexp(p)) #> [1] 0.2876821 0.6931472 1.3862944"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_diagonal.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract diagonal or construct diagonal matrix for mlx arrays — diag.mlx","title":"Extract diagonal or construct diagonal matrix for mlx arrays — diag.mlx","text":"Extract diagonal matrix construct diagonal matrix vector.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_diagonal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract diagonal or construct diagonal matrix for mlx arrays — diag.mlx","text":"","code":"# S3 method for class 'mlx' diag(x, nrow, ncol, names = TRUE)  mlx_diagonal(x, offset = 0L, axis1 = 1L, axis2 = 2L)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_diagonal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract diagonal or construct diagonal matrix for mlx arrays — diag.mlx","text":"x mlx array. 1D, creates diagonal matrix. 2D higher, extracts diagonal. nrow, ncol Diagonal offset (nrow ; ncol ignored). diag.mlx() R interface mlx_diagonal() semantics base::diag(). names Unused. offset Diagonal offset (0 main diagonal, positive , negative ). axis1, axis2 multi-dimensional arrays, axes define 2D planes (1-indexed).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_diagonal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract diagonal or construct diagonal matrix for mlx arrays — diag.mlx","text":"mlx array.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_diagonal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract diagonal or construct diagonal matrix for mlx arrays — diag.mlx","text":"","code":"# Extract diagonal x <- as_mlx(matrix(1:9, 3, 3)) mlx_diagonal(x) #> mlx array [3] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 1 5 9 # (Constructing diagonals from 1D inputs is not yet supported.)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dim.html","id":null,"dir":"Reference","previous_headings":"","what":"Get dimensions helper — mlx_dim","title":"Get dimensions helper — mlx_dim","text":"Get dimensions helper","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get dimensions helper — mlx_dim","text":"","code":"mlx_dim(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get dimensions helper — mlx_dim","text":"x mlx array, R array/matrix/vector converted via as_mlx().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get dimensions helper — mlx_dim","text":"Dimensions","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get dimensions helper — mlx_dim","text":"","code":"x <- as_mlx(matrix(1:6, 2, 3)) mlx_dim(x) #> [1] 2 3"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dlnorm.html","id":null,"dir":"Reference","previous_headings":"","what":"Lognormal distribution functions — mlx_dlnorm","title":"Lognormal distribution functions — mlx_dlnorm","text":"Compute density (mlx_dlnorm), cumulative distribution (mlx_plnorm), quantile (mlx_qlnorm) functions lognormal distribution using MLX.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dlnorm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lognormal distribution functions — mlx_dlnorm","text":"","code":"mlx_dlnorm(   x,   meanlog = 0,   sdlog = 1,   log = FALSE,   device = mlx_default_device() )  mlx_plnorm(x, meanlog = 0, sdlog = 1, device = mlx_default_device())  mlx_qlnorm(p, meanlog = 0, sdlog = 1, device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dlnorm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lognormal distribution functions — mlx_dlnorm","text":"x Vector quantiles (mlx array coercible mlx) meanlog, sdlog Mean standard deviation distribution log scale (default: 0, 1) log TRUE, return log density mlx_dlnorm (default: FALSE) device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream). p Vector probabilities (mlx array coercible mlx)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dlnorm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Lognormal distribution functions — mlx_dlnorm","text":"mlx array computed values","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dlnorm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Lognormal distribution functions — mlx_dlnorm","text":"","code":"x <- as_mlx(seq(0.1, 3, by = 0.2)) as.matrix(mlx_dlnorm(x)) #>  [1] 0.28159016 0.64420331 0.62749606 0.53479487 0.44081569 0.36103126 #>  [7] 0.29649639 0.24497366 0.20385425 0.17088225 0.14426388 0.12261371 #> [13] 0.10487107 0.09022354 0.07804624 as.matrix(mlx_plnorm(x)) #>  [1] 0.01065108 0.11430004 0.24410859 0.36066759 0.45804486 0.53796577 #>  [7] 0.60347968 0.65743220 0.70216179 0.73951596 0.77093732 0.79755199 #> [13] 0.82024282 0.83970642 0.85649657  p <- as_mlx(c(0.25, 0.5, 0.75)) as.matrix(mlx_qlnorm(p)) #> [1] 0.5094163 1.0000000 1.9630311"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dlogis.html","id":null,"dir":"Reference","previous_headings":"","what":"Logistic distribution functions — mlx_dlogis","title":"Logistic distribution functions — mlx_dlogis","text":"Compute density (mlx_dlogis), cumulative distribution (mlx_plogis), quantile (mlx_qlogis) functions logistic distribution using MLX.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dlogis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logistic distribution functions — mlx_dlogis","text":"","code":"mlx_dlogis(   x,   location = 0,   scale = 1,   log = FALSE,   device = mlx_default_device() )  mlx_plogis(x, location = 0, scale = 1, device = mlx_default_device())  mlx_qlogis(p, location = 0, scale = 1, device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dlogis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logistic distribution functions — mlx_dlogis","text":"x Vector quantiles (mlx array coercible mlx) location, scale Location scale parameters (default: 0, 1) log TRUE, return log density mlx_dlogis (default: FALSE) device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream). p Vector probabilities (mlx array coercible mlx)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dlogis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Logistic distribution functions — mlx_dlogis","text":"mlx array computed values","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dlogis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logistic distribution functions — mlx_dlogis","text":"","code":"x <- as_mlx(seq(-3, 3, by = 0.5)) as.matrix(mlx_dlogis(x)) #>  [1] 0.04517667 0.07010371 0.10499357 0.14914645 0.19661196 0.23500372 #>  [7] 0.25000000 0.23500372 0.19661194 0.14914647 0.10499358 0.07010371 #> [13] 0.04517666 as.matrix(mlx_plogis(x)) #>  [1] 0.04742587 0.07585818 0.11920292 0.18242553 0.26894143 0.37754068 #>  [7] 0.50000000 0.62245935 0.73105860 0.81757450 0.88079703 0.92414182 #> [13] 0.95257413  p <- as_mlx(c(0.25, 0.5, 0.75)) as.matrix(mlx_qlogis(p)) #> [1] -1.098612  0.000000  1.098612"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dnorm.html","id":null,"dir":"Reference","previous_headings":"","what":"Normal distribution functions — mlx_dnorm","title":"Normal distribution functions — mlx_dnorm","text":"Compute density (mlx_dnorm), cumulative distribution (mlx_pnorm), quantile (mlx_qnorm) functions normal distribution using MLX.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dnorm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normal distribution functions — mlx_dnorm","text":"","code":"mlx_dnorm(x, mean = 0, sd = 1, log = FALSE, device = mlx_default_device())  mlx_pnorm(x, mean = 0, sd = 1, device = mlx_default_device())  mlx_qnorm(p, mean = 0, sd = 1, device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dnorm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normal distribution functions — mlx_dnorm","text":"x Vector quantiles (mlx array coercible mlx) mean Mean distribution (default: 0) sd Standard deviation distribution (default: 1) log TRUE, return log density mlx_dnorm (default: FALSE) device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream). p Vector probabilities (mlx array coercible mlx)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dnorm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normal distribution functions — mlx_dnorm","text":"mlx array computed values","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dnorm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normal distribution functions — mlx_dnorm","text":"","code":"x <- as_mlx(seq(-3, 3, by = 0.5)) as.matrix(mlx_dnorm(x)) #>  [1] 0.004431848 0.017528297 0.053990964 0.129517585 0.241970733 0.352065325 #>  [7] 0.398942292 0.352065325 0.241970733 0.129517585 0.053990964 0.017528297 #> [13] 0.004431848 as.matrix(mlx_pnorm(x)) #>  [1] 0.001349896 0.006209671 0.022750139 0.066807210 0.158655256 0.308537543 #>  [7] 0.500000000 0.691462457 0.841344714 0.933192790 0.977249861 0.993790329 #> [13] 0.998650074  p <- as_mlx(c(0.025, 0.5, 0.975)) as.matrix(mlx_qnorm(p)) #> [1] -1.959964  0.000000  1.959964"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dropout.html","id":null,"dir":"Reference","previous_headings":"","what":"Dropout layer — mlx_dropout","title":"Dropout layer — mlx_dropout","text":"Dropout layer","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dropout.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dropout layer — mlx_dropout","text":"","code":"mlx_dropout(p = 0.5)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dropout.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dropout layer — mlx_dropout","text":"p Probability dropping element (default: 0.5).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dropout.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Dropout layer — mlx_dropout","text":"mlx_module applying dropout training.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dropout.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dropout layer — mlx_dropout","text":"","code":"set.seed(1) dropout <- mlx_dropout(p = 0.3) x <- as_mlx(matrix(1:12, 3, 4)) mlx_forward(dropout, x) #> mlx array [3 x 4] #>   dtype: float32 #>   device: gpu #>   values: #>          [,1]     [,2]     [,3]     [,4] #> [1,] 1.428571 5.714286 10.00000 14.28571 #> [2,] 2.857143 7.142857 11.42857 15.71429 #> [3,] 4.285714 0.000000 12.85714 17.14286"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dtype.html","id":null,"dir":"Reference","previous_headings":"","what":"Get data type helper — mlx_dtype","title":"Get data type helper — mlx_dtype","text":"Get data type helper","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dtype.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get data type helper — mlx_dtype","text":"","code":"mlx_dtype(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dtype.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get data type helper — mlx_dtype","text":"x mlx array, R array/matrix/vector converted via as_mlx().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dtype.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get data type helper — mlx_dtype","text":"Data type string","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dtype.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get data type helper — mlx_dtype","text":"","code":"x <- as_mlx(matrix(1:6, 2, 3)) mlx_dtype(x) #> [1] \"float32\""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dunif.html","id":null,"dir":"Reference","previous_headings":"","what":"Uniform distribution functions — mlx_dunif","title":"Uniform distribution functions — mlx_dunif","text":"Compute density (mlx_dunif), cumulative distribution (mlx_punif), quantile (mlx_qunif) functions uniform distribution using MLX.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dunif.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Uniform distribution functions — mlx_dunif","text":"","code":"mlx_dunif(x, min = 0, max = 1, log = FALSE, device = mlx_default_device())  mlx_punif(x, min = 0, max = 1, device = mlx_default_device())  mlx_qunif(p, min = 0, max = 1, device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dunif.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Uniform distribution functions — mlx_dunif","text":"x Vector quantiles (mlx array coercible mlx) min, max Lower upper limits distribution (default: 0, 1) log TRUE, return log density mlx_dunif (default: FALSE) device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream). p Vector probabilities (mlx array coercible mlx)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dunif.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Uniform distribution functions — mlx_dunif","text":"mlx array computed values","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_dunif.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Uniform distribution functions — mlx_dunif","text":"","code":"x <- as_mlx(seq(0, 1, by = 0.1)) as.matrix(mlx_dunif(x)) #>  [1] 1 1 1 1 1 1 1 1 1 1 1 as.matrix(mlx_punif(x)) #>  [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0  p <- as_mlx(c(0.25, 0.5, 0.75)) as.matrix(mlx_qunif(p)) #> [1] 0.25 0.50 0.75"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eig.html","id":null,"dir":"Reference","previous_headings":"","what":"Eigen decomposition for mlx arrays — mlx_eig","title":"Eigen decomposition for mlx arrays — mlx_eig","text":"Eigen decomposition mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eig.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Eigen decomposition for mlx arrays — mlx_eig","text":"","code":"mlx_eig(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eig.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Eigen decomposition for mlx arrays — mlx_eig","text":"x mlx matrix (2-dimensional array).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eig.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Eigen decomposition for mlx arrays — mlx_eig","text":"list components values vectors, mlx arrays.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eig.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Eigen decomposition for mlx arrays — mlx_eig","text":"","code":"x <- as_mlx(matrix(c(2, -1, 0, 2), 2, 2)) eig <- mlx_eig(x) eig$values #> mlx array [2] #>   dtype: complex64 #>   device: gpu #>   values: #> [1] 2+0i 2+0i eig$vectors #> mlx array [2 x 2] #>   dtype: complex64 #>   device: gpu #>   values: #>                 [,1] [,2] #> [1,] 2.384186e-07+0i 0+0i #> [2,] 1.000000e+00+0i 1+0i"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigh.html","id":null,"dir":"Reference","previous_headings":"","what":"Eigen decomposition of Hermitian mlx arrays — mlx_eigh","title":"Eigen decomposition of Hermitian mlx arrays — mlx_eigh","text":"Eigen decomposition Hermitian mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Eigen decomposition of Hermitian mlx arrays — mlx_eigh","text":"","code":"mlx_eigh(x, uplo = c(\"L\", \"U\"))"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Eigen decomposition of Hermitian mlx arrays — mlx_eigh","text":"x mlx matrix (2-dimensional array). uplo Character string indicating triangle use (\"L\" \"U\").","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Eigen decomposition of Hermitian mlx arrays — mlx_eigh","text":"list components values vectors.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Eigen decomposition of Hermitian mlx arrays — mlx_eigh","text":"","code":"x <- as_mlx(matrix(c(2, 1, 1, 3), 2, 2)) mlx_eigh(x) #> $values #> mlx array [2] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 1.381966 3.618034 #>  #> $vectors #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>            [,1]      [,2] #> [1,] -0.8506508 0.5257311 #> [2,]  0.5257311 0.8506508 #>"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigvals.html","id":null,"dir":"Reference","previous_headings":"","what":"Eigenvalues of mlx arrays — mlx_eigvals","title":"Eigenvalues of mlx arrays — mlx_eigvals","text":"Eigenvalues mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigvals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Eigenvalues of mlx arrays — mlx_eigvals","text":"","code":"mlx_eigvals(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigvals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Eigenvalues of mlx arrays — mlx_eigvals","text":"x mlx matrix (2-dimensional array).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigvals.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Eigenvalues of mlx arrays — mlx_eigvals","text":"mlx array containing eigenvalues.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigvals.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Eigenvalues of mlx arrays — mlx_eigvals","text":"","code":"x <- as_mlx(matrix(c(3, 1, 0, 2), 2, 2)) mlx_eigvals(x) #> mlx array [2] #>   dtype: complex64 #>   device: gpu #>   values: #> [1] 3+0i 2+0i"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigvalsh.html","id":null,"dir":"Reference","previous_headings":"","what":"Eigenvalues of Hermitian mlx arrays — mlx_eigvalsh","title":"Eigenvalues of Hermitian mlx arrays — mlx_eigvalsh","text":"Eigenvalues Hermitian mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigvalsh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Eigenvalues of Hermitian mlx arrays — mlx_eigvalsh","text":"","code":"mlx_eigvalsh(x, uplo = c(\"L\", \"U\"))"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigvalsh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Eigenvalues of Hermitian mlx arrays — mlx_eigvalsh","text":"x mlx matrix (2-dimensional array). uplo Character string indicating triangle use (\"L\" \"U\").","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigvalsh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Eigenvalues of Hermitian mlx arrays — mlx_eigvalsh","text":"mlx array containing eigenvalues.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eigvalsh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Eigenvalues of Hermitian mlx arrays — mlx_eigvalsh","text":"","code":"x <- as_mlx(matrix(c(2, 1, 1, 3), 2, 2)) mlx_eigvalsh(x) #> mlx array [2] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 1.381966 3.618034"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_embedding.html","id":null,"dir":"Reference","previous_headings":"","what":"Embedding layer — mlx_embedding","title":"Embedding layer — mlx_embedding","text":"Maps discrete tokens continuous vectors.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_embedding.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Embedding layer — mlx_embedding","text":"","code":"mlx_embedding(num_embeddings, embedding_dim, device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_embedding.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Embedding layer — mlx_embedding","text":"num_embeddings Size vocabulary. embedding_dim Dimension embedding vectors. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_embedding.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Embedding layer — mlx_embedding","text":"mlx_module token embeddings.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_embedding.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Embedding layer — mlx_embedding","text":"","code":"set.seed(1) emb <- mlx_embedding(num_embeddings = 100, embedding_dim = 16) # Token indices (1-indexed) tokens <- as_mlx(matrix(c(5, 10, 3, 7), 2, 2)) mlx_forward(emb, tokens) #> mlx array [2 x 2 x 16] #>   dtype: float32 #>   device: gpu #>   (64 elements, not shown)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_erf.html","id":null,"dir":"Reference","previous_headings":"","what":"Error function and inverse error function — mlx_erf","title":"Error function and inverse error function — mlx_erf","text":"mlx_erf() computes error function elementwise. mlx_erfinv() computes inverse error function elementwise.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_erf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Error function and inverse error function — mlx_erf","text":"","code":"mlx_erf(x)  mlx_erfinv(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_erf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Error function and inverse error function — mlx_erf","text":"x mlx array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_erf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Error function and inverse error function — mlx_erf","text":"mlx array result.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_erf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Error function and inverse error function — mlx_erf","text":"","code":"x <- as_mlx(c(-1, 0, 1)) as.matrix(mlx_erf(x)) #> [1] -0.8427008  0.0000000  0.8427008 p <- as_mlx(c(-0.5, 0, 0.5)) as.matrix(mlx_erfinv(p)) #> [1] -0.4769363  0.0000000  0.4769363"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eval.html","id":null,"dir":"Reference","previous_headings":"","what":"Force evaluation of lazy MLX operations — mlx_eval","title":"Force evaluation of lazy MLX operations — mlx_eval","text":"Force evaluation lazy MLX operations","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Force evaluation of lazy MLX operations — mlx_eval","text":"","code":"mlx_eval(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Force evaluation of lazy MLX operations — mlx_eval","text":"x mlx array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Force evaluation of lazy MLX operations — mlx_eval","text":"input object (invisibly)","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eval.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Force evaluation of lazy MLX operations — mlx_eval","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) mlx_eval(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_expand_dims.html","id":null,"dir":"Reference","previous_headings":"","what":"Insert singleton dimensions — mlx_expand_dims","title":"Insert singleton dimensions — mlx_expand_dims","text":"Insert singleton dimensions","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_expand_dims.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Insert singleton dimensions — mlx_expand_dims","text":"","code":"mlx_expand_dims(x, axes)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_expand_dims.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Insert singleton dimensions — mlx_expand_dims","text":"x mlx array. axes Integer vector axis positions (1-indexed) new singleton dimensions inserted.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_expand_dims.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Insert singleton dimensions — mlx_expand_dims","text":"mlx array additional dimensions length one.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_expand_dims.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Insert singleton dimensions — mlx_expand_dims","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) mlx_expand_dims(x, axes = 1) #> mlx array [1 x 2 x 2] #>   dtype: float32 #>   device: gpu #>   (4 elements, not shown)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eye.html","id":null,"dir":"Reference","previous_headings":"","what":"Identity-like matrices on MLX devices — mlx_eye","title":"Identity-like matrices on MLX devices — mlx_eye","text":"Identity-like matrices MLX devices","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eye.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identity-like matrices on MLX devices — mlx_eye","text":"","code":"mlx_eye(   n,   m = n,   k = 0L,   dtype = c(\"float32\", \"float64\"),   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eye.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identity-like matrices on MLX devices — mlx_eye","text":"n Number rows. m Optional number columns (defaults n). k Diagonal index: 0 main diagonal, positive values shift upward, negative values shift downward. dtype MLX dtype use. One \"float32\", \"float64\", \"int8\", \"int16\", \"int32\", \"int64\", \"uint8\", \"uint16\", \"uint32\", \"uint64\", \"bool\", \"complex64\". device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eye.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identity-like matrices on MLX devices — mlx_eye","text":"mlx matrix ones selected diagonal zeros elsewhere.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_eye.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identity-like matrices on MLX devices — mlx_eye","text":"","code":"eye <- mlx_eye(3) upper_eye <- mlx_eye(3, k = 1)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_fft.html","id":null,"dir":"Reference","previous_headings":"","what":"Fast Fourier transforms for MLX arrays — mlx_fft","title":"Fast Fourier transforms for MLX arrays — mlx_fft","text":"mlx_fft(), mlx_fft2(), mlx_fftn() wrap MLX FFT kernels R-friendly defaults. Inputs converted as_mlx() results returned mlx arrays.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_fft.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fast Fourier transforms for MLX arrays — mlx_fft","text":"","code":"mlx_fft(x, axis, inverse = FALSE, device = NULL)  mlx_fft2(x, axes, inverse = FALSE, device = NULL)  mlx_fftn(x, axes = NULL, inverse = FALSE, device = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_fft.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fast Fourier transforms for MLX arrays — mlx_fft","text":"x Array-like object coercible mlx. axis Optional integer axis (1-indexed) one-dimensional transform. Omit argument use last dimension (negative axes). inverse Logical flag; TRUE, compute inverse transform. inverse un-normalised match base R's fft(), .e. results multiplied product transformed axis lengths. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream). axes Optional integer vector axes multi-dimensional transforms. Supply positive, 1-based axes; omit argument use trailing axes (mlx_fft() defaults last axis, mlx_fft2() defaults last two axes, mlx_fftn() defaults axes).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_fft.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fast Fourier transforms for MLX arrays — mlx_fft","text":"mlx array containing complex frequency coefficients.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_fft.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fast Fourier transforms for MLX arrays — mlx_fft","text":"device NULL, transform runs input array's device, falling back mlx_default_device() coercing non-mlx inputs.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_fft.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fast Fourier transforms for MLX arrays — mlx_fft","text":"","code":"x <- as_mlx(c(1, 2, 3, 4)) mlx_fft(x) #> mlx array [4] #>   dtype: complex64 #>   device: gpu #>   values: #> [1] 10+0i -2+2i -2+0i -2-2i mlx_fft(x, inverse = TRUE) #> mlx array [4] #>   dtype: complex64 #>   device: gpu #>   values: #> [1] 10+0i -2-2i -2+0i -2+2i mat <- matrix(1:9, 3, 3) mlx_fft2(as_mlx(mat)) #> mlx array [3 x 3] #>   dtype: complex64 #>   device: gpu #>   values: #>                [,1]            [,2]            [,3] #> [1,] 45.0+0.000000i -13.5+7.794229i -13.5-7.794229i #> [2,] -4.5+2.598076i   0.0+0.000000i   0.0+0.000000i #> [3,] -4.5-2.598076i   0.0+0.000000i   0.0+0.000000i arr <- as_mlx(array(1:8, dim = c(2, 2, 2))) mlx_fftn(arr) #> mlx array [2 x 2 x 2] #>   dtype: complex64 #>   device: gpu #>   (8 elements, not shown)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_flatten.html","id":null,"dir":"Reference","previous_headings":"","what":"Flatten axes of an mlx array — mlx_flatten","title":"Flatten axes of an mlx array — mlx_flatten","text":"mlx_flatten() mirrors mlx.core.flatten(), collapsing contiguous range axes single dimension.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_flatten.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flatten axes of an mlx array — mlx_flatten","text":"","code":"mlx_flatten(x, start_axis = 1L, end_axis = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_flatten.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flatten axes of an mlx array — mlx_flatten","text":"x mlx array. start_axis First axis (1-indexed) flattened range. end_axis Last axis (1-indexed) flattened range. Omit use final dimension.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_flatten.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flatten axes of an mlx array — mlx_flatten","text":"mlx array selected axes collapsed.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_flatten.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flatten axes of an mlx array — mlx_flatten","text":"","code":"x <- as_mlx(array(1:12, dim = c(2, 3, 2))) mlx_flatten(x) #> mlx array [12] #>   dtype: float32 #>   device: gpu #>   values: #>  [1]  1  7  3  9  5 11  2  8  4 10  6 12 mlx_flatten(x, start_axis = 2, end_axis = 3) #> mlx array [2 x 6] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] [,4] [,5] [,6] #> [1,]    1    7    3    9    5   11 #> [2,]    2    8    4   10    6   12"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_forward.html","id":null,"dir":"Reference","previous_headings":"","what":"Forward pass utility — mlx_forward","title":"Forward pass utility — mlx_forward","text":"Forward pass utility","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_forward.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forward pass utility — mlx_forward","text":"","code":"mlx_forward(module, x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_forward.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forward pass utility — mlx_forward","text":"module mlx_module. x mlx array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_forward.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forward pass utility — mlx_forward","text":"Output array.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_forward.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Forward pass utility — mlx_forward","text":"","code":"set.seed(1) layer <- mlx_linear(2, 1) input <- as_mlx(matrix(c(1, 2), 1, 2)) mlx_forward(layer, input) #> mlx array [1 x 1] #>   dtype: float32 #>   device: gpu #>   values: #>            [,1] #> [1,] -0.2591672"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_full.html","id":null,"dir":"Reference","previous_headings":"","what":"Fill an mlx array with a constant value — mlx_full","title":"Fill an mlx array with a constant value — mlx_full","text":"Fill mlx array constant value","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_full.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fill an mlx array with a constant value — mlx_full","text":"","code":"mlx_full(dim, value, dtype = NULL, device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_full.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fill an mlx array with a constant value — mlx_full","text":"dim Integer vector specifying array shape/dimensions. value Scalar value used fill array. Numeric, logical, complex. dtype MLX dtype (\"float32\", \"float64\", \"bool\", \"complex64\"). omitted, defaults \"complex64\" complex scalars, \"bool\" logical scalars, \"float32\" otherwise. device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_full.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fill an mlx array with a constant value — mlx_full","text":"mlx array filled supplied value.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_full.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fill an mlx array with a constant value — mlx_full","text":"","code":"filled <- mlx_full(c(2, 2), 3.14) complex_full <- mlx_full(c(2, 2), 1+2i, dtype = \"complex64\")"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_gather.html","id":null,"dir":"Reference","previous_headings":"","what":"Gather elements from an mlx array — mlx_gather","title":"Gather elements from an mlx array — mlx_gather","text":"Wraps mlx.core.gather() can pull elements axis. Provide one index per axis. Axes must positive integers (allow negative indices, unlike Python).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_gather.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gather elements from an mlx array — mlx_gather","text":"","code":"mlx_gather(x, indices, axes = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_gather.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gather elements from an mlx array — mlx_gather","text":"x mlx array. indices List numeric/logical vectors arrays (R mlx). entries must broadcast common shape. axes Integer vector axes (1-indexed). Defaults first length(indices) axes.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_gather.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gather elements from an mlx array — mlx_gather","text":"mlx array containing gathered elements.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_gather.html","id":"element-wise-indexing","dir":"Reference","previous_headings":"","what":"Element-wise indexing","title":"Gather elements from an mlx array — mlx_gather","text":"output shape indices. element output x[index_1, index_2, ...] corresponding position index. See examples .","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_gather.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gather elements from an mlx array — mlx_gather","text":"","code":"x <- as_mlx(matrix(1:9, 3, 3))  # Simple cartesian gather: as.matrix(mlx_gather(x, list(1:2, 1:2), axes = 1:2)) #> [1] 1 5  # Element-wise pairs: grab a custom 2x2 grid of coordinates row_idx <- matrix(c(1, 1,                     2, 3), nrow = 2, byrow = TRUE) col_idx <- matrix(c(1, 3,                     2, 2), nrow = 2, byrow = TRUE) as.array(mlx_gather(x, list(row_idx, col_idx), axes = c(1L, 2L))) #>      [,1] [,2] #> [1,]    1    7 #> [2,]    5    6"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_gather_qmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Gather-based Quantized Matrix Multiplication — mlx_gather_qmm","title":"Gather-based Quantized Matrix Multiplication — mlx_gather_qmm","text":"Performs quantized matrix multiplication optional gather operations inputs. useful combining embedding lookups quantized linear transformations, common pattern transformer models.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_gather_qmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gather-based Quantized Matrix Multiplication — mlx_gather_qmm","text":"","code":"mlx_gather_qmm(   x,   w,   scales,   biases = NULL,   lhs_indices = NULL,   rhs_indices = NULL,   transpose = TRUE,   group_size = 64L,   bits = 4L,   mode = \"affine\",   sorted_indices = FALSE,   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_gather_qmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gather-based Quantized Matrix Multiplication — mlx_gather_qmm","text":"x mlx array. w mlx array (quantized weight matrix) scales mlx array (quantization scales) biases optional mlx array (biases add). Default: NULL lhs_indices optional mlx array (indices gathering x). Default: NULL rhs_indices optional mlx array (indices gathering w). Default: NULL transpose Whether transpose weight matrix. Default: TRUE group_size group size quantization. Default: 64 bits number bits quantization (typically 4 8). Default: 4 mode quantization mode, either \"affine\" \"mxfp4\". Default: \"affine\" sorted_indices Whether indices sorted (enables optimizations). Default: FALSE device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_gather_qmm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gather-based Quantized Matrix Multiplication — mlx_gather_qmm","text":"mlx array result gather-based quantized matrix multiplication","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_gather_qmm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gather-based Quantized Matrix Multiplication — mlx_gather_qmm","text":"function combines gather operations (indexed lookups) quantized matrix multiplication. lhs_indices provided, performs x[lhs_indices] multiplication. Similarly, rhs_indices gathers weight matrix. particularly efficient transformer models need look token embeddings apply quantized linear transformation one fused operation.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_gelu.html","id":null,"dir":"Reference","previous_headings":"","what":"GELU activation — mlx_gelu","title":"GELU activation — mlx_gelu","text":"Gaussian Error Linear Unit activation function.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_gelu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"GELU activation — mlx_gelu","text":"","code":"mlx_gelu()"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_gelu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"GELU activation — mlx_gelu","text":"mlx_module applying GELU activation.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_gelu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"GELU activation — mlx_gelu","text":"","code":"act <- mlx_gelu() x <- as_mlx(matrix(c(-2, -1, 0, 1, 2), 5, 1)) mlx_forward(act, x) #> mlx array [5 x 1] #>   dtype: float32 #>   device: gpu #>   values: #>             [,1] #> [1,] -0.04540229 #> [2,] -0.15880799 #> [3,]  0.00000000 #> [4,]  0.84119201 #> [5,]  1.95459771"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_grad.html","id":null,"dir":"Reference","previous_headings":"","what":"Automatic differentiation for MLX functions — mlx_grad","title":"Automatic differentiation for MLX functions — mlx_grad","text":"mlx_grad() computes gradients R function operates mlx arrays. function must keep differentiable computations MLX (e.g., via as_mlx() MLX operators) return mlx object.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_grad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Automatic differentiation for MLX functions — mlx_grad","text":"","code":"mlx_grad(f, ..., argnums = NULL, value = FALSE)  mlx_value_grad(f, ..., argnums = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_grad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Automatic differentiation for MLX functions — mlx_grad","text":"f R function. arguments mlx objects, return value must mlx array (typically scalar loss). ... Arguments pass f. coerced mlx needed. argnums Indices (1-based) identifying arguments differentiate respect . Defaults arguments. value function value returned alongside gradients? Set TRUE receive list components value grads.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_grad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Automatic differentiation for MLX functions — mlx_grad","text":"value = FALSE (default), list mlx arrays containing gradients order argnums. value = TRUE, list elements value (function output mlx) grads.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_grad.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Automatic differentiation for MLX functions — mlx_grad","text":"Keep differentiated closure inside MLX operations. Coercing arrays back base R objects (.matrix(), .numeric(), [[ extraction) breaks gradient tape results error.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_grad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Automatic differentiation for MLX functions — mlx_grad","text":"","code":"loss <- function(w, x, y) {   preds <- x %*% w   resids <- preds - y   sum(resids * resids) / length(y) } x <- as_mlx(matrix(1:8, 4, 2)) y <- as_mlx(matrix(c(1, 3, 2, 4), 4, 1)) w <- as_mlx(matrix(0, 2, 1)) mlx_grad(loss, w, x, y)[[1]] #> mlx array [2 x 1] #>   dtype: float32 #>   device: gpu #>   values: #>       [,1] #> [1,] -14.5 #> [2,] -34.5 loss <- function(w, x) sum((x %*% w) * (x %*% w)) x <- as_mlx(matrix(1:4, 2, 2)) w <- as_mlx(matrix(c(1, -1), 2, 1)) mlx_value_grad(loss, w, x) #> $value #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 8 #>  #> $grads #> $grads[[1]] #> mlx array [2 x 1] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] #> [1,]  -12 #> [2,]  -28 #>  #> $grads[[2]] #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]   -4    4 #> [2,]   -4    4 #>  #>"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_hadamard_transform.html","id":null,"dir":"Reference","previous_headings":"","what":"Hadamard transform for MLX arrays — mlx_hadamard_transform","title":"Hadamard transform for MLX arrays — mlx_hadamard_transform","text":"Multiplies last dimension x Sylvester-Hadamard matrix corresponding size. transform expects length last axis power two.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_hadamard_transform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hadamard transform for MLX arrays — mlx_hadamard_transform","text":"","code":"mlx_hadamard_transform(x, scale = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_hadamard_transform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hadamard transform for MLX arrays — mlx_hadamard_transform","text":"x mlx array, R array/matrix/vector converted via as_mlx(). scale Optional numeric scalar applied result. MLX defaults 1 / sqrt(n) n size transformed axis; set scale override factor (example, scale = 1 yields unnormalised Hadamard transform).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_hadamard_transform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hadamard transform for MLX arrays — mlx_hadamard_transform","text":"mlx array containing Hadamard-transformed values.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_hadamard_transform.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hadamard transform for MLX arrays — mlx_hadamard_transform","text":"","code":"x <- as_mlx(c(1, -1)) as.vector(mlx_hadamard_transform(x)) #> [1] 0.000000 1.414214 as.vector(mlx_hadamard_transform(x, scale = 1)) #> [1] 0 2"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_identity.html","id":null,"dir":"Reference","previous_headings":"","what":"Identity matrices on MLX devices — mlx_identity","title":"Identity matrices on MLX devices — mlx_identity","text":"Identity matrices MLX devices","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_identity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identity matrices on MLX devices — mlx_identity","text":"","code":"mlx_identity(n, dtype = c(\"float32\", \"float64\"), device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_identity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identity matrices on MLX devices — mlx_identity","text":"n Size square matrix. dtype MLX dtype use. One \"float32\", \"float64\", \"int8\", \"int16\", \"int32\", \"int64\", \"uint8\", \"uint16\", \"uint32\", \"uint64\", \"bool\", \"complex64\". device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_identity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identity matrices on MLX devices — mlx_identity","text":"mlx identity matrix.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_identity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identity matrices on MLX devices — mlx_identity","text":"","code":"I4 <- mlx_identity(4)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_import_function.html","id":null,"dir":"Reference","previous_headings":"","what":"Import an exported MLX function — mlx_import_function","title":"Import an exported MLX function — mlx_import_function","text":"Loads function previously exported MLX Python utilities returns R callable.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_import_function.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import an exported MLX function — mlx_import_function","text":"","code":"mlx_import_function(path, device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_import_function.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import an exported MLX function — mlx_import_function","text":"path Path .mlxfn file created via MLX export utilities. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_import_function.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import an exported MLX function — mlx_import_function","text":"R function. Calling returns mlx array imported function single output, list mlx arrays otherwise.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_import_function.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Import an exported MLX function — mlx_import_function","text":"Imported functions behave like regular R closures: Positional arguments passed first become positional inputs original MLX function expects. Named arguments (e.g. bias = ...) become MLX keyword arguments must match names used exporting. argument coerced mlx via as_mlx() automatically moved requested device/stream execution. MLX function yields single array result returned mlx object; multiple outputs returned list order MLX produced . .mlxfn files can bundle multiple traces (different shapes keyword combinations), imported callable keeps varargs (...) signature. MLX selects appropriate trace runtime based shapes keyword names provide.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_import_function.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import an exported MLX function — mlx_import_function","text":"","code":"add_fn <- mlx_import_function(   system.file(\"extdata/add_matrix.mlxfn\", package = \"Rmlx\"),   device = \"cpu\" ) x <- as_mlx(matrix(1:4, 2, 2)) y <- as_mlx(matrix(5:8, 2, 2)) add_fn(x, bias = y)  # positional + keyword argument #> mlx array [2 x 2] #>   dtype: float32 #>   device: cpu #>   values: #>      [,1] [,2] #> [1,]    6   10 #> [2,]    8   12"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_inv.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute matrix inverse — mlx_inv","title":"Compute matrix inverse — mlx_inv","text":"Computes inverse square matrix.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_inv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute matrix inverse — mlx_inv","text":"","code":"mlx_inv(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_inv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute matrix inverse — mlx_inv","text":"x mlx array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_inv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute matrix inverse — mlx_inv","text":"inverse x.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_inv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute matrix inverse — mlx_inv","text":"","code":"A <- as_mlx(matrix(c(4, 7, 2, 6), 2, 2)) A_inv <- mlx_inv(A) # Verify: A %*% A_inv should be identity as.matrix(A %*% A_inv) #>              [,1] [,2] #> [1,] 1.000000e+00    0 #> [2,] 3.576279e-07    1"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isclose.html","id":null,"dir":"Reference","previous_headings":"","what":"Element-wise approximate equality — mlx_isclose","title":"Element-wise approximate equality — mlx_isclose","text":"Returns boolean array indicating elements two arrays close within specified tolerances.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isclose.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Element-wise approximate equality — mlx_isclose","text":"","code":"mlx_isclose(   a,   b,   rtol = 1e-05,   atol = 1e-08,   equal_nan = FALSE,   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isclose.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Element-wise approximate equality — mlx_isclose","text":", b MLX arrays objects coercible MLX arrays rtol Relative tolerance (default: 1e-5) atol Absolute tolerance (default: 1e-8) equal_nan TRUE, NaN values considered equal (default: FALSE) device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isclose.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Element-wise approximate equality — mlx_isclose","text":"mlx array booleans element-wise comparison results","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isclose.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Element-wise approximate equality — mlx_isclose","text":"Two values considered close : abs(- b) <= (atol + rtol * abs(b)) Infinite values matching signs considered equal. Supports NumPy-style broadcasting.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isclose.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Element-wise approximate equality — mlx_isclose","text":"","code":"a <- as_mlx(c(1.0, 2.0, 3.0)) b <- as_mlx(c(1.0 + 1e-6, 2.0 + 1e-6, 3.0 + 1e-3)) mlx_isclose(a, b)  # First two TRUE, last FALSE #> mlx array [3] #>   dtype: bool #>   device: gpu #>   values: #> [1]  TRUE  TRUE FALSE"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isnan.html","id":null,"dir":"Reference","previous_headings":"","what":"Elementwise NaN and infinity predicates — mlx_isnan","title":"Elementwise NaN and infinity predicates — mlx_isnan","text":"mlx_isnan(), mlx_isinf(), mlx_isfinite() wrap corresponding MLX elementwise predicates, returning boolean arrays.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isnan.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Elementwise NaN and infinity predicates — mlx_isnan","text":"","code":"mlx_isnan(x)  mlx_isinf(x)  mlx_isfinite(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isnan.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Elementwise NaN and infinity predicates — mlx_isnan","text":"x mlx array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isnan.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Elementwise NaN and infinity predicates — mlx_isnan","text":"mlx boolean array.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isposinf.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect signed infinities in mlx arrays — mlx_isposinf","title":"Detect signed infinities in mlx arrays — mlx_isposinf","text":"mlx_isposinf() mlx_isneginf() mirror mlx.core.isposinf() mlx.core.isneginf(), returning boolean masks positive negative infinities.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isposinf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect signed infinities in mlx arrays — mlx_isposinf","text":"","code":"mlx_isposinf(x)  mlx_isneginf(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isposinf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect signed infinities in mlx arrays — mlx_isposinf","text":"x mlx array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isposinf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect signed infinities in mlx arrays — mlx_isposinf","text":"mlx boolean array highlighting infinite entries.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_isposinf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect signed infinities in mlx arrays — mlx_isposinf","text":"","code":"vals <- as_mlx(c(-Inf, -1, 0, Inf)) as.matrix(mlx_isposinf(vals)) #> [1] FALSE FALSE FALSE  TRUE as.matrix(mlx_isneginf(vals)) #> [1]  TRUE FALSE FALSE FALSE"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_key.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct MLX random number generator keys — mlx_key","title":"Construct MLX random number generator keys — mlx_key","text":"mlx_key() provides access MLX's stateless PRNG. Given 64-bit seed returns key can passed random helpers. Use mlx_key_split() derive multiple independent keys existing key.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_key.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct MLX random number generator keys — mlx_key","text":"","code":"mlx_key(seed)  mlx_key_split(key, num = 2L)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_key.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct MLX random number generator keys — mlx_key","text":"seed Integer numeric seed (converted unsigned 64-bit). key mlx key array returned mlx_key(). num Number subkeys produce (default 2L).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_key.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct MLX random number generator keys — mlx_key","text":"mlx array holding PRNG key. list num mlx key arrays.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_key.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct MLX random number generator keys — mlx_key","text":"","code":"k <- mlx_key(42) subkeys <- mlx_key_split(k, num = 2)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_key_bits.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate raw random bits on MLX arrays — mlx_key_bits","title":"Generate raw random bits on MLX arrays — mlx_key_bits","text":"Generate raw random bits MLX arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_key_bits.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate raw random bits on MLX arrays — mlx_key_bits","text":"","code":"mlx_key_bits(dim, width = 4L, key = NULL, device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_key_bits.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate raw random bits on MLX arrays — mlx_key_bits","text":"dim Integer vector specifying array shape/dimensions. width Number bytes per element (default 4 = 32 bits). Must positive. key Optional mlx key array. omitted, MLX's default generator used. device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_key_bits.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate raw random bits on MLX arrays — mlx_key_bits","text":"mlx array unsigned integers filled random bits.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_key_bits.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate raw random bits on MLX arrays — mlx_key_bits","text":"","code":"k <- mlx_key(12) raw_bits <- mlx_key_bits(c(4, 4), key = k)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_kron.html","id":null,"dir":"Reference","previous_headings":"","what":"Kronecker product for mlx arrays — mlx_kron","title":"Kronecker product for mlx arrays — mlx_kron","text":"Computes Kronecker (tensor) product two mlx arrays. Inputs automatically cast common dtype device evaluation.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_kron.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kronecker product for mlx arrays — mlx_kron","text":"","code":"mlx_kron(a, b)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_kron.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kronecker product for mlx arrays — mlx_kron","text":", b Objects coercible mlx.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_kron.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Kronecker product for mlx arrays — mlx_kron","text":"mlx array representing Kronecker product.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_kron.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Kronecker product for mlx arrays — mlx_kron","text":"","code":"A <- as_mlx(matrix(1:4, 2, 2)) B <- as_mlx(matrix(c(0, 5, 6, 7), 2, 2)) mlx_kron(A, B) #> mlx array [4 x 4] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] [,4] #> [1,]    0    6    0   18 #> [2,]    5    7   15   21 #> [3,]    0   12    0   24 #> [4,]   10   14   20   28"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_l1_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"L1 loss (Mean Absolute Error) — mlx_l1_loss","title":"L1 loss (Mean Absolute Error) — mlx_l1_loss","text":"Computes mean absolute error predictions targets.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_l1_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"L1 loss (Mean Absolute Error) — mlx_l1_loss","text":"","code":"mlx_l1_loss(predictions, targets, reduction = c(\"mean\", \"sum\", \"none\"))"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_l1_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"L1 loss (Mean Absolute Error) — mlx_l1_loss","text":"predictions Predicted values mlx array. targets Target values mlx array. reduction Type reduction: \"mean\" (default), \"sum\", \"none\".","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_l1_loss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"L1 loss (Mean Absolute Error) — mlx_l1_loss","text":"mlx array containing loss.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_l1_loss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"L1 loss (Mean Absolute Error) — mlx_l1_loss","text":"","code":"preds <- as_mlx(matrix(c(1.5, 2.3, 0.8), 3, 1)) targets <- as_mlx(matrix(c(1, 2, 1), 3, 1)) mlx_l1_loss(preds, targets) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 0.3333333"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_layer_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"Layer normalization — mlx_layer_norm","title":"Layer normalization — mlx_layer_norm","text":"Normalizes inputs across feature dimension.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_layer_norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Layer normalization — mlx_layer_norm","text":"","code":"mlx_layer_norm(normalized_shape, eps = 1e-05, device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_layer_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Layer normalization — mlx_layer_norm","text":"normalized_shape Size feature dimension normalize. eps Small constant numerical stability (default: 1e-5). device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_layer_norm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Layer normalization — mlx_layer_norm","text":"mlx_module applying layer normalization.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_layer_norm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Layer normalization — mlx_layer_norm","text":"","code":"set.seed(1) ln <- mlx_layer_norm(4) x <- as_mlx(matrix(rnorm(12), 3, 4)) mlx_forward(ln, x) #> mlx array [3 x 4] #>   dtype: float32 #>   device: gpu #>   values: #>            [,1]       [,2]       [,3]       [,4] #> [1,] -1.0668312  1.5259182 0.23306273 -0.6921500 #> [2,] -0.9833397 -0.7005272 0.09211669  1.5917501 #> [3,] -1.0064702 -0.9834564 1.13609314  0.8538334"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_leaky_relu.html","id":null,"dir":"Reference","previous_headings":"","what":"Leaky ReLU activation — mlx_leaky_relu","title":"Leaky ReLU activation — mlx_leaky_relu","text":"Leaky ReLU activation","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_leaky_relu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Leaky ReLU activation — mlx_leaky_relu","text":"","code":"mlx_leaky_relu(negative_slope = 0.01)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_leaky_relu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Leaky ReLU activation — mlx_leaky_relu","text":"negative_slope Slope negative values (default: 0.01).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_leaky_relu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Leaky ReLU activation — mlx_leaky_relu","text":"mlx_module applying Leaky ReLU activation.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_leaky_relu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Leaky ReLU activation — mlx_leaky_relu","text":"","code":"act <- mlx_leaky_relu(negative_slope = 0.1) x <- as_mlx(matrix(c(-2, -1, 0, 1, 2), 5, 1)) mlx_forward(act, x) #> mlx array [5 x 1] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] #> [1,] -0.2 #> [2,] -0.1 #> [3,]  0.0 #> [4,]  1.0 #> [5,]  2.0"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_linear.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a learnable linear transformation — mlx_linear","title":"Create a learnable linear transformation — mlx_linear","text":"Create learnable linear transformation","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_linear.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a learnable linear transformation — mlx_linear","text":"","code":"mlx_linear(   in_features,   out_features,   bias = TRUE,   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_linear.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a learnable linear transformation — mlx_linear","text":"in_features Number input features. out_features Number output features. bias bias term included? device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_linear.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a learnable linear transformation — mlx_linear","text":"object class mlx_module.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_linear.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a learnable linear transformation — mlx_linear","text":"","code":"set.seed(1) layer <- mlx_linear(3, 2) x <- as_mlx(matrix(1:6, 2, 3)) mlx_forward(layer, x) #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>           [,1]       [,2] #> [1,] -3.473105 -1.2398810 #> [2,] -4.516946 -0.3382074"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_linspace.html","id":null,"dir":"Reference","previous_headings":"","what":"Evenly spaced ranges on MLX devices — mlx_linspace","title":"Evenly spaced ranges on MLX devices — mlx_linspace","text":"mlx_linspace() creates num evenly spaced values start stop, inclusive. Unlike mlx_arange(), specify many samples want rather step size.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_linspace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evenly spaced ranges on MLX devices — mlx_linspace","text":"","code":"mlx_linspace(   start,   stop,   num = 50L,   dtype = c(\"float32\", \"float64\"),   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_linspace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evenly spaced ranges on MLX devices — mlx_linspace","text":"start Starting value. stop Final value (inclusive). num Number samples generate. dtype MLX dtype (\"float32\" \"float64\"). device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_linspace.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evenly spaced ranges on MLX devices — mlx_linspace","text":"1D mlx array.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_linspace.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evenly spaced ranges on MLX devices — mlx_linspace","text":"","code":"mlx_linspace(0, 1, num = 5) #> mlx array [5] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 0.00 0.25 0.50 0.75 1.00"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_load.html","id":null,"dir":"Reference","previous_headings":"","what":"Load an MLX array from disk — mlx_load","title":"Load an MLX array from disk — mlx_load","text":"Restores array saved mlx_save() optionally places specified device.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_load.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load an MLX array from disk — mlx_load","text":"","code":"mlx_load(file, device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_load.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load an MLX array from disk — mlx_load","text":"file Path .npy file. extension appended automatically missing. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_load.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load an MLX array from disk — mlx_load","text":"mlx array containing file contents.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_load.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Load an MLX array from disk — mlx_load","text":"Use mlx_stream mlx_new_stream() load directly onto specific stream; otherwise array placed current mlx_default_device().","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_load_gguf.html","id":null,"dir":"Reference","previous_headings":"","what":"Load MLX tensors from the GGUF format — mlx_load_gguf","title":"Load MLX tensors from the GGUF format — mlx_load_gguf","text":"Load MLX tensors GGUF format","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_load_gguf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load MLX tensors from the GGUF format — mlx_load_gguf","text":"","code":"mlx_load_gguf(file, device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_load_gguf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load MLX tensors from the GGUF format — mlx_load_gguf","text":"file Path .npy file. extension appended automatically missing. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_load_gguf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load MLX tensors from the GGUF format — mlx_load_gguf","text":"list containing: tensors Named list mlx arrays. metadata Named list values NULL, character vectors, mlx arrays depending GGUF entry type.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_load_safetensors.html","id":null,"dir":"Reference","previous_headings":"","what":"Load MLX arrays from the safetensors format — mlx_load_safetensors","title":"Load MLX arrays from the safetensors format — mlx_load_safetensors","text":"Load MLX arrays safetensors format","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_load_safetensors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load MLX arrays from the safetensors format — mlx_load_safetensors","text":"","code":"mlx_load_safetensors(file, device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_load_safetensors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load MLX arrays from the safetensors format — mlx_load_safetensors","text":"file Path .npy file. extension appended automatically missing. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_load_safetensors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load MLX arrays from the safetensors format — mlx_load_safetensors","text":"list containing: tensors Named list mlx arrays. metadata Named character vector serialized metadata.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_logcumsumexp.html","id":null,"dir":"Reference","previous_headings":"","what":"Log cumulative sum exponential for mlx arrays — mlx_logcumsumexp","title":"Log cumulative sum exponential for mlx arrays — mlx_logcumsumexp","text":"Log cumulative sum exponential mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_logcumsumexp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log cumulative sum exponential for mlx arrays — mlx_logcumsumexp","text":"","code":"mlx_logcumsumexp(x, axis = NULL, reverse = FALSE, inclusive = TRUE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_logcumsumexp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log cumulative sum exponential for mlx arrays — mlx_logcumsumexp","text":"x mlx array, R array/matrix/vector converted via as_mlx(). axis Optional axis (single integer) operate . reverse Logical flag reverse accumulation. inclusive Logical flag controlling inclusivity.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_logcumsumexp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log cumulative sum exponential for mlx arrays — mlx_logcumsumexp","text":"mlx array.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_logcumsumexp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log cumulative sum exponential for mlx arrays — mlx_logcumsumexp","text":"","code":"x <- as_mlx(1:4) as.vector(mlx_logcumsumexp(x)) #> [1] 1.000000 2.313262 3.407606 4.440190 m <- as_mlx(matrix(1:6, 2, 3)) as.matrix(mlx_logcumsumexp(m, axis = 2)) #>      [,1]     [,2]     [,3] #> [1,]    1 3.126928 5.142931 #> [2,]    2 4.126928 6.142931"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_logsumexp.html","id":null,"dir":"Reference","previous_headings":"","what":"Log-sum-exp reduction for mlx arrays — mlx_logsumexp","title":"Log-sum-exp reduction for mlx arrays — mlx_logsumexp","text":"Log-sum-exp reduction mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_logsumexp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log-sum-exp reduction for mlx arrays — mlx_logsumexp","text":"","code":"mlx_logsumexp(x, axes = NULL, drop = TRUE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_logsumexp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log-sum-exp reduction for mlx arrays — mlx_logsumexp","text":"x mlx array, R array/matrix/vector converted via as_mlx(). axes Integer vector axes (1-indexed). Supply positive integers 1 array rank. Many helpers interpret NULL mean \"axes\"—see function details specifics. drop Logical indicating whether reduced axes dropped (default TRUE).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_logsumexp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log-sum-exp reduction for mlx arrays — mlx_logsumexp","text":"mlx array containing log-sum-exp results.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_logsumexp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log-sum-exp reduction for mlx arrays — mlx_logsumexp","text":"","code":"x <- as_mlx(matrix(1:6, 2, 3)) as.matrix(mlx_logsumexp(x)) #> [1] 6.456193 as.matrix(mlx_logsumexp(x, axes = 2)) #> [1] 5.142931 6.142931"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_lu.html","id":null,"dir":"Reference","previous_headings":"","what":"LU factorization — mlx_lu","title":"LU factorization — mlx_lu","text":"Computes LU factorization matrix.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_lu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"LU factorization — mlx_lu","text":"","code":"mlx_lu(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_lu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"LU factorization — mlx_lu","text":"x mlx array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_lu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"LU factorization — mlx_lu","text":"list components p (pivot indices), l (lower triangular), u (upper triangular). relationship = L[P, ] %*% U.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_lu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"LU factorization — mlx_lu","text":"","code":"A <- as_mlx(matrix(rnorm(16), 4, 4)) lu_result <- mlx_lu(A) P <- lu_result$p  # Pivot indices L <- lu_result$l  # Lower triangular U <- lu_result$u  # Upper triangular"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct MLX matrices efficiently — mlx_matrix","title":"Construct MLX matrices efficiently — mlx_matrix","text":"mlx_matrix() wraps mlx_array() common 2-D case. accepts style arguments base::matrix() without recycling, mistakes surface early. Supply nrow ncol (may inferred length(data)).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct MLX matrices efficiently — mlx_matrix","text":"","code":"mlx_matrix(   data,   nrow = NULL,   ncol = NULL,   byrow = FALSE,   dtype = NULL,   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct MLX matrices efficiently — mlx_matrix","text":"data Numeric, logical, complex vector supplying payload. dimension attributes ignored; pass dim explicitly. nrow, ncol Matrix dimensions (positive integers). byrow Logical; TRUE, fill rows (semantics base::matrix()). dtype Optional MLX dtype. Defaults \"float32\" numeric input, \"bool\" logical, \"complex64\" complex. device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct MLX matrices efficiently — mlx_matrix","text":"mlx matrix dim = c(nrow, ncol).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct MLX matrices efficiently — mlx_matrix","text":"","code":"mx <- mlx_matrix(1:6, nrow = 2, ncol = 3, byrow = TRUE) as.matrix(mx) #>      [,1] [,2] [,3] #> [1,]    1    2    3 #> [2,]    4    5    6"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_matrix_required.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameters for Functions Requiring MLX Matrices — mlx_matrix_required","title":"Parameters for Functions Requiring MLX Matrices — mlx_matrix_required","text":"Parameters Functions Requiring MLX Matrices","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_matrix_required.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameters for Functions Requiring MLX Matrices — mlx_matrix_required","text":"x mlx matrix (2-dimensional array).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_maximum.html","id":null,"dir":"Reference","previous_headings":"","what":"Elementwise maximum of two mlx arrays — mlx_maximum","title":"Elementwise maximum of two mlx arrays — mlx_maximum","text":"Elementwise maximum two mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_maximum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Elementwise maximum of two mlx arrays — mlx_maximum","text":"","code":"mlx_maximum(x, y)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_maximum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Elementwise maximum of two mlx arrays — mlx_maximum","text":"x, y mlx arrays objects coercible as_mlx().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_maximum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Elementwise maximum of two mlx arrays — mlx_maximum","text":"mlx array containing elementwise maximum.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_maximum.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Elementwise maximum of two mlx arrays — mlx_maximum","text":"","code":"mlx_maximum(1:3, c(3, 2, 1)) #> mlx array [3] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 3 2 3"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_meshgrid.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct coordinate arrays from input vectors — mlx_meshgrid","title":"Construct coordinate arrays from input vectors — mlx_meshgrid","text":"mlx_meshgrid() mirrors mlx.core.meshgrid(), returning coordinate arrays suitable vectorised evaluation MLX devices.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_meshgrid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct coordinate arrays from input vectors — mlx_meshgrid","text":"","code":"mlx_meshgrid(..., sparse = FALSE, indexing = c(\"xy\", \"ij\"), device = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_meshgrid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct coordinate arrays from input vectors — mlx_meshgrid","text":"... One arrays (single list) convertible via as_mlx() representing coordinate vectors. sparse Logical flag producing broadcast-friendly outputs TRUE. indexing Either \"xy\" (Cartesian) \"ij\" (matrix) indexing. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_meshgrid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct coordinate arrays from input vectors — mlx_meshgrid","text":"list mlx arrays matching number inputs.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_meshgrid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct coordinate arrays from input vectors — mlx_meshgrid","text":"","code":"xs <- as_mlx(1:3) ys <- as_mlx(1:2) grids <- mlx_meshgrid(xs, ys, indexing = \"xy\") lapply(grids, as.matrix) #> [[1]] #>      [,1] [,2] [,3] #> [1,]    1    2    3 #> [2,]    1    2    3 #>  #> [[2]] #>      [,1] [,2] [,3] #> [1,]    1    1    1 #> [2,]    2    2    2 #>"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_minimum.html","id":null,"dir":"Reference","previous_headings":"","what":"Elementwise minimum of two mlx arrays — mlx_minimum","title":"Elementwise minimum of two mlx arrays — mlx_minimum","text":"Elementwise minimum two mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_minimum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Elementwise minimum of two mlx arrays — mlx_minimum","text":"","code":"mlx_minimum(x, y)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_minimum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Elementwise minimum of two mlx arrays — mlx_minimum","text":"x, y mlx arrays objects coercible as_mlx().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_minimum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Elementwise minimum of two mlx arrays — mlx_minimum","text":"mlx array containing elementwise minimum.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_minimum.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Elementwise minimum of two mlx arrays — mlx_minimum","text":"","code":"a <- as_mlx(matrix(1:4, 2, 2)) b <- as_mlx(matrix(c(4, 3, 2, 1), 2, 2)) mlx_minimum(a, b) #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]    1    2 #> [2,]    2    1"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_moveaxis.html","id":null,"dir":"Reference","previous_headings":"","what":"Reorder mlx array axes — mlx_moveaxis","title":"Reorder mlx array axes — mlx_moveaxis","text":"mlx_moveaxis() repositions one axes new locations. aperm.mlx() provides familiar R interface, permuting axes according perm via repeated calls mlx_moveaxis().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_moveaxis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reorder mlx array axes — mlx_moveaxis","text":"","code":"mlx_moveaxis(x, source, destination)  # S3 method for class 'mlx' aperm(a, perm = NULL, resize = TRUE, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_moveaxis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reorder mlx array axes — mlx_moveaxis","text":"x, object coercible mlx via as_mlx(). source Integer vector axis indices move (1-indexed). destination Integer vector giving target positions source axes (1-indexed). Must length source. perm Integer permutation describing desired axis order, matching semantics base::aperm(). resize Logical flag base::aperm(). TRUE currently supported mlx arrays. ... Additional arguments accepted compatibility; ignored.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_moveaxis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reorder mlx array axes — mlx_moveaxis","text":"mlx array axes permuted.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_moveaxis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reorder mlx array axes — mlx_moveaxis","text":"","code":"x <- as_mlx(array(1:8, dim = c(2, 2, 2))) moved <- mlx_moveaxis(x, source = 1, destination = 3) permuted <- aperm(x, c(2, 1, 3))"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_mse_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean squared error loss — mlx_mse_loss","title":"Mean squared error loss — mlx_mse_loss","text":"Computes mean squared error predictions targets.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_mse_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean squared error loss — mlx_mse_loss","text":"","code":"mlx_mse_loss(predictions, targets, reduction = c(\"mean\", \"sum\", \"none\"))"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_mse_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean squared error loss — mlx_mse_loss","text":"predictions Predicted values mlx array. targets Target values mlx array. reduction Type reduction: \"mean\" (default), \"sum\", \"none\".","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_mse_loss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean squared error loss — mlx_mse_loss","text":"mlx array containing loss.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_mse_loss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mean squared error loss — mlx_mse_loss","text":"","code":"preds <- as_mlx(matrix(c(1.5, 2.3, 0.8), 3, 1)) targets <- as_mlx(matrix(c(1, 2, 1), 3, 1)) mlx_mse_loss(preds, targets) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 0.1266666"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_nan_to_num.html","id":null,"dir":"Reference","previous_headings":"","what":"Replace NaN and infinite values with finite numbers — mlx_nan_to_num","title":"Replace NaN and infinite values with finite numbers — mlx_nan_to_num","text":"mlx_nan_to_num() mirrors mlx.core.nan_to_num(), filling non-finite entries user-provided finite substitutes.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_nan_to_num.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replace NaN and infinite values with finite numbers — mlx_nan_to_num","text":"","code":"mlx_nan_to_num(x, nan = 0, posinf = NULL, neginf = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_nan_to_num.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replace NaN and infinite values with finite numbers — mlx_nan_to_num","text":"x mlx array. nan Replacement NaN values (default 0). Use NULL retain MLX's default. posinf Optional replacement positive infinity. neginf Optional replacement negative infinity.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_nan_to_num.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Replace NaN and infinite values with finite numbers — mlx_nan_to_num","text":"mlx array non-finite values replaced.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_nan_to_num.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Replace NaN and infinite values with finite numbers — mlx_nan_to_num","text":"","code":"x <- as_mlx(c(-Inf, -1, NaN, 3, Inf)) as.matrix(mlx_nan_to_num(x, nan = 0, posinf = 10, neginf = -10)) #> [1] -10  -1   0   3  10"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_new_stream.html","id":null,"dir":"Reference","previous_headings":"","what":"MLX streams for asynchronous execution — mlx_new_stream","title":"MLX streams for asynchronous execution — mlx_new_stream","text":"Streams provide independent execution queues device, allowing overlap computation finer control scheduling. mlx_default_stream() returns current default stream device.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_new_stream.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MLX streams for asynchronous execution — mlx_new_stream","text":"","code":"mlx_new_stream(device = mlx_default_device())  mlx_default_stream(device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_new_stream.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MLX streams for asynchronous execution — mlx_new_stream","text":"device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_new_stream.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MLX streams for asynchronous execution — mlx_new_stream","text":"object class mlx_stream.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_new_stream.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MLX streams for asynchronous execution — mlx_new_stream","text":"","code":"stream <- mlx_new_stream() stream #> mlx stream [gpu] index=2"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"Matrix and vector norms for mlx arrays — mlx_norm","title":"Matrix and vector norms for mlx arrays — mlx_norm","text":"Matrix vector norms mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matrix and vector norms for mlx arrays — mlx_norm","text":"","code":"mlx_norm(x, ord = NULL, axes = NULL, drop = TRUE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matrix and vector norms for mlx arrays — mlx_norm","text":"x mlx array. ord Numeric character norm order. Use NULL default 2-norm. axes Integer vector axes (1-indexed). Supply positive integers 1 array rank. Many helpers interpret NULL mean \"axes\"—see function details specifics. drop TRUE (default), drop dimensions length 1. FALSE, retain dimensions. Equivalent keepdims = TRUE underlying mlx functions.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_norm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Matrix and vector norms for mlx arrays — mlx_norm","text":"mlx array containing requested norm.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_norm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Matrix and vector norms for mlx arrays — mlx_norm","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) mlx_norm(x) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 5.477226 mlx_norm(x, ord = 2) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 5.464986 mlx_norm(x, axes = 2) #> mlx array [2] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 3.162278 4.472136"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_ones.html","id":null,"dir":"Reference","previous_headings":"","what":"Create arrays of ones on MLX devices — mlx_ones","title":"Create arrays of ones on MLX devices — mlx_ones","text":"Create arrays ones MLX devices","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_ones.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create arrays of ones on MLX devices — mlx_ones","text":"","code":"mlx_ones(   dim,   dtype = c(\"float32\", \"float64\", \"int8\", \"int16\", \"int32\", \"int64\", \"uint8\", \"uint16\",     \"uint32\", \"uint64\", \"bool\", \"complex64\"),   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_ones.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create arrays of ones on MLX devices — mlx_ones","text":"dim Integer vector specifying array shape/dimensions. dtype MLX dtype use. One \"float32\", \"float64\", \"int8\", \"int16\", \"int32\", \"int64\", \"uint8\", \"uint16\", \"uint32\", \"uint64\", \"bool\", \"complex64\". device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_ones.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create arrays of ones on MLX devices — mlx_ones","text":"mlx array filled ones.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_ones.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create arrays of ones on MLX devices — mlx_ones","text":"","code":"ones <- mlx_ones(c(2, 2), dtype = \"float64\", device = \"cpu\") ones_int <- mlx_ones(c(3, 3), dtype = \"int32\")"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_ones_like.html","id":null,"dir":"Reference","previous_headings":"","what":"Ones shaped like an existing mlx array — mlx_ones_like","title":"Ones shaped like an existing mlx array — mlx_ones_like","text":"mlx_ones_like() mirrors mlx.core.ones_like(), creating array ones shape. Optionally override dtype device.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_ones_like.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ones shaped like an existing mlx array — mlx_ones_like","text":"","code":"mlx_ones_like(x, dtype = NULL, device = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_ones_like.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ones shaped like an existing mlx array — mlx_ones_like","text":"x mlx array. dtype Optional MLX dtype override. Defaults source array's dtype. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_ones_like.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ones shaped like an existing mlx array — mlx_ones_like","text":"mlx array ones matching x.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_ones_like.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ones shaped like an existing mlx array — mlx_ones_like","text":"","code":"base <- mlx_full(c(2, 3), 5) ones <- mlx_ones_like(base) as.matrix(ones) #>      [,1] [,2] [,3] #> [1,]    1    1    1 #> [2,]    1    1    1"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_optimizer_sgd.html","id":null,"dir":"Reference","previous_headings":"","what":"Stochastic gradient descent optimizer — mlx_optimizer_sgd","title":"Stochastic gradient descent optimizer — mlx_optimizer_sgd","text":"Stochastic gradient descent optimizer","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_optimizer_sgd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stochastic gradient descent optimizer — mlx_optimizer_sgd","text":"","code":"mlx_optimizer_sgd(params, lr = 0.01)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_optimizer_sgd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stochastic gradient descent optimizer — mlx_optimizer_sgd","text":"params List parameters (mlx_parameters()). lr Learning rate.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_optimizer_sgd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stochastic gradient descent optimizer — mlx_optimizer_sgd","text":"optimizer object step() method.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_optimizer_sgd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stochastic gradient descent optimizer — mlx_optimizer_sgd","text":"","code":"set.seed(1) model <- mlx_linear(2, 1, bias = FALSE) opt <- mlx_optimizer_sgd(mlx_parameters(model), lr = 0.1)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_pad.html","id":null,"dir":"Reference","previous_headings":"","what":"Pad or split mlx arrays — mlx_pad","title":"Pad or split mlx arrays — mlx_pad","text":"mlx_pad() mirrors MLX padding primitive, enlarging axis according pad_width. Values added symmetrically (pad_width[, 1] , pad_width[, 2] ) using specified mode. mlx_split() divides array along axis either equal sections (sections scalar) explicit 1-based split points (sections vector), returning list mlx arrays.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_pad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pad or split mlx arrays — mlx_pad","text":"","code":"mlx_pad(   x,   pad_width,   value = 0,   mode = c(\"constant\", \"edge\", \"reflect\", \"symmetric\"),   axes = NULL )  mlx_split(x, sections, axis = 1L)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_pad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pad or split mlx arrays — mlx_pad","text":"x mlx array, R array/matrix/vector converted via as_mlx(). pad_width Padding extents. Supply single integer, length-two numeric vector, matrix/list one (, ) pair per padded axis. value Constant fill value used mode = \"constant\". mode Padding mode passed MLX (e.g., \"constant\", \"edge\", \"reflect\"). axes Optional integer vector axes (1-indexed) pad_width applies. Unlisted axes receive zero padding. sections Either single integer (number equal parts) integer vector 1-based split points along axis. axis Axis (1-indexed) operate .","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_pad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pad or split mlx arrays — mlx_pad","text":"mlx_pad(), mlx array; mlx_split(), list mlx arrays.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_pad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pad or split mlx arrays — mlx_pad","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) padded <- mlx_pad(x, pad_width = 1) padded_cols <- mlx_pad(x, pad_width = c(0, 1), axes = 2) parts <- mlx_split(x, sections = 2, axis = 1) custom_parts <- mlx_split(x, sections = c(1), axis = 2)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_param_set_values.html","id":null,"dir":"Reference","previous_headings":"","what":"Assign arrays back to parameters — mlx_param_set_values","title":"Assign arrays back to parameters — mlx_param_set_values","text":"Assign arrays back parameters","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_param_set_values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assign arrays back to parameters — mlx_param_set_values","text":"","code":"mlx_param_set_values(params, values)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_param_set_values.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assign arrays back to parameters — mlx_param_set_values","text":"params list mlx_param. values list arrays.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_param_set_values.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assign arrays back to parameters — mlx_param_set_values","text":"","code":"set.seed(1) layer <- mlx_linear(2, 1) params <- mlx_parameters(layer) current <- mlx_param_values(params) mlx_param_set_values(params, current)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_param_values.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve parameter arrays — mlx_param_values","title":"Retrieve parameter arrays — mlx_param_values","text":"Retrieve parameter arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_param_values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve parameter arrays — mlx_param_values","text":"","code":"mlx_param_values(params)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_param_values.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve parameter arrays — mlx_param_values","text":"params list mlx_param.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_param_values.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve parameter arrays — mlx_param_values","text":"List mlx arrays.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_param_values.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve parameter arrays — mlx_param_values","text":"","code":"set.seed(1) layer <- mlx_linear(2, 1) vals <- mlx_param_values(mlx_parameters(layer))"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Collect parameters from modules — mlx_parameters","title":"Collect parameters from modules — mlx_parameters","text":"Collect parameters modules","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Collect parameters from modules — mlx_parameters","text":"","code":"mlx_parameters(module)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Collect parameters from modules — mlx_parameters","text":"module mlx_module list modules.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Collect parameters from modules — mlx_parameters","text":"list mlx_param objects.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_parameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Collect parameters from modules — mlx_parameters","text":"","code":"set.seed(1) layer <- mlx_linear(2, 1) mlx_parameters(layer) #> [[1]] #> $env #> <environment: 0x1483438f0> #>  #> $name #> [1] \"weight\" #>  #> attr(,\"class\") #> [1] \"mlx_param\" #>  #> [[2]] #> $env #> <environment: 0x1483438f0> #>  #> $name #> [1] \"bias\" #>  #> attr(,\"class\") #> [1] \"mlx_param\" #>"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantile.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute quantiles of MLX arrays — mlx_quantile","title":"Compute quantiles of MLX arrays — mlx_quantile","text":"Calculates sample quantiles corresponding given probabilities using linear interpolation (R's type 7 quantiles, default stats::quantile()). S3 method quantile.mlx() provides interface compatible generic stats::quantile().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute quantiles of MLX arrays — mlx_quantile","text":"","code":"mlx_quantile(   x,   probs,   axis = NULL,   drop = FALSE,   device = mlx_default_device() )  # S3 method for class 'mlx' quantile(x, probs, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute quantiles of MLX arrays — mlx_quantile","text":"x mlx array, R array/matrix/vector converted via as_mlx(). probs Numeric vector probabilities [0, 1]. axis Optional integer axis (vector axes) along compute quantiles. NULL (default), quantiles computed entire flattened array. drop Logical; TRUE computing quantiles along axis single probability, removes quantile dimension length 1. Defaults FALSE match behavior reduction functions. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream). ... Additional arguments (currently ignored quantile.mlx()).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantile.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute quantiles of MLX arrays — mlx_quantile","text":"mlx array containing requested quantiles. shape depends probs, axis, drop: axis = NULL, returns scalar single probability vector multiple probabilities. axis specified, quantile dimension replaces reduced axis (e.g., (3, 4) matrix axis = 1 2 quantiles gives (2, 4)), unless drop = TRUE single probability removes dimension.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantile.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute quantiles of MLX arrays — mlx_quantile","text":"Uses type 7 quantiles (linear interpolation): probability p n observations, quantile computed : h = (n-1) * p Interpolate floor(h) ceiling(h) matches default behavior stats::quantile().","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantile.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute quantiles of MLX arrays — mlx_quantile","text":"","code":"x <- as_mlx(1:10) as.numeric(mlx_quantile(x, 0.5))  # median #> [1] 5.5 as.numeric(mlx_quantile(x, c(0.25, 0.5, 0.75)))  # quartiles #> [1] 3.25 5.50 7.75  # S3 method: quantile(x, probs = c(0, 0.25, 0.5, 0.75, 1)) #> mlx array [5] #>   dtype: float32 #>   device: gpu #>   values: #> [1]  1.00  3.25  5.50  7.75 10.00  # With axis parameter, quantile dimension replaces the reduced axis: mat <- as_mlx(matrix(1:12, 3, 4))  # shape (3, 4) result <- mlx_quantile(mat, c(0.25, 0.75), axis = 1)  # shape (2, 4) result <- mlx_quantile(mat, 0.5, axis = 1)  # shape (1, 4) result <- mlx_quantile(mat, 0.5, axis = 1, drop = TRUE)  # shape (4,)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantize.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantize a Matrix — mlx_quantize","title":"Quantize a Matrix — mlx_quantize","text":"Quantizes weight matrix low-precision representation (typically 4-bit 8-bit). reduces memory usage enables faster computation inference.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantize a Matrix — mlx_quantize","text":"","code":"mlx_quantize(   w,   group_size = 64L,   bits = 4L,   mode = \"affine\",   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantize a Matrix — mlx_quantize","text":"w mlx array (weight matrix quantize) group_size group size quantization. Smaller groups provide better accuracy slightly higher memory. Default: 64 bits number bits quantization (typically 4 8). Default: 4 mode quantization mode: \"affine\" (scales biases) \"mxfp4\" (4-bit floating point group_size=32). Default: \"affine\" device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quantize a Matrix — mlx_quantize","text":"list containing: w_q quantized weight matrix (packed uint32) scales quantization scales dequantization biases quantization biases (NULL symmetric mode)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantize.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Quantize a Matrix — mlx_quantize","text":"Quantization converts floating-point weights low-precision integers, reducing memory 8x 4-bit quantization. scales (optionally biases) stored enable approximate reconstruction original values.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantize a Matrix — mlx_quantize","text":"","code":"w <- mlx_rand_normal(c(64, 32)) quant <- mlx_quantize(w, group_size = 32, bits = 4) # Use quant$w_q, quant$scales, quant$biases with mlx_quantized_matmul()"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantized_matmul.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantized Matrix Multiplication — mlx_quantized_matmul","title":"Quantized Matrix Multiplication — mlx_quantized_matmul","text":"Performs matrix multiplication quantized weight matrix. operation essential efficient inference quantized models, significantly reducing memory usage computation time maintaining reasonable accuracy.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantized_matmul.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantized Matrix Multiplication — mlx_quantized_matmul","text":"","code":"mlx_quantized_matmul(   x,   w,   scales = NULL,   biases = NULL,   transpose = TRUE,   group_size = 64L,   bits = 4L,   mode = \"affine\",   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantized_matmul.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantized Matrix Multiplication — mlx_quantized_matmul","text":"x mlx array. w mlx array. Either: quantized weight matrix (uint32) mlx_quantize(), unquantized weight matrix quantized automatically scales optional mlx array (quantization scales). NULL w unquantized, w quantized automatically. Default: NULL biases optional mlx array (biases add). affine quantization, quantization biases w pre-quantized. Default: NULL transpose Whether transpose weight matrix. Default: TRUE group_size group size quantization. Default: 64 bits number bits quantization (typically 4 8). Default: 4 mode quantization mode, either \"affine\" \"mxfp4\". Default: \"affine\" device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantized_matmul.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quantized Matrix Multiplication — mlx_quantized_matmul","text":"mlx array result quantized matrix multiplication","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantized_matmul.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Quantized Matrix Multiplication — mlx_quantized_matmul","text":"Quantized matrix multiplication uses low-precision representations (typically 4-bit 8-bit integers) weights, reduces memory footprint 8x compared float32. scales parameter contains dequantization factors needed reconstruct approximate float values computation. group_size parameter controls granularity quantization - smaller groups provide better accuracy slightly higher memory usage. Automatic Quantization: w provided (without scales), function automatically quantize w using mlx_quantize() performing multiplication. repeated operations, efficient pre-quantize weights using mlx_quantize() reuse .","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_quantized_matmul.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantized Matrix Multiplication — mlx_quantized_matmul","text":"","code":"# Automatic quantization (convenient but slower for repeated use) x <- mlx_rand_normal(c(4, 64)) w <- mlx_rand_normal(c(128, 64)) result <- mlx_quantized_matmul(x, w, group_size = 32)  # Pre-quantized weights (faster for repeated operations) quant <- mlx_quantize(w, group_size = 32, bits = 4) result <- mlx_quantized_matmul(x, quant$w_q, quant$scales, quant$biases, group_size = 32)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_bernoulli.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample Bernoulli random variables on mlx arrays — mlx_rand_bernoulli","title":"Sample Bernoulli random variables on mlx arrays — mlx_rand_bernoulli","text":"Sample Bernoulli random variables mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_bernoulli.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample Bernoulli random variables on mlx arrays — mlx_rand_bernoulli","text":"","code":"mlx_rand_bernoulli(dim, prob = 0.5, device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_bernoulli.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample Bernoulli random variables on mlx arrays — mlx_rand_bernoulli","text":"dim Integer vector specifying array shape/dimensions. prob Probability one. device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_bernoulli.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample Bernoulli random variables on mlx arrays — mlx_rand_bernoulli","text":"mlx boolean array.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_bernoulli.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample Bernoulli random variables on mlx arrays — mlx_rand_bernoulli","text":"","code":"mask <- mlx_rand_bernoulli(c(4, 4), prob = 0.3)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_categorical.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from a categorical distribution on mlx arrays — mlx_rand_categorical","title":"Sample from a categorical distribution on mlx arrays — mlx_rand_categorical","text":"Samples indices categorical distributions. row (slice along specified axis) represents separate categorical distribution classes.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_categorical.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from a categorical distribution on mlx arrays — mlx_rand_categorical","text":"","code":"mlx_rand_categorical(logits, axis = NULL, num_samples = 1L)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_categorical.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from a categorical distribution on mlx arrays — mlx_rand_categorical","text":"logits matrix mlx array log-probabilities. values need normalized (function applies softmax internally). single distribution K classes, use 1×K matrix. multiple independent distributions, use N×K matrix row distribution. axis Axis (1-indexed) along sample. Omit argument use last dimension (typically class dimension). num_samples Number samples draw distribution.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_categorical.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from a categorical distribution on mlx arrays — mlx_rand_categorical","text":"mlx array integer indices (1-indexed) sampled categorical distributions.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_categorical.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample from a categorical distribution on mlx arrays — mlx_rand_categorical","text":"","code":"# Single distribution over 3 classes logits <- matrix(c(0.5, 0.2, 0.3), 1, 3) samples <- mlx_rand_categorical(logits, num_samples = 10)  # Multiple distributions logits <- matrix(c(1, 2, 3,                    3, 2, 1), nrow = 2, byrow = TRUE) samples <- mlx_rand_categorical(logits, num_samples = 5)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_gumbel.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from the Gumbel distribution on mlx arrays — mlx_rand_gumbel","title":"Sample from the Gumbel distribution on mlx arrays — mlx_rand_gumbel","text":"Sample Gumbel distribution mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_gumbel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from the Gumbel distribution on mlx arrays — mlx_rand_gumbel","text":"","code":"mlx_rand_gumbel(   dim,   dtype = c(\"float32\", \"float64\"),   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_gumbel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from the Gumbel distribution on mlx arrays — mlx_rand_gumbel","text":"dim Integer vector specifying array shape/dimensions. dtype Desired MLX dtype (\"float32\" \"float64\"). device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_gumbel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from the Gumbel distribution on mlx arrays — mlx_rand_gumbel","text":"mlx array Gumbel-distributed entries.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_gumbel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample from the Gumbel distribution on mlx arrays — mlx_rand_gumbel","text":"","code":"samples <- mlx_rand_gumbel(c(2, 3))"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_laplace.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from the Laplace distribution on mlx arrays — mlx_rand_laplace","title":"Sample from the Laplace distribution on mlx arrays — mlx_rand_laplace","text":"Sample Laplace distribution mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_laplace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from the Laplace distribution on mlx arrays — mlx_rand_laplace","text":"","code":"mlx_rand_laplace(   dim,   loc = 0,   scale = 1,   dtype = c(\"float32\", \"float64\"),   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_laplace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from the Laplace distribution on mlx arrays — mlx_rand_laplace","text":"dim Integer vector specifying array shape/dimensions. loc Location parameter (mean) Laplace distribution. scale Scale parameter (diversity) Laplace distribution. dtype Desired MLX dtype (\"float32\" \"float64\"). device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_laplace.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from the Laplace distribution on mlx arrays — mlx_rand_laplace","text":"mlx array Laplace-distributed entries.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_laplace.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample from the Laplace distribution on mlx arrays — mlx_rand_laplace","text":"","code":"samples <- mlx_rand_laplace(c(2, 3), loc = 0, scale = 1)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_multivariate_normal.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from a multivariate normal distribution on mlx arrays — mlx_rand_multivariate_normal","title":"Sample from a multivariate normal distribution on mlx arrays — mlx_rand_multivariate_normal","text":"Sample multivariate normal distribution mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_multivariate_normal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from a multivariate normal distribution on mlx arrays — mlx_rand_multivariate_normal","text":"","code":"mlx_rand_multivariate_normal(   dim,   mean,   cov,   dtype = c(\"float32\", \"float64\"),   device = \"cpu\" )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_multivariate_normal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from a multivariate normal distribution on mlx arrays — mlx_rand_multivariate_normal","text":"dim Integer vector specifying array shape/dimensions. mean mlx array vector mean. cov mlx array matrix covariance. dtype Desired MLX dtype (\"float32\" \"float64\"). device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_multivariate_normal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from a multivariate normal distribution on mlx arrays — mlx_rand_multivariate_normal","text":"mlx array samples multivariate normal.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_multivariate_normal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sample from a multivariate normal distribution on mlx arrays — mlx_rand_multivariate_normal","text":"Samples generated CPU: GPU execution currently unavailable covariance factorisation runs host. Supply CPU stream (via mlx_new_stream()) integrate asynchronous flows.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_multivariate_normal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample from a multivariate normal distribution on mlx arrays — mlx_rand_multivariate_normal","text":"","code":"mean <- as_mlx(c(0, 0), device = \"cpu\") cov <- as_mlx(matrix(c(1, 0, 0, 1), 2, 2), device = \"cpu\") samples <- mlx_rand_multivariate_normal(c(100, 2), mean, cov, device = \"cpu\")"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_normal.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from a normal distribution on mlx arrays — mlx_rand_normal","title":"Sample from a normal distribution on mlx arrays — mlx_rand_normal","text":"Sample normal distribution mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_normal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from a normal distribution on mlx arrays — mlx_rand_normal","text":"","code":"mlx_rand_normal(   dim,   mean = 0,   sd = 1,   dtype = c(\"float32\", \"float64\"),   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_normal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from a normal distribution on mlx arrays — mlx_rand_normal","text":"dim Integer vector specifying array shape/dimensions. mean Mean normal distribution. sd Standard deviation normal distribution. dtype Desired MLX dtype (\"float32\" \"float64\"). device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_normal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from a normal distribution on mlx arrays — mlx_rand_normal","text":"mlx array normally distributed entries.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_normal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample from a normal distribution on mlx arrays — mlx_rand_normal","text":"","code":"weights <- mlx_rand_normal(c(3, 3), mean = 0, sd = 0.1)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_permutation.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate random permutations on mlx arrays — mlx_rand_permutation","title":"Generate random permutations on mlx arrays — mlx_rand_permutation","text":"Generate random permutation integers permute entries array along specified axis.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_permutation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate random permutations on mlx arrays — mlx_rand_permutation","text":"","code":"mlx_rand_permutation(x, axis = 1L, device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_permutation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate random permutations on mlx arrays — mlx_rand_permutation","text":"x Either integer n (generate permutation 1:n), mlx array matrix permute. axis Axis (1-indexed) along permute x array. Default 1L (permute rows). device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_permutation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate random permutations on mlx arrays — mlx_rand_permutation","text":"mlx array containing random permutation.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_permutation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate random permutations on mlx arrays — mlx_rand_permutation","text":"x integer, result created specified device stream; otherwise permutation follows input array's device.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_permutation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate random permutations on mlx arrays — mlx_rand_permutation","text":"","code":"# Generate a random permutation of 1:10 perm <- mlx_rand_permutation(10)  # Permute the rows of a matrix mat <- matrix(1:12, 4, 3) perm_mat <- mlx_rand_permutation(mat)  # Permute columns instead perm_cols <- mlx_rand_permutation(mat, axis = 2)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_randint.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample random integers on mlx arrays — mlx_rand_randint","title":"Sample random integers on mlx arrays — mlx_rand_randint","text":"Generates random integers uniformly distributed interval [low, high).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_randint.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample random integers on mlx arrays — mlx_rand_randint","text":"","code":"mlx_rand_randint(   dim,   low,   high,   dtype = c(\"int32\", \"int64\", \"uint32\", \"uint64\"),   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_randint.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample random integers on mlx arrays — mlx_rand_randint","text":"dim Integer vector specifying array shape/dimensions. low Lower bound (inclusive). high Upper bound (exclusive). dtype Desired integer dtype (\"int32\", \"int64\", \"uint32\", \"uint64\"). device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_randint.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample random integers on mlx arrays — mlx_rand_randint","text":"mlx array random integers.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_randint.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample random integers on mlx arrays — mlx_rand_randint","text":"","code":"# Random integers from 0 to 9 samples <- mlx_rand_randint(c(3, 3), low = 0, high = 10)  # Random integers from -5 to 4 samples <- mlx_rand_randint(c(2, 5), low = -5, high = 5)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_truncated_normal.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from a truncated normal distribution on mlx arrays — mlx_rand_truncated_normal","title":"Sample from a truncated normal distribution on mlx arrays — mlx_rand_truncated_normal","text":"Sample truncated normal distribution mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_truncated_normal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from a truncated normal distribution on mlx arrays — mlx_rand_truncated_normal","text":"","code":"mlx_rand_truncated_normal(   lower,   upper,   dim,   dtype = c(\"float32\", \"float64\"),   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_truncated_normal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from a truncated normal distribution on mlx arrays — mlx_rand_truncated_normal","text":"lower Lower bound truncated normal. upper Upper bound truncated normal. dim Integer vector specifying array shape/dimensions. dtype Desired MLX dtype (\"float32\" \"float64\"). device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_truncated_normal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from a truncated normal distribution on mlx arrays — mlx_rand_truncated_normal","text":"mlx array truncated normally distributed entries.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_truncated_normal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample from a truncated normal distribution on mlx arrays — mlx_rand_truncated_normal","text":"","code":"samples <- mlx_rand_truncated_normal(-1, 1, c(5, 5))"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_uniform.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from a uniform distribution on mlx arrays — mlx_rand_uniform","title":"Sample from a uniform distribution on mlx arrays — mlx_rand_uniform","text":"Sample uniform distribution mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_uniform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from a uniform distribution on mlx arrays — mlx_rand_uniform","text":"","code":"mlx_rand_uniform(   dim,   min = 0,   max = 1,   dtype = c(\"float32\", \"float64\"),   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_uniform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from a uniform distribution on mlx arrays — mlx_rand_uniform","text":"dim Integer vector specifying array shape/dimensions. min Lower bound uniform distribution. max Upper bound uniform distribution. dtype Desired MLX dtype (\"float32\" \"float64\"). device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_uniform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from a uniform distribution on mlx arrays — mlx_rand_uniform","text":"mlx array whose entries sampled uniformly.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_rand_uniform.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample from a uniform distribution on mlx arrays — mlx_rand_uniform","text":"","code":"noise <- mlx_rand_uniform(c(2, 2), min = -1, max = 1)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_real.html","id":null,"dir":"Reference","previous_headings":"","what":"Complex-valued helpers for mlx arrays — mlx_real","title":"Complex-valued helpers for mlx arrays — mlx_real","text":"mlx_real(), mlx_imag(), mlx_conjugate() expose MLX's complex helpers extract real part, imaginary part, complex conjugate mlx array. Corresponding S3 methods Re(), Im(), Conj() also provided.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_real.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Complex-valued helpers for mlx arrays — mlx_real","text":"","code":"mlx_real(x)  mlx_imag(x)  mlx_conjugate(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_real.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Complex-valued helpers for mlx arrays — mlx_real","text":"x mlx array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_real.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Complex-valued helpers for mlx arrays — mlx_real","text":"mlx array containing requested component.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_real.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Complex-valued helpers for mlx arrays — mlx_real","text":"","code":"z <- as_mlx(1:4 + 1i * (4:1)) mlx_real(z) #> mlx array [4] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 1 2 3 4 Im(z) #> mlx array [4] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 4 3 2 1"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_reduction_base.html","id":null,"dir":"Reference","previous_headings":"","what":"Shared arguments for MLX/base reduction helpers. — mlx_reduction_base","title":"Shared arguments for MLX/base reduction helpers. — mlx_reduction_base","text":"Shared arguments MLX/base reduction helpers.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_reduction_base.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shared arguments for MLX/base reduction helpers. — mlx_reduction_base","text":"x array mlx array. na.rm Logical; currently ignored mlx arrays. dims Dimensions passed base implementation x mlx array. ... Additional arguments forwarded base implementation.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_relu.html","id":null,"dir":"Reference","previous_headings":"","what":"Rectified linear activation module — mlx_relu","title":"Rectified linear activation module — mlx_relu","text":"Rectified linear activation module","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_relu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rectified linear activation module — mlx_relu","text":"","code":"mlx_relu()"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_relu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rectified linear activation module — mlx_relu","text":"mlx_module applying ReLU.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_relu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rectified linear activation module — mlx_relu","text":"","code":"act <- mlx_relu() x <- as_mlx(matrix(c(-1, 0, 2), 3, 1)) mlx_forward(act, x) #> mlx array [3 x 1] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] #> [1,]    0 #> [2,]    0 #> [3,]    2"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_repeat.html","id":null,"dir":"Reference","previous_headings":"","what":"Repeat array elements — mlx_repeat","title":"Repeat array elements — mlx_repeat","text":"Repeat array elements","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_repeat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Repeat array elements — mlx_repeat","text":"","code":"mlx_repeat(x, repeats, axis = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_repeat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Repeat array elements — mlx_repeat","text":"x mlx array. repeats Number repetitions. axis Optional axis along repeat. NULL, array flattened repetition (matching NumPy semantics).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_repeat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Repeat array elements — mlx_repeat","text":"mlx array repeated values.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_repeat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Repeat array elements — mlx_repeat","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) mlx_repeat(x, repeats = 2, axis = 2) #> mlx array [2 x 4] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] [,4] #> [1,]    1    1    3    3 #> [2,]    2    2    4    4"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_reshape.html","id":null,"dir":"Reference","previous_headings":"","what":"Reshape an mlx array — mlx_reshape","title":"Reshape an mlx array — mlx_reshape","text":"Reshape mlx array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_reshape.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reshape an mlx array — mlx_reshape","text":"","code":"mlx_reshape(x, newshape)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_reshape.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reshape an mlx array — mlx_reshape","text":"x mlx array. newshape Integer vector specifying new dimensions.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_reshape.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reshape an mlx array — mlx_reshape","text":"mlx array specified shape.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_reshape.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reshape an mlx array — mlx_reshape","text":"","code":"x <- as_mlx(1:12) mlx_reshape(x, c(3, 4)) #> mlx array [3 x 4] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] [,4] #> [1,]    1    2    3    4 #> [2,]    5    6    7    8 #> [3,]    9   10   11   12 mlx_reshape(x, c(2, 6)) #> mlx array [2 x 6] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] [,4] [,5] [,6] #> [1,]    1    2    3    4    5    6 #> [2,]    7    8    9   10   11   12"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_roll.html","id":null,"dir":"Reference","previous_headings":"","what":"Roll array elements — mlx_roll","title":"Roll array elements — mlx_roll","text":"Roll array elements","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_roll.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Roll array elements — mlx_roll","text":"","code":"mlx_roll(x, shift, axes = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_roll.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Roll array elements — mlx_roll","text":"x mlx array. shift Integer vector giving number places elements shifted. axes Optional integer vector (1-indexed) along elements shifted. NULL, array flattened shifted.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_roll.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Roll array elements — mlx_roll","text":"mlx array elements circularly shifted.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_roll.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Roll array elements — mlx_roll","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) mlx_roll(x, shift = 1, axes = 2) #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]    3    1 #> [2,]    4    2"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_save.html","id":null,"dir":"Reference","previous_headings":"","what":"Save an MLX array to disk — mlx_save","title":"Save an MLX array to disk — mlx_save","text":"Persists MLX array .npy file using MLX's native serialization.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_save.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save an MLX array to disk — mlx_save","text":"","code":"mlx_save(x, file)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_save.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save an MLX array to disk — mlx_save","text":"x Object coercible mlx. file Path output file. file end .npy, extension appended automatically.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_save.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save an MLX array to disk — mlx_save","text":"Invisibly returns full path written, including .npy suffix.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_save.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Save an MLX array to disk — mlx_save","text":"","code":"path <- tempfile(fileext = \".mlx\") mlx_save(as_mlx(matrix(1:4, 2, 2), device = \"cpu\"), path) restored <- mlx_load(path, device = \"cpu\")"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_save_gguf.html","id":null,"dir":"Reference","previous_headings":"","what":"Save MLX arrays to the GGUF format — mlx_save_gguf","title":"Save MLX arrays to the GGUF format — mlx_save_gguf","text":"Save MLX arrays GGUF format","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_save_gguf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save MLX arrays to the GGUF format — mlx_save_gguf","text":"","code":"mlx_save_gguf(file, arrays, metadata = list())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_save_gguf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save MLX arrays to the GGUF format — mlx_save_gguf","text":"file Output path. .safetensors appended automatically omitted. arrays Named list objects coercible mlx. metadata Optional named list describing GGUF metadata. Values may character vectors mlx arrays.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_save_gguf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save MLX arrays to the GGUF format — mlx_save_gguf","text":"Invisibly returns full path written.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_save_safetensors.html","id":null,"dir":"Reference","previous_headings":"","what":"Save MLX arrays to the safetensors format — mlx_save_safetensors","title":"Save MLX arrays to the safetensors format — mlx_save_safetensors","text":"Save MLX arrays safetensors format","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_save_safetensors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save MLX arrays to the safetensors format — mlx_save_safetensors","text":"","code":"mlx_save_safetensors(file, arrays, metadata = character())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_save_safetensors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save MLX arrays to the safetensors format — mlx_save_safetensors","text":"file Output path. .safetensors appended automatically omitted. arrays Named list objects coercible mlx. metadata Optional named character vector metadata entries.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_save_safetensors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save MLX arrays to the safetensors format — mlx_save_safetensors","text":"Invisibly returns full path written.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_scalar.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct MLX scalars — mlx_scalar","title":"Construct MLX scalars — mlx_scalar","text":"Construct MLX scalars","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_scalar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct MLX scalars — mlx_scalar","text":"","code":"mlx_scalar(value, dtype = NULL, device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_scalar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct MLX scalars — mlx_scalar","text":"value Single value (numeric, logical, complex). dtype Optional MLX dtype. Defaults \"float32\" numeric input, \"bool\" logical, \"complex64\" complex. device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_scalar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct MLX scalars — mlx_scalar","text":"dimensionless mlx scalar.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sequential.html","id":null,"dir":"Reference","previous_headings":"","what":"Compose modules sequentially — mlx_sequential","title":"Compose modules sequentially — mlx_sequential","text":"Compose modules sequentially","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sequential.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compose modules sequentially — mlx_sequential","text":"","code":"mlx_sequential(...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sequential.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compose modules sequentially — mlx_sequential","text":"... Modules compose.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sequential.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compose modules sequentially — mlx_sequential","text":"mlx_module.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sequential.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compose modules sequentially — mlx_sequential","text":"","code":"set.seed(1) net <- mlx_sequential(mlx_linear(2, 3), mlx_relu(), mlx_linear(3, 1)) input <- as_mlx(matrix(c(1, 2), 1, 2)) mlx_forward(net, input) #> mlx array [1 x 1] #>   dtype: float32 #>   device: gpu #>   values: #>          [,1] #> [1,] 1.419647"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_set_default_stream.html","id":null,"dir":"Reference","previous_headings":"","what":"Set the default MLX stream — mlx_set_default_stream","title":"Set the default MLX stream — mlx_set_default_stream","text":"Set default MLX stream","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_set_default_stream.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set the default MLX stream — mlx_set_default_stream","text":"","code":"mlx_set_default_stream(stream)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_set_default_stream.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set the default MLX stream — mlx_set_default_stream","text":"stream object created mlx_new_stream() mlx_default_stream().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_set_default_stream.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set the default MLX stream — mlx_set_default_stream","text":"Invisibly returns stream.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_set_default_stream.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set the default MLX stream — mlx_set_default_stream","text":"","code":"stream <- mlx_new_stream() old <- mlx_default_stream() mlx_set_default_stream(stream) mlx_set_default_stream(old)  # restore"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_set_training.html","id":null,"dir":"Reference","previous_headings":"","what":"Toggle training mode for MLX modules — mlx_set_training","title":"Toggle training mode for MLX modules — mlx_set_training","text":"mlx_set_training() switches modules training evaluation modes. Layers implement training-specific behaviour ignore call.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_set_training.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Toggle training mode for MLX modules — mlx_set_training","text":"","code":"mlx_set_training(module, mode = TRUE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_set_training.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Toggle training mode for MLX modules — mlx_set_training","text":"module object inheriting mlx_module. mode Logical flag; TRUE training mode, FALSE evaluation.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_set_training.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Toggle training mode for MLX modules — mlx_set_training","text":"input module (invisibly).","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_set_training.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Toggle training mode for MLX modules — mlx_set_training","text":"","code":"model <- mlx_sequential(mlx_linear(2, 4), mlx_dropout(0.5)) mlx_set_training(model, FALSE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sigmoid.html","id":null,"dir":"Reference","previous_headings":"","what":"Sigmoid activation — mlx_sigmoid","title":"Sigmoid activation — mlx_sigmoid","text":"Sigmoid activation","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sigmoid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sigmoid activation — mlx_sigmoid","text":"","code":"mlx_sigmoid()"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sigmoid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sigmoid activation — mlx_sigmoid","text":"mlx_module applying sigmoid activation.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sigmoid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sigmoid activation — mlx_sigmoid","text":"","code":"act <- mlx_sigmoid() x <- as_mlx(matrix(c(-2, -1, 0, 1, 2), 5, 1)) mlx_forward(act, x) #> mlx array [5 x 1] #>   dtype: float32 #>   device: gpu #>   values: #>           [,1] #> [1,] 0.1192029 #> [2,] 0.2689414 #> [3,] 0.5000000 #> [4,] 0.7310586 #> [5,] 0.8807970"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_silu.html","id":null,"dir":"Reference","previous_headings":"","what":"SiLU (Swish) activation — mlx_silu","title":"SiLU (Swish) activation — mlx_silu","text":"Sigmoid Linear Unit, also known Swish activation.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_silu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"SiLU (Swish) activation — mlx_silu","text":"","code":"mlx_silu()"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_silu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"SiLU (Swish) activation — mlx_silu","text":"mlx_module applying SiLU activation.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_silu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"SiLU (Swish) activation — mlx_silu","text":"","code":"act <- mlx_silu() x <- as_mlx(matrix(c(-2, -1, 0, 1, 2), 5, 1)) mlx_forward(act, x) #> mlx array [5 x 1] #>   dtype: float32 #>   device: gpu #>   values: #>            [,1] #> [1,] -0.2384058 #> [2,] -0.2689414 #> [3,]  0.0000000 #> [4,]  0.7310586 #> [5,]  1.7615941"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_slice_update.html","id":null,"dir":"Reference","previous_headings":"","what":"Update a slice of an mlx array — mlx_slice_update","title":"Update a slice of an mlx array — mlx_slice_update","text":"Wrapper around mlx.core.slice_update() replaces contiguous strided region value.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_slice_update.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update a slice of an mlx array — mlx_slice_update","text":"","code":"mlx_slice_update(x, value, start, stop, strides = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_slice_update.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update a slice of an mlx array — mlx_slice_update","text":"x mlx array. value Replacement mlx (coercible) array. Must broadcast slice determined start, stop, strides. start Integer vector (1-indexed) giving inclusive starting index axis. stop Integer vector (1-indexed) giving inclusive stopping index axis. strides Optional integer vector strides (defaults ones).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_slice_update.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update a slice of an mlx array — mlx_slice_update","text":"mlx array specified slice replaced.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_slice_update.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Update a slice of an mlx array — mlx_slice_update","text":"","code":"x <- as_mlx(matrix(1:9, 3, 3)) replacement <- as_mlx(matrix(100:103, nrow = 2)) updated <- mlx_slice_update(x, replacement, start = c(1L, 2L), stop = c(2L, 3L)) as.matrix(updated) #>      [,1] [,2] [,3] #> [1,]    1  100  102 #> [2,]    2  101  103 #> [3,]    3    6    9"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_softmax.html","id":null,"dir":"Reference","previous_headings":"","what":"Softmax for mlx arrays — mlx_softmax","title":"Softmax for mlx arrays — mlx_softmax","text":"Softmax mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_softmax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Softmax for mlx arrays — mlx_softmax","text":"","code":"mlx_softmax(x, axes = NULL, precise = FALSE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_softmax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Softmax for mlx arrays — mlx_softmax","text":"x mlx array, R array/matrix/vector converted via as_mlx(). axes Integer vector axes (1-indexed). Supply positive integers 1 array rank. Many helpers interpret NULL mean \"axes\"—see function details specifics. precise Logical; compute higher precision stability.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_softmax.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Softmax for mlx arrays — mlx_softmax","text":"mlx array normalized probabilities.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_softmax.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Softmax for mlx arrays — mlx_softmax","text":"","code":"x <- as_mlx(matrix(c(1, 2, 3, 4, 5, 6), 2, 3)) sm <- mlx_softmax(x, axes = 2) rowSums(as.matrix(sm)) #> [1] 1 1"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_softmax_layer.html","id":null,"dir":"Reference","previous_headings":"","what":"Softmax activation — mlx_softmax_layer","title":"Softmax activation — mlx_softmax_layer","text":"Softmax activation","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_softmax_layer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Softmax activation — mlx_softmax_layer","text":"","code":"mlx_softmax_layer(axis = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_softmax_layer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Softmax activation — mlx_softmax_layer","text":"axis Axis (1-indexed) along apply softmax. Omit argument use last dimension runtime.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_softmax_layer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Softmax activation — mlx_softmax_layer","text":"mlx_module applying softmax activation.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_softmax_layer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Softmax activation — mlx_softmax_layer","text":"","code":"act <- mlx_softmax_layer() x <- as_mlx(matrix(1:6, 2, 3)) mlx_forward(act, x) #> mlx array [2 x 3] #>   dtype: float32 #>   device: gpu #>   values: #>            [,1]      [,2]      [,3] #> [1,] 0.01587624 0.1173104 0.8668134 #> [2,] 0.01587624 0.1173104 0.8668134"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_solve_triangular.html","id":null,"dir":"Reference","previous_headings":"","what":"Solve triangular systems with mlx arrays — mlx_solve_triangular","title":"Solve triangular systems with mlx arrays — mlx_solve_triangular","text":"Solve triangular systems mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_solve_triangular.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solve triangular systems with mlx arrays — mlx_solve_triangular","text":"","code":"mlx_solve_triangular(a, b, upper = FALSE)  backsolve(r, x, k = NULL, upper.tri = TRUE, transpose = FALSE, ...)  # Default S3 method backsolve(r, x, k = NULL, upper.tri = TRUE, transpose = FALSE, ...)  # S3 method for class 'mlx' backsolve(r, x, k = NULL, upper.tri = TRUE, transpose = FALSE, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_solve_triangular.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solve triangular systems with mlx arrays — mlx_solve_triangular","text":"mlx triangular matrix. b Right-hand side matrix vector. upper Logical; TRUE, upper triangular, otherwise lower. r Triangular system matrix passed backsolve(). x Right-hand side supplied backsolve(). k Number columns r use. upper.tri Logical; indicates r upper triangular. transpose Logical; TRUE, solve t(r) %*% x = b. ... Additional arguments forwarded base::backsolve().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_solve_triangular.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solve triangular systems with mlx arrays — mlx_solve_triangular","text":"mlx array solution.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_solve_triangular.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Solve triangular systems with mlx arrays — mlx_solve_triangular","text":"","code":"a <- as_mlx(matrix(c(2, 1, 0, 3), 2, 2)) b <- as_mlx(matrix(c(1, 5), 2, 1)) mlx_solve_triangular(a, b, upper = FALSE) #> mlx array [2 x 1] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] #> [1,]  0.5 #> [2,]  1.5"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sort.html","id":null,"dir":"Reference","previous_headings":"","what":"Sort and argsort for mlx arrays — mlx_sort","title":"Sort and argsort for mlx arrays — mlx_sort","text":"mlx_sort() returns sorted values along specified axis. mlx_argsort() returns indices sort array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sort.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sort and argsort for mlx arrays — mlx_sort","text":"","code":"mlx_sort(x, axis = NULL)  mlx_argsort(x, axis = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sort.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sort and argsort for mlx arrays — mlx_sort","text":"x mlx array, R array/matrix/vector converted via as_mlx(). axis Single axis (1-indexed). Supply positive integer 1 array rank. Use NULL helper interprets \"axes\" (see individual docs).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sort.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sort and argsort for mlx arrays — mlx_sort","text":"mlx array containing sorted values (mlx_sort()) 1-based indices (mlx_argsort()). indices follow R's indexing convention can used directly R's [ operator.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sort.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sort and argsort for mlx arrays — mlx_sort","text":"mlx_argsort() returns 1-based indices sort array ascending order. follows R's indexing convention (unlike underlying MLX library uses 0-based indexing). returned indices can used directly reorder original array. partial sorting (finding elements certain rank without fully sorting), see mlx_partition() mlx_argpartition().","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sort.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sort and argsort for mlx arrays — mlx_sort","text":"","code":"x <- as_mlx(c(3, 1, 4, 2)) mlx_sort(x) #> mlx array [4] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 1 2 3 4  # Returns 1-based indices idx <- mlx_argsort(x) as.integer(as.matrix(idx))  # [1] 2 4 1 3 #> [1] 2 4 1 3  # Can be used directly with R indexing original <- c(3, 1, 4, 2) sorted_idx <- as.integer(as.matrix(mlx_argsort(as_mlx(original)))) original[sorted_idx]  # [1] 1 2 3 4 #> [1] 1 2 3 4  mlx_sort(as_mlx(matrix(1:6, 2, 3)), axis = 1) #> mlx array [2 x 3] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] #> [1,]    1    3    5 #> [2,]    2    4    6"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_squeeze.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove singleton dimensions — mlx_squeeze","title":"Remove singleton dimensions — mlx_squeeze","text":"Remove singleton dimensions","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_squeeze.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove singleton dimensions — mlx_squeeze","text":"","code":"mlx_squeeze(x, axes = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_squeeze.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove singleton dimensions — mlx_squeeze","text":"x mlx array. axes Optional integer vector axes (1-indexed) remove. NULL axes length one removed.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_squeeze.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove singleton dimensions — mlx_squeeze","text":"mlx array selected axes removed.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_squeeze.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove singleton dimensions — mlx_squeeze","text":"","code":"x <- as_mlx(array(1:4, dim = c(1, 2, 2, 1))) mlx_squeeze(x) #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]    1    3 #> [2,]    2    4 mlx_squeeze(x, axes = 1) #> mlx array [2 x 2 x 1] #>   dtype: float32 #>   device: gpu #>   (4 elements, not shown)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_stack.html","id":null,"dir":"Reference","previous_headings":"","what":"Stack mlx arrays along a new axis — mlx_stack","title":"Stack mlx arrays along a new axis — mlx_stack","text":"Stack mlx arrays along new axis","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_stack.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stack mlx arrays along a new axis — mlx_stack","text":"","code":"mlx_stack(..., axis = 1L)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_stack.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stack mlx arrays along a new axis — mlx_stack","text":"... One arrays (single list arrays) coercible mlx. axis Position new axis (1-indexed). Supply values 1 length(dim(x)) + 1 insert anywhere along dimension list.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_stack.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stack mlx arrays along a new axis — mlx_stack","text":"mlx array one additional dimension.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_stack.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stack mlx arrays along a new axis — mlx_stack","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) y <- as_mlx(matrix(5:8, 2, 2)) stacked <- mlx_stack(x, y, axis = 1)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_stop_gradient.html","id":null,"dir":"Reference","previous_headings":"","what":"Stop gradient propagation through an mlx array — mlx_stop_gradient","title":"Stop gradient propagation through an mlx array — mlx_stop_gradient","text":"Stop gradient propagation mlx array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_stop_gradient.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stop gradient propagation through an mlx array — mlx_stop_gradient","text":"","code":"mlx_stop_gradient(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_stop_gradient.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stop gradient propagation through an mlx array — mlx_stop_gradient","text":"x mlx array, R array/matrix/vector converted via as_mlx().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_stop_gradient.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stop gradient propagation through an mlx array — mlx_stop_gradient","text":"new mlx array identical values zero gradient.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_stop_gradient.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stop gradient propagation through an mlx array — mlx_stop_gradient","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) mlx_stop_gradient(x) #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]    1    3 #> [2,]    2    4"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_subset.html","id":null,"dir":"Reference","previous_headings":"","what":"Subset MLX array — mlx_subset","title":"Subset MLX array — mlx_subset","text":"MLX subsetting mirrors base R common cases avoiding language's historical footguns:","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_subset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subset MLX array — mlx_subset","text":"","code":"# S3 method for class 'mlx' x[..., drop = FALSE]  # S3 method for class 'mlx' x[...] <- value"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_subset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subset MLX array — mlx_subset","text":"x mlx array, R array/matrix/vector converted via as_mlx(). ... Indices dimension. Provide one per axis; omitted indices select full extent. Logical indices recycle dimension length. drop dimensions dropped? (default: FALSE) value Replacement value(s) \\code{[<-} (scalar, vector, matrix, array) recycled match selection.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_subset.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Subset MLX array — mlx_subset","text":"Subsetted mlx object","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_subset.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Subset MLX array — mlx_subset","text":"Numeric indices: positive (1-based) purely negative vectors supported. Negative indices drop listed elements, just base R. Mixing signs error 0 allowed. Logical indices: recycled target dimension length. Logical masks may mixed numeric indices across dimensions. Matrices/arrays: numeric matrices (higher dimensional arrays) select individual elements, one coordinate per row. trailing dimension must match array rank entries must positive; negative matrices rejected avoid ambiguous complements. mlx indices: mlx vectors, logical masks, matrices behave R equivalents. One-dimensional MLX arrays treated vectors rather 1-column matrices. drop: dimensions preserved default (drop = FALSE), matching package's preference explicit shapes. Unsupported: character indices named lookups implemented.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_subset.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Subset MLX array — mlx_subset","text":"","code":"x <- as_mlx(matrix(1:9, 3, 3)) x[1, ] #> mlx array [1 x 3] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] #> [1,]    1    4    7"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sum.html","id":null,"dir":"Reference","previous_headings":"","what":"Reduce mlx arrays — mlx_sum","title":"Reduce mlx arrays — mlx_sum","text":"helpers mirror NumPy-style reductions, optionally collapsing one axes. Use drop = FALSE retain reduced axes length one (akin setting drop = FALSE base R).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reduce mlx arrays — mlx_sum","text":"","code":"mlx_sum(x, axes = NULL, drop = TRUE)  mlx_prod(x, axes = NULL, drop = TRUE)  mlx_all(x, axes = NULL, drop = TRUE)  mlx_any(x, axes = NULL, drop = TRUE)  mlx_mean(x, axes = NULL, drop = TRUE)  mlx_var(x, axes = NULL, drop = TRUE, ddof = 0L)  mlx_std(x, axes = NULL, drop = TRUE, ddof = 0L)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reduce mlx arrays — mlx_sum","text":"x mlx array, R array/matrix/vector converted via as_mlx(). axes Integer vector axes (1-indexed). Supply positive integers 1 array rank. Many helpers interpret NULL mean \"axes\"—see function details specifics. drop TRUE (default), drop dimensions length 1. FALSE, retain dimensions. Equivalent keepdims = TRUE underlying mlx functions. ddof Non-negative integer delta degrees freedom variance standard deviation reductions.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reduce mlx arrays — mlx_sum","text":"mlx array containing reduction result.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sum.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reduce mlx arrays — mlx_sum","text":"mlx_all() mlx_any() return mlx boolean scalars, base R reducers () () applied mlx inputs return plain logical scalars.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_sum.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reduce mlx arrays — mlx_sum","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) mlx_sum(x) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 10 mlx_sum(x, axes = 1) #> mlx array [2] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 3 7 mlx_prod(x, axes = 2, drop = FALSE) #> mlx array [2 x 1] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] #> [1,]    3 #> [2,]    8 mlx_all(x > 0) #> mlx array [] #>   dtype: bool #>   device: gpu #>   values: #> [1] TRUE mlx_any(x > 3) #> mlx array [] #>   dtype: bool #>   device: gpu #>   values: #> [1] TRUE mlx_mean(x, axes = 1) #> mlx array [2] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 1.5 3.5 mlx_var(x, axes = 2) #> mlx array [2] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 1 1 mlx_std(x, ddof = 1) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 1.290994"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_swapaxes.html","id":null,"dir":"Reference","previous_headings":"","what":"Swap two axes of an mlx array — mlx_swapaxes","title":"Swap two axes of an mlx array — mlx_swapaxes","text":"mlx_swapaxes() mirrors mlx.core.swapaxes(), exchanging two dimensions leaving others intact.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_swapaxes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Swap two axes of an mlx array — mlx_swapaxes","text":"","code":"mlx_swapaxes(x, axis1, axis2)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_swapaxes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Swap two axes of an mlx array — mlx_swapaxes","text":"x mlx array. axis1, axis2 Axes swap (1-indexed).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_swapaxes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Swap two axes of an mlx array — mlx_swapaxes","text":"mlx array specified axes exchanged.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_swapaxes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Swap two axes of an mlx array — mlx_swapaxes","text":"","code":"x <- as_mlx(array(1:24, dim = c(2, 3, 4))) swapped <- mlx_swapaxes(x, axis1 = 1, axis2 = 3) dim(swapped) #> [1] 4 3 2"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_synchronize.html","id":null,"dir":"Reference","previous_headings":"","what":"Synchronize MLX execution — mlx_synchronize","title":"Synchronize MLX execution — mlx_synchronize","text":"Waits outstanding operations specified device stream complete.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_synchronize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Synchronize MLX execution — mlx_synchronize","text":"","code":"mlx_synchronize(device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_synchronize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Synchronize MLX execution — mlx_synchronize","text":"device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_synchronize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Synchronize MLX execution — mlx_synchronize","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) mlx_synchronize(\"gpu\") stream <- mlx_new_stream() mlx_synchronize(stream)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tanh.html","id":null,"dir":"Reference","previous_headings":"","what":"Tanh activation — mlx_tanh","title":"Tanh activation — mlx_tanh","text":"Tanh activation","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tanh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tanh activation — mlx_tanh","text":"","code":"mlx_tanh()"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tanh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tanh activation — mlx_tanh","text":"mlx_module applying hyperbolic tangent activation.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tanh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tanh activation — mlx_tanh","text":"","code":"act <- mlx_tanh() x <- as_mlx(matrix(c(-2, -1, 0, 1, 2), 5, 1)) mlx_forward(act, x) #> mlx array [5 x 1] #>   dtype: float32 #>   device: gpu #>   values: #>            [,1] #> [1,] -0.9640276 #> [2,] -0.7615941 #> [3,]  0.0000000 #> [4,]  0.7615941 #> [5,]  0.9640276"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tile.html","id":null,"dir":"Reference","previous_headings":"","what":"Tile an array — mlx_tile","title":"Tile an array — mlx_tile","text":"Tile array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tile an array — mlx_tile","text":"","code":"mlx_tile(x, reps)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tile an array — mlx_tile","text":"x mlx array. reps Integer vector giving number repetitions axis.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tile.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tile an array — mlx_tile","text":"mlx array tiled content.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tile.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tile an array — mlx_tile","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) mlx_tile(x, reps = c(1, 2)) #> mlx array [2 x 4] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] [,4] #> [1,]    1    3    1    3 #> [2,]    2    4    2    4"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_topk.html","id":null,"dir":"Reference","previous_headings":"","what":"Top-k selection and partitioning on mlx arrays — mlx_topk","title":"Top-k selection and partitioning on mlx arrays — mlx_topk","text":"mlx_topk() returns largest k values. mlx_partition() mlx_argpartition() perform partial sorting, rearranging elements element position kth correctly sorted position, smaller elements larger elements . efficient full sorting need elements certain rank.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_topk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Top-k selection and partitioning on mlx arrays — mlx_topk","text":"","code":"mlx_topk(x, k, axis = NULL)  mlx_partition(x, kth, axis = NULL)  mlx_argpartition(x, kth, axis = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_topk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Top-k selection and partitioning on mlx arrays — mlx_topk","text":"x mlx array, R array/matrix/vector converted via as_mlx(). k Positive integer specifying number elements select. axis Single axis (1-indexed). Supply positive integer 1 array rank. Use NULL helper interprets \"axes\" (see individual docs). kth Zero-based index element placed -order partitioning.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_topk.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Top-k selection and partitioning on mlx arrays — mlx_topk","text":"mlx array. mlx_argpartition(), returns 1-based indices (following R conventions) showing partition ordering.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_topk.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Top-k selection and partitioning on mlx arrays — mlx_topk","text":"mlx_topk() returns largest k values along specified axis. mlx_partition() rearranges elements kth element correctly positioned. mlx_argpartition() returns 1-based indices partition array. follows R's indexing convention (unlike underlying MLX library uses 0-based indexing). Use mlx_argsort() need fully sorted indices.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_topk.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Top-k selection and partitioning on mlx arrays — mlx_topk","text":"","code":"scores <- as_mlx(c(0.7, 0.2, 0.9, 0.4)) mlx_topk(scores, k = 2) #> mlx array [2] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 0.7 0.9 mlx_partition(scores, kth = 1) #> mlx array [4] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 0.2 0.4 0.7 0.9  # Returns 1-based indices idx <- mlx_argpartition(scores, kth = 1) as.integer(as.matrix(idx))  # 1-based indices #> [1] 2 4 1 3  mlx_topk(as_mlx(matrix(1:6, 2, 3)), k = 1, axis = 1) #> mlx array [1 x 3] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] #> [1,]    2    4    6"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_trace.html","id":null,"dir":"Reference","previous_headings":"","what":"Matrix trace for mlx arrays — mlx_trace","title":"Matrix trace for mlx arrays — mlx_trace","text":"Computes sum diagonal elements 2D array, sum along diagonals higher dimensional array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_trace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matrix trace for mlx arrays — mlx_trace","text":"","code":"mlx_trace(x, offset = 0L, axis1 = 1L, axis2 = 2L)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_trace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matrix trace for mlx arrays — mlx_trace","text":"x mlx array. offset Offset diagonal (0 main diagonal, positive , negative ). axis1, axis2 Axes along diagonals taken (1-indexed, default 1 2).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_trace.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Matrix trace for mlx arrays — mlx_trace","text":"mlx scalar array containing trace.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_trace.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Matrix trace for mlx arrays — mlx_trace","text":"","code":"x <- as_mlx(matrix(1:9, 3, 3)) mlx_trace(x) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 15 mlx_trace(x, offset = 1) #> mlx array [] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 12"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_train_step.html","id":null,"dir":"Reference","previous_headings":"","what":"Single training step helper — mlx_train_step","title":"Single training step helper — mlx_train_step","text":"Single training step helper","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_train_step.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Single training step helper — mlx_train_step","text":"","code":"mlx_train_step(module, loss_fn, optimizer, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_train_step.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Single training step helper — mlx_train_step","text":"module mlx_module. loss_fn Function module data returning mlx scalar. optimizer Optimizer object mlx_optimizer_sgd(). ... Additional data passed loss_fn.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_train_step.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Single training step helper — mlx_train_step","text":"list current loss.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_train_step.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Single training step helper — mlx_train_step","text":"","code":"set.seed(1) model <- mlx_linear(2, 1, bias = FALSE) opt <- mlx_optimizer_sgd(mlx_parameters(model), lr = 0.1) data_x <- as_mlx(matrix(c(1, 2, 3, 4), 2, 2)) data_y <- as_mlx(matrix(c(5, 6), 2, 1)) loss_fn <- function(model, x, y) {   pred <- model$forward(x)   mean((pred - y)^2) } result <- mlx_train_step(model, loss_fn, opt, data_x, data_y)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tri.html","id":null,"dir":"Reference","previous_headings":"","what":"Triangular helpers for MLX arrays — mlx_tri","title":"Triangular helpers for MLX arrays — mlx_tri","text":"mlx_tri() creates lower-triangular mask (ones diagonal, zeros elsewhere). mlx_tril() mlx_triu() retain lower upper triangular part existing array, respectively.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tri.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Triangular helpers for MLX arrays — mlx_tri","text":"","code":"mlx_tri(   n,   m = NULL,   k = 0L,   dtype = c(\"float32\", \"float64\"),   device = mlx_default_device() )  mlx_tril(x, k = 0L)  mlx_triu(x, k = 0L)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tri.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Triangular helpers for MLX arrays — mlx_tri","text":"n Number rows. m Optional number columns (defaults n square output). k Diagonal offset: 0 selects main diagonal, positive values move upper diagonals, negative values lower diagonals. dtype MLX dtype use (\"float32\" \"float64\"). device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device(). x Object coercible mlx.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tri.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Triangular helpers for MLX arrays — mlx_tri","text":"mlx array.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tri.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Triangular helpers for MLX arrays — mlx_tri","text":"","code":"mlx_tri(3)          # 3x3 lower-triangular mask #> mlx array [3 x 3] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] #> [1,]    1    0    0 #> [2,]    1    1    0 #> [3,]    1    1    1 mlx_tril(diag(3) + 2)  # keep lower part of a matrix #> mlx array [3 x 3] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] [,3] #> [1,]    3    0    0 #> [2,]    2    3    0 #> [3,]    2    2    3"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tri_inv.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute triangular matrix inverse — mlx_tri_inv","title":"Compute triangular matrix inverse — mlx_tri_inv","text":"Computes inverse triangular matrix.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tri_inv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute triangular matrix inverse — mlx_tri_inv","text":"","code":"mlx_tri_inv(x, upper = FALSE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tri_inv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute triangular matrix inverse — mlx_tri_inv","text":"x mlx array. upper Logical; TRUE, x upper triangular, otherwise lower triangular.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tri_inv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute triangular matrix inverse — mlx_tri_inv","text":"inverse triangular matrix x.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_tri_inv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute triangular matrix inverse — mlx_tri_inv","text":"","code":"# Lower triangular matrix L <- as_mlx(matrix(c(1, 2, 0, 3, 0, 0, 4, 5, 6), 3, 3, byrow = TRUE)) L_inv <- mlx_tri_inv(L, upper = FALSE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_unflatten.html","id":null,"dir":"Reference","previous_headings":"","what":"Unflatten an axis into multiple axes — mlx_unflatten","title":"Unflatten an axis into multiple axes — mlx_unflatten","text":"reverse flattening: expands single axis multiple axes given shape.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_unflatten.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unflatten an axis into multiple axes — mlx_unflatten","text":"","code":"mlx_unflatten(x, axis, shape)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_unflatten.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unflatten an axis into multiple axes — mlx_unflatten","text":"x mlx array. axis axis unflatten (1-indexed). shape Integer vector specifying new shape unflattened axis.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_unflatten.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unflatten an axis into multiple axes — mlx_unflatten","text":"mlx array axis expanded.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_unflatten.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unflatten an axis into multiple axes — mlx_unflatten","text":"","code":"# Flatten and unflatten x <- as_mlx(array(1:24, c(2, 3, 4))) x_flat <- mlx_reshape(x, c(2, 12))  # flatten last two dims mlx_unflatten(x_flat, axis = 2, shape = c(3, 4))  # restore original shape #> mlx array [2 x 3 x 4] #>   dtype: float32 #>   device: gpu #>   (24 elements, not shown)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_vector.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct MLX vectors — mlx_vector","title":"Construct MLX vectors — mlx_vector","text":"mlx_vector() convenience around mlx_array() 1-D payloads.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_vector.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct MLX vectors — mlx_vector","text":"","code":"mlx_vector(data, dtype = NULL, device = mlx_default_device())"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_vector.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct MLX vectors — mlx_vector","text":"data Atomic vector providing elements (recycling allowed). dtype Optional MLX dtype. Defaults \"float32\" numeric input, \"bool\" logical, \"complex64\" complex. device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_vector.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct MLX vectors — mlx_vector","text":"mlx vector dim = length(data).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_where.html","id":null,"dir":"Reference","previous_headings":"","what":"Elementwise conditional selection — mlx_where","title":"Elementwise conditional selection — mlx_where","text":"Elementwise conditional selection","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_where.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Elementwise conditional selection — mlx_where","text":"","code":"mlx_where(condition, x, y)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_where.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Elementwise conditional selection — mlx_where","text":"condition Logical mlx array (non-zero values treated TRUE). x, y Arrays broadcastable shape condition.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_where.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Elementwise conditional selection — mlx_where","text":"mlx array elements drawn x condition TRUE, otherwise y.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_where.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Elementwise conditional selection — mlx_where","text":"Behaves like ifelse() arrays, evaluates branches.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_where.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Elementwise conditional selection — mlx_where","text":"","code":"cond <- as_mlx(matrix(c(TRUE, FALSE, TRUE, FALSE), 2, 2)) a <- as_mlx(matrix(1:4, 2, 2)) b <- as_mlx(matrix(5:8, 2, 2)) mlx_where(cond, a, b) #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]    1    3 #> [2,]    6    8"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_zeros.html","id":null,"dir":"Reference","previous_headings":"","what":"Create arrays of zeros on MLX devices — mlx_zeros","title":"Create arrays of zeros on MLX devices — mlx_zeros","text":"Create arrays zeros MLX devices","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_zeros.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create arrays of zeros on MLX devices — mlx_zeros","text":"","code":"mlx_zeros(   dim,   dtype = c(\"float32\", \"float64\", \"int8\", \"int16\", \"int32\", \"int64\", \"uint8\", \"uint16\",     \"uint32\", \"uint64\", \"bool\", \"complex64\"),   device = mlx_default_device() )"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_zeros.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create arrays of zeros on MLX devices — mlx_zeros","text":"dim Integer vector specifying array shape/dimensions. dtype MLX dtype use. One \"float32\", \"float64\", \"int8\", \"int16\", \"int32\", \"int64\", \"uint8\", \"uint16\", \"uint32\", \"uint64\", \"bool\", \"complex64\". device Execution target: provide \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device().","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_zeros.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create arrays of zeros on MLX devices — mlx_zeros","text":"mlx array filled zeros.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_zeros.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create arrays of zeros on MLX devices — mlx_zeros","text":"","code":"zeros <- mlx_zeros(c(2, 3)) zeros_int <- mlx_zeros(c(2, 3), dtype = \"int32\")"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_zeros_like.html","id":null,"dir":"Reference","previous_headings":"","what":"Zeros shaped like an existing mlx array — mlx_zeros_like","title":"Zeros shaped like an existing mlx array — mlx_zeros_like","text":"mlx_zeros_like() mirrors mlx.core.zeros_like(): creates zero-filled array matching source array's shape. Optionally override dtype device.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_zeros_like.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Zeros shaped like an existing mlx array — mlx_zeros_like","text":"","code":"mlx_zeros_like(x, dtype = NULL, device = NULL)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_zeros_like.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Zeros shaped like an existing mlx array — mlx_zeros_like","text":"x mlx array. dtype Optional MLX dtype override. Defaults source array's dtype. device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_zeros_like.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Zeros shaped like an existing mlx array — mlx_zeros_like","text":"mlx array zeros matching x.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/mlx_zeros_like.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Zeros shaped like an existing mlx array — mlx_zeros_like","text":"","code":"base <- mlx_ones(c(2, 2)) zeros <- mlx_zeros_like(base) as.matrix(zeros) #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0"},{"path":"https://hughjonesd.github.io/Rmlx/reference/outer.html","id":null,"dir":"Reference","previous_headings":"","what":"Outer product of two vectors — outer","title":"Outer product of two vectors — outer","text":"Outer product two vectors","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/outer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Outer product of two vectors — outer","text":"","code":"outer(X, Y, FUN = \"*\", ...)  # S3 method for class 'mlx' outer(X, Y, FUN = \"*\", ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/outer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Outer product of two vectors — outer","text":"X, Y Numeric vectors mlx arrays. FUN Function apply (default method). ... Additional arguments passed methods.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/outer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Outer product of two vectors — outer","text":"mlx inputs, mlx matrix. Otherwise delegates base::outer.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/outer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Outer product of two vectors — outer","text":"","code":"x <- as_mlx(c(1, 2, 3)) y <- as_mlx(c(4, 5)) outer(x, y) #> mlx array [3 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]    4    5 #> [2,]    8   10 #> [3,]   12   15"},{"path":"https://hughjonesd.github.io/Rmlx/reference/pinv.html","id":null,"dir":"Reference","previous_headings":"","what":"Moore-Penrose pseudoinverse for MLX arrays — pinv","title":"Moore-Penrose pseudoinverse for MLX arrays — pinv","text":"Moore-Penrose pseudoinverse MLX arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/pinv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Moore-Penrose pseudoinverse for MLX arrays — pinv","text":"","code":"pinv(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/pinv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Moore-Penrose pseudoinverse for MLX arrays — pinv","text":"x mlx object coercible matrix.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/pinv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Moore-Penrose pseudoinverse for MLX arrays — pinv","text":"mlx object containing pseudoinverse.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/pinv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Moore-Penrose pseudoinverse for MLX arrays — pinv","text":"","code":"x <- as_mlx(matrix(c(1, 2, 3, 4), 2, 2)) pinv(x) #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1]       [,2] #> [1,]   -2  1.5000004 #> [2,]    1 -0.5000001"},{"path":"https://hughjonesd.github.io/Rmlx/reference/print.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Print MLX array — print.mlx","title":"Print MLX array — print.mlx","text":"Print MLX array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/print.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print MLX array — print.mlx","text":"","code":"# S3 method for class 'mlx' print(x, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/print.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print MLX array — print.mlx","text":"x mlx array, R array/matrix/vector converted via as_mlx(). ... Additional arguments (ignored)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/print.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print MLX array — print.mlx","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) print(x) #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]    1    3 #> [2,]    2    4"},{"path":"https://hughjonesd.github.io/Rmlx/reference/qr.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"QR decomposition for mlx arrays — qr.mlx","title":"QR decomposition for mlx arrays — qr.mlx","text":"QR decomposition mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/qr.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"QR decomposition for mlx arrays — qr.mlx","text":"","code":"# S3 method for class 'mlx' qr(x, tol = 1e-07, LAPACK = FALSE, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/qr.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"QR decomposition for mlx arrays — qr.mlx","text":"x mlx matrix (2-dimensional array). tol Ignored; custom tolerances supported. LAPACK Ignored; set FALSE. ... Additional arguments (unused).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/qr.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"QR decomposition for mlx arrays — qr.mlx","text":"list components Q R, mlx matrix.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/qr.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"QR decomposition for mlx arrays — qr.mlx","text":"","code":"x <- as_mlx(matrix(c(1, 2, 3, 4, 5, 6), 3, 2)) qr(x) #> $Q #> mlx array [3 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>            [,1]       [,2] #> [1,] -0.2672611  0.8728715 #> [2,] -0.5345225  0.2182179 #> [3,] -0.8017837 -0.4364358 #>  #> $R #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>           [,1]      [,2] #> [1,] -3.741657 -8.552359 #> [2,]  0.000000  1.963961 #>  #> attr(,\"class\") #> [1] \"mlx_qr\" \"list\""},{"path":"https://hughjonesd.github.io/Rmlx/reference/rbind.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Row-bind mlx arrays — rbind.mlx","title":"Row-bind mlx arrays — rbind.mlx","text":"Row-bind mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/rbind.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Row-bind mlx arrays — rbind.mlx","text":"","code":"# S3 method for class 'mlx' rbind(..., deparse.level = 1)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/rbind.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Row-bind mlx arrays — rbind.mlx","text":"... Objects bind. mlx arrays kept MLX; inputs coerced via as_mlx(). deparse.level Compatibility argument accepted S3 dispatch; ignored.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/rbind.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Row-bind mlx arrays — rbind.mlx","text":"mlx array stacked along first axis.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/rbind.mlx.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Row-bind mlx arrays — rbind.mlx","text":"Unlike base R's rbind(), function supports arrays 2 dimensions preserves dimensions except first (summed across inputs). Base R's rbind() flattens higher-dimensional arrays matrices binding.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/rbind.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Row-bind mlx arrays — rbind.mlx","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) y <- as_mlx(matrix(5:8, 2, 2)) rbind(x, y) #> mlx array [4 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]    1    3 #> [2,]    2    4 #> [3,]    5    7 #> [4,]    6    8"},{"path":"https://hughjonesd.github.io/Rmlx/reference/row.html","id":null,"dir":"Reference","previous_headings":"","what":"Row and column indices for mlx arrays — row","title":"Row and column indices for mlx arrays — row","text":"Extends base row() col() also accept mlx arrays. .factor = FALSE result stays MLX backend, avoiding round-tripping base R.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/row.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Row and column indices for mlx arrays — row","text":"","code":"row(x, as.factor = FALSE)  # Default S3 method row(x, as.factor = FALSE)  # S3 method for class 'mlx' row(x, as.factor = FALSE)  col(x, as.factor = FALSE)  # Default S3 method col(x, as.factor = FALSE)  # S3 method for class 'mlx' col(x, as.factor = FALSE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/row.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Row and column indices for mlx arrays — row","text":"x matrix-like object, one two-dimensional     dim. .factor logical value indicating whether value     returned factor row labels (created necessary)     rather numbers.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/row.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Row and column indices for mlx arrays — row","text":"matrix array row indices (row()) column indices (col()), matching base R behaviour.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/rowMeans.html","id":null,"dir":"Reference","previous_headings":"","what":"Row means for mlx arrays — rowMeans","title":"Row means for mlx arrays — rowMeans","text":"Row means mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/rowMeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Row means for mlx arrays — rowMeans","text":"","code":"rowMeans(x, ...)  # Default S3 method rowMeans(x, na.rm = FALSE, dims = 1, ...)  # S3 method for class 'mlx' rowMeans(x, na.rm = FALSE, dims = 1, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/rowMeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Row means for mlx arrays — rowMeans","text":"x array mlx array. ... Additional arguments forwarded base implementation. na.rm Logical; currently ignored mlx arrays. dims Dimensions passed base implementation x mlx array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/rowMeans.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Row means for mlx arrays — rowMeans","text":"mlx array x mlx, otherwise numeric vector.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/rowMeans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Row means for mlx arrays — rowMeans","text":"","code":"x <- as_mlx(matrix(1:6, 3, 2)) rowMeans(x) #> mlx array [3] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 2.5 3.5 4.5"},{"path":"https://hughjonesd.github.io/Rmlx/reference/rowSums.html","id":null,"dir":"Reference","previous_headings":"","what":"Row sums for mlx arrays — rowSums","title":"Row sums for mlx arrays — rowSums","text":"Row sums mlx arrays","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/rowSums.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Row sums for mlx arrays — rowSums","text":"","code":"rowSums(x, ...)  # Default S3 method rowSums(x, na.rm = FALSE, dims = 1, ...)  # S3 method for class 'mlx' rowSums(x, na.rm = FALSE, dims = 1, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/rowSums.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Row sums for mlx arrays — rowSums","text":"x array mlx array. ... Additional arguments forwarded base implementation. na.rm Logical; currently ignored mlx arrays. dims Dimensions passed base implementation x mlx array.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/rowSums.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Row sums for mlx arrays — rowSums","text":"mlx array x mlx, otherwise numeric vector.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/rowSums.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Row sums for mlx arrays — rowSums","text":"","code":"x <- as_mlx(matrix(1:6, 3, 2)) rowSums(x) #> mlx array [3] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 5 7 9"},{"path":"https://hughjonesd.github.io/Rmlx/reference/scale.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Scale mlx arrays — scale.mlx","title":"Scale mlx arrays — scale.mlx","text":"Extends base scale() handle mlx inputs without moving data back base R. computation delegates MLX reductions broadcasting. centering scaling values computed, attributes \"scaled:center\" \"scaled:scale\" stored 1 x ncol(x) mlx arrays (user-supplied numeric vectors preserved -). attributes remain MLX arrays even coercing .matrix(), stay lazily evaluated.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/scale.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scale mlx arrays — scale.mlx","text":"","code":"# S3 method for class 'mlx' scale(x, center = TRUE, scale = TRUE)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/scale.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scale mlx arrays — scale.mlx","text":"x numeric matrix(like object). center either logical value numeric-alike vector length     equal number columns x,     ‘numeric-alike’ means .numeric(.)     applied successfully .numeric(.) true. scale either logical value numeric-alike vector length     equal number columns x.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/scale.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scale mlx arrays — scale.mlx","text":"mlx array centred/scaled columns.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/solve.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Solve a system of linear equations — solve.mlx","title":"Solve a system of linear equations — solve.mlx","text":"Solve system linear equations","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/solve.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solve a system of linear equations — solve.mlx","text":"","code":"# S3 method for class 'mlx' solve(a, b = NULL, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/solve.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solve a system of linear equations — solve.mlx","text":"mlx matrix (coefficient matrix) b mlx vector matrix (right-hand side). omitted, computes matrix inverse. ... Additional arguments (compatibility base::solve)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/solve.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solve a system of linear equations — solve.mlx","text":"mlx object containing solution","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/solve.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Solve a system of linear equations — solve.mlx","text":"","code":"a <- as_mlx(matrix(c(3, 1, 1, 2), 2, 2)) b <- as_mlx(c(9, 8)) solve(a, b) #> mlx array [2] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 2 3"},{"path":"https://hughjonesd.github.io/Rmlx/reference/str.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Object structure for MLX array — str.mlx","title":"Object structure for MLX array — str.mlx","text":"Object structure MLX array","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/str.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Object structure for MLX array — str.mlx","text":"","code":"# S3 method for class 'mlx' str(object, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/str.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Object structure for MLX array — str.mlx","text":"object mlx object ... Additional arguments (ignored)","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/str.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Object structure for MLX array — str.mlx","text":"","code":"x <- as_mlx(matrix(1:4, 2, 2)) str(x) #> mlx [2 x 2] float32 on gpu"},{"path":"https://hughjonesd.github.io/Rmlx/reference/svd.html","id":null,"dir":"Reference","previous_headings":"","what":"Singular value decomposition — svd","title":"Singular value decomposition — svd","text":"Generic function SVD computation.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/svd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Singular value decomposition — svd","text":"","code":"svd(x, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/svd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Singular value decomposition — svd","text":"x object. ... Additional arguments.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/svd.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Singular value decomposition for mlx arrays — svd.mlx","title":"Singular value decomposition for mlx arrays — svd.mlx","text":"Note mlx's svd returns \"full\" SVD, U V' square matrices. different R's implementation.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/svd.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Singular value decomposition for mlx arrays — svd.mlx","text":"","code":"# S3 method for class 'mlx' svd(x, nu = min(n, p), nv = min(n, p), ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/svd.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Singular value decomposition for mlx arrays — svd.mlx","text":"x mlx matrix (2-dimensional array). nu Number left singular vectors return (0 min(dim(x))). nv Number right singular vectors return (0 min(dim(x))). ... Additional arguments (unused).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/svd.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Singular value decomposition for mlx arrays — svd.mlx","text":"list components d, u, v.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/svd.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Singular value decomposition for mlx arrays — svd.mlx","text":"","code":"x <- as_mlx(matrix(c(1, 0, 0, 2), 2, 2)) svd(x) #> $d #> mlx array [2] #>   dtype: float32 #>   device: gpu #>   values: #> [1] 2 1 #>  #> $u #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]    0    1 #> [2,]    1    0 #>  #> $v #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]    0    1 #> [2,]    1    0 #>"},{"path":"https://hughjonesd.github.io/Rmlx/reference/t.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Transpose of MLX matrix — t.mlx","title":"Transpose of MLX matrix — t.mlx","text":"Transpose MLX matrix","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/t.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transpose of MLX matrix — t.mlx","text":"","code":"# S3 method for class 'mlx' t(x)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/t.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transpose of MLX matrix — t.mlx","text":"x mlx matrix (2-dimensional array).","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/t.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transpose of MLX matrix — t.mlx","text":"Transposed mlx matrix","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/t.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transpose of MLX matrix — t.mlx","text":"","code":"x <- as_mlx(matrix(1:6, 2, 3)) t(x) #> mlx array [3 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]    1    2 #> [2,]    3    4 #> [3,]    5    6"},{"path":"https://hughjonesd.github.io/Rmlx/reference/tcrossprod.mlx.html","id":null,"dir":"Reference","previous_headings":"","what":"Transposed cross product — tcrossprod.mlx","title":"Transposed cross product — tcrossprod.mlx","text":"Transposed cross product","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/tcrossprod.mlx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transposed cross product — tcrossprod.mlx","text":"","code":"# S3 method for class 'mlx' tcrossprod(x, y = NULL, ...)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/tcrossprod.mlx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transposed cross product — tcrossprod.mlx","text":"x mlx matrix (2-dimensional array). y mlx matrix (default: NULL, uses x) ... Additional arguments passed base::tcrossprod.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/tcrossprod.mlx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transposed cross product — tcrossprod.mlx","text":"x %*% t(y) mlx object","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/tcrossprod.mlx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transposed cross product — tcrossprod.mlx","text":"","code":"x <- as_mlx(matrix(1:6, 2, 3)) tcrossprod(x) #> mlx array [2 x 2] #>   dtype: float32 #>   device: gpu #>   values: #>      [,1] [,2] #> [1,]   35   44 #> [2,]   44   56"},{"path":"https://hughjonesd.github.io/Rmlx/reference/with_default_device.html","id":null,"dir":"Reference","previous_headings":"","what":"Temporarily set the default MLX device — with_default_device","title":"Temporarily set the default MLX device — with_default_device","text":"Temporarily set default MLX device","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/with_default_device.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temporarily set the default MLX device — with_default_device","text":"","code":"with_default_device(device, code)"},{"path":"https://hughjonesd.github.io/Rmlx/reference/with_default_device.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Temporarily set the default MLX device — with_default_device","text":"device Execution target: supply \"gpu\", \"cpu\", mlx_stream created via mlx_new_stream(). Defaults current mlx_default_device() unless noted otherwise (helpers act existing array typically reuse array's device stream). code Expression evaluate device active.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/reference/with_default_device.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Temporarily set the default MLX device — with_default_device","text":"result evaluating code.","code":""},{"path":[]},{"path":"https://hughjonesd.github.io/Rmlx/reference/with_default_device.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Temporarily set the default MLX device — with_default_device","text":"","code":"old <- mlx_default_device() with_default_device(\"cpu\", mlx_default_device()) #> [1] \"cpu\" mlx_default_device(old) #> [1] \"gpu\""},{"path":"https://hughjonesd.github.io/Rmlx/news/index.html","id":"rmlx-0109000-development","dir":"Changelog","previous_headings":"","what":"Rmlx 0.1.0.9000 (development)","title":"Rmlx 0.1.0.9000 (development)","text":"mlx_slice_update() now accepts 1-based (inclusive) start/stop indices match rest R API; internal callers updated accordingly. mlx_rand_categorical(), mlx_rand_permutation(), mlx_cross_entropy(), mlx_embedding() now accept 1-based indices inputs/outputs, keeping exported APIs consistent R conventions. Added negative numeric indexing support [/[<- mlx arrays documented subsetting semantics. Added mlx_import_function() import MLX functions (e.g.) Python. Added mlx_array(), mlx_matrix(), mlx_vector(), mlx_scalar() fast construction MLX objects data dimensions already known. Added mlx_fft(), mlx_fft2(), mlx_fftn() wrappers around MLX FFT kernels. Added distribution functions mlx_d/p/qnorm(), mlx_d/p/qunif() etc. Added mlx_quantile(). Added mlx_coordinate_descent(), coordinate descent algorithm. Fixed several [/[<- bugs affecting non-contiguous, unsorted, duplicate subsetting patterns mlx arrays. as_mlx() now takes much faster path large numeric matrices letting MLX handle column-major inputs directly. Base reducers () () applied mlx arrays now return plain R logical scalars; mlx_all()/mlx_any() continue yield mlx booleans. Added mlx-aware wrappers row(), col(), asplit(), backsolve(). Added scale.mlx() center/scale matrices entirely MLX backend (MLX arrays stored scaled:center / scaled:scale attributes). scale.mlx() now always records scaled:center / scaled:scale attributes 1 x p MLX arrays, keeping lazily evaluated even coercion. .matrix.mlx() now preserves user-set attributes (including MLX scaling metadata) copying arrays back base R. Created new benchmarks vignette. Added pre-commit hooks run, commit print benchmark.","code":""},{"path":"https://hughjonesd.github.io/Rmlx/news/index.html","id":"rmlx-010","dir":"Changelog","previous_headings":"","what":"Rmlx 0.1.0","title":"Rmlx 0.1.0","text":"Initial release r-universe.","code":""}]
