% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/nn.R
\name{mlx_quantized_matmul}
\alias{mlx_quantized_matmul}
\title{Quantized Matrix Multiplication}
\usage{
mlx_quantized_matmul(
  x,
  w,
  scales,
  biases = NULL,
  transpose = TRUE,
  group_size = 64L,
  bits = 4L,
  mode = "affine",
  device = mlx_default_device()
)
}
\arguments{
\item{x}{An mlx array (the input matrix)}

\item{w}{An mlx array (the quantized weight matrix)}

\item{scales}{An mlx array (the quantization scales)}

\item{biases}{An optional mlx array (biases to add). Default: NULL}

\item{transpose}{Whether to transpose the weight matrix. Default: TRUE}

\item{group_size}{The group size for quantization. Default: 64}

\item{bits}{The number of bits for quantization (typically 4 or 8). Default: 4}

\item{mode}{The quantization mode, either "affine" or "symmetric". Default: "affine"}

\item{device}{Device to perform computation on. Default: \code{mlx_default_device()}}
}
\value{
An mlx array with the result of the quantized matrix multiplication
}
\description{
Performs matrix multiplication with a quantized weight matrix. This operation
is essential for efficient inference with quantized models, significantly reducing
memory usage and computation time while maintaining reasonable accuracy.
}
\details{
Quantized matrix multiplication uses low-precision representations (typically 4-bit or
8-bit integers) for weights, which reduces memory footprint by up to 8x compared to
float32. The scales parameter contains the dequantization factors needed to reconstruct
approximate float values during computation.

The group_size parameter controls the granularity of quantization - smaller groups
provide better accuracy but slightly higher memory usage.

\strong{Note:} This function requires properly quantized and packed weights. Users should
use MLX quantization utilities to prepare weights in the correct format. The weight
matrix must be uint32 type with values packed according to the bits parameter.
}
\seealso{
\code{\link[=mlx_gather_qmm]{mlx_gather_qmm()}}

\url{https://ml-explore.github.io/mlx/build/html/python/nn.html}
}
