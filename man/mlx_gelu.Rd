% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/nn.R
\name{mlx_gelu}
\alias{mlx_gelu}
\title{GELU activation}
\usage{
mlx_gelu()
}
\value{
An \code{mlx_module} applying GELU activation.
}
\description{
Gaussian Error Linear Unit activation function.
}
\examples{
act <- mlx_gelu()
x <- as_mlx(matrix(c(-2, -1, 0, 1, 2), 5, 1))
mlx_forward(act, x)
}
\seealso{
\url{https://ml-explore.github.io/mlx/build/html/python/nn.html#mlx.nn.GELU}
}
