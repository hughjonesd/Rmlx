# Missing MLX Functions in Rmlx

Based on analysis of MLX C++ headers (/opt/homebrew/include/mlx/) vs current Rmlx implementation.

## MLX API Coverage Summary

- **Linear algebra**: ✅ Complete! All functions from linalg.h are wrapped
- **Array creation**: ✅ Most covered (zeros, ones, full, eye, identity, arange, linspace, random)
- **Shape manipulation**: ⚠️  Partial coverage - missing several useful utilities
- **Neural network layers**: ✅ Good coverage of common activations and layers

---

## Still Missing from MLX in Rmlx

### Shape & Array Manipulation (High Priority)

- `zeros_like()`, `ones_like()` - Create arrays matching input shape
- `tril()`, `triu()` - Extract lower/upper triangular parts (different from tri_inv)
- `tri()` - Generate triangular matrices with specified diagonal
- `flatten()` - Flatten to 1D (may differ from R's `as.vector()`)
- `swapaxes()` - Swap two specific axes (simpler than full `aperm`)
- `broadcast_to()`, `broadcast_arrays()` - Explicit broadcasting control
- `meshgrid()` - Create coordinate matrices (useful for plotting/sampling)
- `copy()` - Explicit copy operation
- `as_strided()` - Low-level view creation with custom strides
- `slice_update()` - In-place slice updates

### Cumulative Operations

- `cumsum()`, `cumprod()` - Cumulative sum/product
- `diff()` - Finite differences

### Advanced Indexing

- `take()` - Index selection with integer arrays
- `gather()`, `scatter()` - Advanced gather/scatter operations

### Comparison & Checks

- `isnan()`, `isinf()`, `isfinite()` - NaN/infinity checks
- `allclose()`, `isclose()` - Approximate equality with tolerance
- `array_equal()` - Exact array equality

### Specialized Transforms

- `hadamard_transform()` - Hadamard matrix multiplication
- Convolution operations (conv1d, conv2d, conv3d) if they exist

---

## Already Implemented ✅

### Linear Algebra (linalg.h)
- norm, qr, svd, inv, tri_inv, cholesky, pinv, cholesky_inv, lu
- solve, solve_triangular, cross
- eig, eigvals, eigh, eigvalsh
- trace, diagonal, outer

### Array Creation
- zeros, ones, full, eye, identity, arange, linspace
- Random: normal, uniform, bernoulli, gumbel, truncated_normal, multivariate_normal,
  laplace, categorical, randint, permutation

### Shape Operations
- stack, squeeze, expand_dims, repeat, tile, pad, roll, moveaxis, split, unflatten
- transpose (t), aperm

### Reductions
- sum, mean, var, std, prod, min, max, all, any
- logsumexp, logcumsumexp

### Sorting & Selection
- sort, argsort, partition, argpartition, topk, argmin, argmax

### Other
- FFT operations
- Neural network layers (linear, sequential, embedding)
- Activations (relu, gelu, sigmoid, tanh, silu, leaky_relu, softmax)
- Normalization (layer_norm, batch_norm, dropout)
- Loss functions (mse_loss, l1_loss, binary_cross_entropy, cross_entropy)

---

## Priority Recommendations

**Most useful missing functions for general array manipulation:**
1. `zeros_like()` / `ones_like()` - Very common pattern
2. `tril()` / `triu()` - Essential for triangular matrix operations
3. `cumsum()` / `cumprod()` - Common in time series and numerical computing
4. `flatten()` - Array reshaping utility
5. `isnan()` / `isinf()` / `isfinite()` - Essential for data validation
